[
  {
    "id": "http://arxiv.org/abs/2602.02164v1",
    "title": "Co-RedTeam: Orchestrated Security Discovery and Exploitation with LLM Agents",
    "summary": "Large language models (LLMs) have shown promise in assisting cybersecurity tasks, yet existing approaches struggle with automatic vulnerability discovery and exploitation due to limited interaction, weak execution grounding, and a lack of experience reuse. We propose Co-RedTeam, a security-aware multi-agent framework designed to mirror real-world red-teaming workflows by integrating security-domain knowledge, code-aware analysis, execution-grounded iterative reasoning, and long-term memory. Co-RedTeam decomposes vulnerability analysis into coordinated discovery and exploitation stages, enabling agents to plan, execute, validate, and refine actions based on real execution feedback while learning from prior trajectories. Extensive evaluations on challenging security benchmarks demonstrate that Co-RedTeam consistently outperforms strong baselines across diverse backbone models, achieving over 60% success rate in vulnerability exploitation and over 10% absolute improvement in vulnerability detection. Ablation and iteration studies further confirm the critical role of execution feedback, structured interaction, and memory for building robust and generalizable cybersecurity agents.",
    "published": "2026-02-02T14:38:45Z",
    "updated": "2026-02-02T14:38:45Z",
    "authors": [
      "Pengfei He",
      "Ash Fox",
      "Lesly Miculicich",
      "Stefan Friedli",
      "Daniel Fabian",
      "Burak Gokturk",
      "Jiliang Tang",
      "Chen-Yu Lee",
      "Tomas Pfister",
      "Long T. Le"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "cs.CR"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02164v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02164v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 15.6,
    "matched_areas": [
      "ai",
      "agents"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02034v1",
    "title": "Constrained Process Maps for Multi-Agent Generative AI Workflows",
    "summary": "Large language model (LLM)-based agents are increasingly used to perform complex, multi-step workflows in regulated settings such as compliance and due diligence. However, many agentic architectures rely primarily on prompt engineering of a single agent, making it difficult to observe or compare how models handle uncertainty and coordination across interconnected decision stages and with human oversight. We introduce a multi-agent system formalized as a finite-horizon Markov Decision Process (MDP) with a directed acyclic structure. Each agent corresponds to a specific role or decision stage (e.g., content, business, or legal review in a compliance workflow), with predefined transitions representing task escalation or completion. Epistemic uncertainty is quantified at the agent level using Monte Carlo estimation, while system-level uncertainty is captured by the MDP's termination in either an automated labeled state or a human-review state. We illustrate the approach through a case study in AI safety evaluation for self-harm detection, implemented as a multi-agent compliance system. Results demonstrate improvements over a single-agent baseline, including up to a 19\\% increase in accuracy, up to an 85x reduction in required human review, and, in some configurations, reduced processing time.",
    "published": "2026-02-02T12:32:11Z",
    "updated": "2026-02-02T12:32:11Z",
    "authors": [
      "Ananya Joshi",
      "Michael Rudow"
    ],
    "primary_category": "cs.AI",
    "categories": [
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02034v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02034v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 15.6,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02455v1",
    "title": "Drift-Bench: Diagnosing Cooperative Breakdowns in LLM Agents under Input Faults via Multi-Turn Interaction",
    "summary": "As Large Language Models transition to autonomous agents, user inputs frequently violate cooperative assumptions (e.g., implicit intent, missing parameters, false presuppositions, or ambiguous expressions), creating execution risks that text-only evaluations do not capture. Existing benchmarks typically assume well-specified instructions or restrict evaluation to text-only, single-turn clarification, and thus do not measure multi-turn disambiguation under grounded execution risk. We introduce \\textbf{Drift-Bench}, the first diagnostic benchmark that evaluates agentic pragmatics under input faults through multi-turn clarification across state-oriented and service-oriented execution environments. Grounded in classical theories of communication, \\textbf{Drift-Bench} provides a unified taxonomy of cooperative breakdowns and employs a persona-driven user simulator with the \\textbf{Rise} evaluation protocol. Experiments show substantial performance drops under these faults, with clarification effectiveness varying across user personas and fault types. \\MethodName bridges clarification research and agent safety evaluation, enabling systematic diagnosis of failures that can lead to unsafe executions.",
    "published": "2026-02-02T18:46:16Z",
    "updated": "2026-02-02T18:46:16Z",
    "authors": [
      "Han Bao",
      "Zheyuan Zhang",
      "Pengcheng Jing",
      "Zhengqing Yuan",
      "Kaiwen Shi",
      "Yanfang Ye"
    ],
    "primary_category": "cs.AI",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.SE"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02455v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02455v1",
    "comment": "65 pages, 40 figures",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 14.4,
    "matched_areas": [
      "ai",
      "agents"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02196v1",
    "title": "TIDE: Trajectory-based Diagnostic Evaluation of Test-Time Improvement in LLM Agents",
    "summary": "Recent advances in autonomous LLM agents demonstrate their ability to improve performance through iterative interaction with the environment. We define this paradigm as Test-Time Improvement (TTI). However, the mechanisms under how and why TTI succeed or fail remain poorly understood, and existing evaluation metrics fail to capture their task optimization efficiency, behavior adaptation after erroneous actions, and the specific utility of working memory for task completion. To address these gaps, we propose Test-time Improvement Diagnostic Evaluation (TIDE), an agent-agnostic and environment-agnostic framework that decomposes TTI into three comprehensive and interconnected dimensions. The framework measures (1) the overall temporal dynamics of task completion and (2) identifies whether performance is primarily constrained by recursive looping behaviors or (3) by burdensome accumulated memory. Through extensive experiments across diverse agents and environments, TIDE highlights that improving agent performance requires more than scaling internal reasoning, calling for explicitly optimizing the interaction dynamics between the agent and the environment.",
    "published": "2026-02-02T15:00:47Z",
    "updated": "2026-02-02T15:00:47Z",
    "authors": [
      "Hang Yan",
      "Xinyu Che",
      "Fangzhi Xu",
      "Qiushi Sun",
      "Zichen Ding",
      "Kanzhi Cheng",
      "Jian Zhang",
      "Tao Qin",
      "Jun Liu",
      "Qika Lin"
    ],
    "primary_category": "cs.AI",
    "categories": [
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02196v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02196v1",
    "comment": "29pages, 10 figures",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 14.4,
    "matched_areas": [
      "ai",
      "agents"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01665v1",
    "title": "TABX: A High-Throughput Sandbox Battle Simulator for Multi-Agent Reinforcement Learning",
    "summary": "The design of environments plays a critical role in shaping the development and evaluation of cooperative multi-agent reinforcement learning (MARL) algorithms. While existing benchmarks highlight critical challenges, they often lack the modularity required to design custom evaluation scenarios. We introduce the Totally Accelerated Battle Simulator in JAX (TABX), a high-throughput sandbox designed for reconfigurable multi-agent tasks. TABX provides granular control over environmental parameters, permitting a systematic investigation into emergent agent behaviors and algorithmic trade-offs across a diverse spectrum of task complexities. Leveraging JAX for hardware-accelerated execution on GPUs, TABX enables massive parallelization and significantly reduces computational overhead. By providing a fast, extensible, and easily customized framework, TABX facilitates the study of MARL agents in complex structured domains and serves as a scalable foundation for future research. Our code is available at: https://anonymous.4open.science/r/TABX-00CA.",
    "published": "2026-02-02T05:34:38Z",
    "updated": "2026-02-02T05:34:38Z",
    "authors": [
      "Hayeong Lee",
      "JunHyeok Oh",
      "Byung-Jun Lee"
    ],
    "primary_category": "cs.MA",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01665v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01665v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 14.4,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02395v1",
    "title": "David vs. Goliath: Verifiable Agent-to-Agent Jailbreaking via Reinforcement Learning",
    "summary": "The evolution of large language models into autonomous agents introduces adversarial failures that exploit legitimate tool privileges, transforming safety evaluation in tool-augmented environments from a subjective NLP task into an objective control problem. We formalize this threat model as Tag-Along Attacks: a scenario where a tool-less adversary \"tags along\" on the trusted privileges of a safety-aligned Operator to induce prohibited tool use through conversation alone. To validate this threat, we present Slingshot, a 'cold-start' reinforcement learning framework that autonomously discovers emergent attack vectors, revealing a critical insight: in our setting, learned attacks tend to converge to short, instruction-like syntactic patterns rather than multi-turn persuasion. On held-out extreme-difficulty tasks, Slingshot achieves a 67.0% success rate against a Qwen2.5-32B-Instruct-AWQ Operator (vs. 1.7% baseline), reducing the expected attempts to first success (on solved tasks) from 52.3 to 1.3. Crucially, Slingshot transfers zero-shot to several model families, including closed-source models like Gemini 2.5 Flash (56.0% attack success rate) and defensive-fine-tuned open-source models like Meta-SecAlign-8B (39.2% attack success rate). Our work establishes Tag-Along Attacks as a first-class, verifiable threat model and shows that effective agentic attacks can be elicited from off-the-shelf open-weight models through environment interaction alone.",
    "published": "2026-02-02T17:56:55Z",
    "updated": "2026-02-02T17:56:55Z",
    "authors": [
      "Samuel Nellessen",
      "Tal Kachman"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "cs.MA"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02395v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02395v1",
    "comment": "Under review. 8 main pages, 2 figures, 2 tables. Appendix included",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 13.2,
    "matched_areas": [
      "ai",
      "agents"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01869v1",
    "title": "ProcMEM: Learning Reusable Procedural Memory from Experience via Non-Parametric PPO for LLM Agents",
    "summary": "LLM-driven agents demonstrate strong performance in sequential decision-making but often rely on on-the-fly reasoning, re-deriving solutions even in recurring scenarios. This insufficient experience reuse leads to computational redundancy and execution instability. To bridge this gap, we propose ProcMEM, a framework that enables agents to autonomously learn procedural memory from interaction experiences without parameter updates. By formalizing a Skill-MDP, ProcMEM transforms passive episodic narratives into executable Skills defined by activation, execution, and termination conditions to ensure executability. To achieve reliable reusability without capability degradation, we introduce Non-Parametric PPO, which leverages semantic gradients for high-quality candidate generation and a PPO Gate for robust Skill verification. Through score-based maintenance, ProcMEM sustains compact, high-quality procedural memory. Experimental results across in-domain, cross-task, and cross-agent scenarios demonstrate that ProcMEM achieves superior reuse rates and significant performance gains with extreme memory compression. Visualized evolutionary trajectories and Skill distributions further reveal how ProcMEM transparently accumulates, refines, and reuses procedural knowledge to facilitate long-term autonomy.",
    "published": "2026-02-02T09:43:12Z",
    "updated": "2026-02-02T09:43:12Z",
    "authors": [
      "Qirui Mi",
      "Zhijian Ma",
      "Mengyue Yang",
      "Haoxuan Li",
      "Yisen Wang",
      "Haifeng Zhang",
      "Jun Wang"
    ],
    "primary_category": "cs.AI",
    "categories": [
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01869v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01869v1",
    "comment": "20 Pages, 6 Figures, 4 Tables",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 13.2,
    "matched_areas": [
      "ai",
      "agents"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02475v1",
    "title": "AgentRx: Diagnosing AI Agent Failures from Execution Trajectories",
    "summary": "AI agents often fail in ways that are difficult to localize because executions are probabilistic, long-horizon, multi-agent, and mediated by noisy tool outputs. We address this gap by manually annotating failed agent runs and release a novel benchmark of 115 failed trajectories spanning structured API workflows, incident management, and open-ended web/file tasks. Each trajectory is annotated with a critical failure step and a category from a grounded-theory derived, cross-domain failure taxonomy. To mitigate the human cost of failure attribution, we present AGENTRX, an automated domain-agnostic diagnostic framework that pinpoints the critical failure step in a failed agent trajectory. It synthesizes constraints, evaluates them step-by-step, and produces an auditable validation log of constraint violations with associated evidence; an LLM-based judge uses this log to localize the critical step and category. Our framework improves step localization and failure attribution over existing baselines across three domains.",
    "published": "2026-02-02T18:54:07Z",
    "updated": "2026-02-02T18:54:07Z",
    "authors": [
      "Shraddha Barke",
      "Arnav Goyal",
      "Alind Khare",
      "Avaljot Singh",
      "Suman Nath",
      "Chetan Bansal"
    ],
    "primary_category": "cs.AI",
    "categories": [
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02475v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02475v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 12.0,
    "matched_areas": [
      "ai",
      "agents"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01664v1",
    "title": "FlowSteer: Interactive Agentic Workflow Orchestration via End-to-End Reinforcement Learning",
    "summary": "In recent years, a variety of powerful agentic workflows have been applied to solve a wide range of human problems. However, existing workflow orchestration still faces key challenges, including high manual cost, reliance on specific operators/large language models (LLMs), and sparse reward signals. To address these challenges, we propose FlowSteer, an end-to-end reinforcement learning framework that takes a lightweight policy model as the agent and an executable canvas environment, automating workflow orchestration through multi-turn interaction. In this process, the policy model analyzes execution states and selects editing actions, while the canvas executes operators and returns feedback for iterative refinement. Moreover, FlowSteer provides a plug-and-play framework that supports diverse operator libraries and interchangeable LLM backends. To effectively train this interaction paradigm, we propose Canvas Workflow Relative Policy Optimization (CWRPO), which introduces diversity-constrained rewards with conditional release to stabilize learning and suppress shortcut behaviors. Experimental results on twelve datasets show that FlowSteer significantly outperforms baselines across various tasks.",
    "published": "2026-02-02T05:30:42Z",
    "updated": "2026-02-02T05:30:42Z",
    "authors": [
      "Mingda Zhang",
      "Haoran Luo",
      "Tiesunlong Shen",
      "Qika Lin",
      "Xiaoying Tang",
      "Rui Mao",
      "Erik Cambria"
    ],
    "primary_category": "cs.AI",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01664v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01664v1",
    "comment": "41 pages, 7 figures, 6 tables. Project page: http://flowsteer.org/",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 12.0,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02471v1",
    "title": "Multi-head automated segmentation by incorporating detection head into the contextual layer neural network",
    "summary": "Deep learning based auto segmentation is increasingly used in radiotherapy, but conventional models often produce anatomically implausible false positives, or hallucinations, in slices lacking target structures. We propose a gated multi-head Transformer architecture based on Swin U-Net, augmented with inter-slice context integration and a parallel detection head, which jointly performs slice-level structure detection via a multi-layer perceptron and pixel-level segmentation through a context-enhanced stream. Detection outputs gate the segmentation predictions to suppress false positives in anatomically invalid slices, and training uses slice-wise Tversky loss to address class imbalance. Experiments on the Prostate-Anatomical-Edge-Cases dataset from The Cancer Imaging Archive demonstrate that the gated model substantially outperforms a non-gated segmentation-only baseline, achieving a mean Dice loss of $0.013 \\pm 0.036$ versus $0.732 \\pm 0.314$, with detection probabilities strongly correlated with anatomical presence, effectively eliminating spurious segmentations. In contrast, the non-gated model exhibited higher variability and persistent false positives across all slices. These results indicate that detection-based gating enhances robustness and anatomical plausibility in automated segmentation applications, reducing hallucinated predictions without compromising segmentation quality in valid slices, and offers a promising approach for improving the reliability of clinical radiotherapy auto-contouring workflows.",
    "published": "2026-02-02T18:51:25Z",
    "updated": "2026-02-02T18:51:25Z",
    "authors": [
      "Edwin Kys",
      "Febian Febian"
    ],
    "primary_category": "cs.CV",
    "categories": [
      "cs.CV",
      "cs.AI",
      "physics.med-ph"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02471v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02471v1",
    "comment": "8 pages, 3 figures, 1 table",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 10.8,
    "matched_areas": [
      "ai",
      "vision"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02350v1",
    "title": "Context Learning for Multi-Agent Discussion",
    "summary": "Multi-Agent Discussion (MAD) has garnered increasing attention very recently, where multiple LLM instances collaboratively solve problems via structured discussion. However, we find that current MAD methods easily suffer from discussion inconsistency, LLMs fail to reach a coherent solution, due to the misalignment between their individual contexts.In this paper, we introduce a multi-LLM context learning method (M2CL) that learns a context generator for each agent, capable of dynamically generating context instructions per discussion round via automatic information organization and refinement. Specifically, inspired by our theoretical insights on the context instruction, M2CL train the generators to control context coherence and output discrepancies via a carefully crafted self-adaptive mechanism.It enables LLMs to avoid premature convergence on majority noise and progressively reach the correct consensus. We evaluate M2CL on challenging tasks, including academic reasoning, embodied tasks, and mobile control. The results show that the performance of M2CL significantly surpasses existing methods by 20%--50%, while enjoying favorable transferability and computational efficiency.",
    "published": "2026-02-02T17:15:17Z",
    "updated": "2026-02-02T17:15:17Z",
    "authors": [
      "Xingyuan Hua",
      "Sheng Yue",
      "Xinyi Li",
      "Yizhe Zhao",
      "Jinrui Zhang",
      "Ju Ren"
    ],
    "primary_category": "cs.AI",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.MA"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02350v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02350v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 10.8,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02138v1",
    "title": "CAM: A Causality-based Analysis Framework for Multi-Agent Code Generation Systems",
    "summary": "Despite the remarkable success that Multi-Agent Code Generation Systems (MACGS) have achieved, the inherent complexity of multi-agent architectures produces substantial volumes of intermediate outputs. To date, the individual importance of these intermediate outputs to the system correctness remains opaque, which impedes targeted optimization of MACGS designs. To address this challenge, we propose CAM, the first \\textbf{C}ausality-based \\textbf{A}nalysis framework for \\textbf{M}ACGS that systematically quantifies the contribution of different intermediate features for system correctness. By comprehensively categorizing intermediate outputs and systematically simulating realistic errors on intermediate features, we identify the important features for system correctness and aggregate their importance rankings. We conduct extensive empirical analysis on the identified importance rankings. Our analysis reveals intriguing findings: first, we uncover context-dependent features\\textemdash features whose importance emerges mainly through interactions with other features, revealing that quality assurance for MACGS should incorporate cross-feature consistency checks; second, we reveal that hybrid backend MACGS with different backend LLMs assigned according to their relative strength achieves up to 7.2\\% Pass@1 improvement, underscoring hybrid architectures as a promising direction for future MACGS design. We further demonstrate CAM's practical utility through two applications: (1) failure repair which achieves a 73.3\\% success rate by optimizing top-3 importance-ranked features and (2) feature pruning that reduces up to 66.8\\% intermediate token consumption while maintaining generation performance. Our work provides actionable insights for MACGS design and deployment, establishing causality analysis as a powerful approach for understanding and improving MACGS.",
    "published": "2026-02-02T14:19:08Z",
    "updated": "2026-02-02T14:19:08Z",
    "authors": [
      "Lyu Zongyi",
      "Ji Zhenlan",
      "Chen Songqiang",
      "Wang Liwen",
      "Huang Yuheng",
      "Wang Shuai",
      "Cheung Shing-Chi"
    ],
    "primary_category": "cs.SE",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02138v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02138v1",
    "comment": "18 pages, 12 tables, 4 figures",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 10.8,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02050v1",
    "title": "Rethinking the Role of Entropy in Optimizing Tool-Use Behaviors for Large Language Model Agents",
    "summary": "Tool-using agents based on Large Language Models (LLMs) excel in tasks such as mathematical reasoning and multi-hop question answering. However, in long trajectories, agents often trigger excessive and low-quality tool calls, increasing latency and degrading inference performance, making managing tool-use behavior challenging. In this work, we conduct entropy-based pilot experiments and observe a strong positive correlation between entropy reduction and high-quality tool calls. Building on this finding, we propose using entropy reduction as a supervisory signal and design two reward strategies to address the differing needs of optimizing tool-use behavior. Sparse outcome rewards provide coarse, trajectory-level guidance to improve efficiency, while dense process rewards offer fine-grained supervision to enhance performance. Experiments across diverse domains show that both reward designs improve tool-use behavior: the former reduces tool calls by 72.07% compared to the average of baselines, while the latter improves performance by 22.27%. These results position entropy reduction as a key mechanism for enhancing tool-use behavior, enabling agents to be more adaptive in real-world applications.",
    "published": "2026-02-02T12:52:14Z",
    "updated": "2026-02-02T12:52:14Z",
    "authors": [
      "Zeping Li",
      "Hongru Wang",
      "Yiwen Zhao",
      "Guanhua Chen",
      "Yixia Li",
      "Keyang Chen",
      "Yixin Cao",
      "Guangnan Ye",
      "Hongfeng Chai",
      "Mengdi Wang",
      "Zhenfei Yin"
    ],
    "primary_category": "cs.AI",
    "categories": [
      "cs.AI",
      "cs.SE"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02050v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02050v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 10.8,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02035v1",
    "title": "Bandwidth-Efficient Multi-Agent Communication through Information Bottleneck and Vector Quantization",
    "summary": "Multi-agent reinforcement learning systems deployed in real-world robotics applications face severe communication constraints that significantly impact coordination effectiveness. We present a framework that combines information bottleneck theory with vector quantization to enable selective, bandwidth-efficient communication in multi-agent environments. Our approach learns to compress and discretize communication messages while preserving task-critical information through principled information-theoretic optimization. We introduce a gated communication mechanism that dynamically determines when communication is necessary based on environmental context and agent states. Experimental evaluation on challenging coordination tasks demonstrates that our method achieves 181.8% performance improvement over no-communication baselines while reducing bandwidth usage by 41.4%. Comprehensive Pareto frontier analysis shows dominance across the entire success-bandwidth spectrum with area-under-curve of 0.198 vs 0.142 for next-best methods. Our approach significantly outperforms existing communication strategies and establishes a theoretically grounded framework for deploying multi-agent systems in bandwidth-constrained environments such as robotic swarms, autonomous vehicle fleets, and distributed sensor networks.",
    "published": "2026-02-02T12:32:28Z",
    "updated": "2026-02-02T12:32:28Z",
    "authors": [
      "Ahmad Farooq",
      "Kamran Iqbal"
    ],
    "primary_category": "cs.RO",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.IT",
      "cs.LG",
      "cs.MA"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02035v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02035v1",
    "comment": "Accepted at the 2026 IEEE International Conference on Robotics and Automation (ICRA 2026), Vienna, Austria. 9 pages, 4 figures, 6 tables",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 10.8,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01991v1",
    "title": "Leveraging Latent Vector Prediction for Localized Control in Image Generation via Diffusion Models",
    "summary": "Diffusion models emerged as a leading approach in text-to-image generation, producing high-quality images from textual descriptions. However, attempting to achieve detailed control to get a desired image solely through text remains a laborious trial-and-error endeavor. Recent methods have introduced image-level controls alongside with text prompts, using prior images to extract conditional information such as edges, segmentation and depth maps. While effective, these methods apply conditions uniformly across the entire image, limiting localized control. In this paper, we propose a novel methodology to enable precise local control over user-defined regions of an image, while leaving to the diffusion model the task of autonomously generating the remaining areas according to the original prompt. Our approach introduces a new training framework that incorporates masking features and an additional loss term, which leverages the prediction of the initial latent vector at any diffusion step to enhance the correspondence between the current step and the final sample in the latent space. Extensive experiments demonstrate that our method effectively synthesizes high-quality images with controlled local conditions.",
    "published": "2026-02-02T11:47:48Z",
    "updated": "2026-02-02T11:47:48Z",
    "authors": [
      "Pablo Domingo-Gregorio",
      "Javier Ruiz-Hidalgo"
    ],
    "primary_category": "cs.CV",
    "categories": [
      "cs.CV"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01991v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01991v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 10.8,
    "matched_areas": [
      "ai",
      "vision"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01853v1",
    "title": "Designing Time Series Experiments in A/B Testing with Transformer Reinforcement Learning",
    "summary": "A/B testing has become a gold standard for modern technological companies to conduct policy evaluation. Yet, its application to time series experiments, where policies are sequentially assigned over time, remains challenging. Existing designs suffer from two limitations: (i) they do not fully leverage the entire history for treatment allocation; (ii) they rely on strong assumptions to approximate the objective function (e.g., the mean squared error of the estimated treatment effect) for optimizing the design. We first establish an impossibility theorem showing that failure to condition on the full history leads to suboptimal designs, due to the dynamic dependencies in time series experiments. To address both limitations simultaneously, we next propose a transformer reinforcement learning (RL) approach which leverages transformers to condition allocation on the entire history and employs RL to directly optimize the MSE without relying on restrictive assumptions. Empirical evaluations on synthetic data, a publicly available dispatch simulator, and a real-world ridesharing dataset demonstrate that our proposal consistently outperforms existing designs.",
    "published": "2026-02-02T09:27:51Z",
    "updated": "2026-02-02T09:27:51Z",
    "authors": [
      "Xiangkun Wu",
      "Qianglin Wen",
      "Yingying Zhang",
      "Hongtu Zhu",
      "Ting Li",
      "Chengchun Shi"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "stat.ME",
      "stat.ML"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01853v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01853v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 10.8,
    "matched_areas": [
      "ai",
      "vision"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01797v1",
    "title": "ORCH: many analyses, one merge-a deterministic multi-agent orchestrator for discrete-choice reasoning with EMA-guided routing",
    "summary": "Recent advances in large-scale language models (LLMs) have made multi-agent architectures attractive for challenging reasoning tasks. However, many existing systems rely on stochastic routing or ad-hoc heuristics, making their behavior difficult to reproduce and their decision process hard to interpret. We propose ORCH, a deterministic coordination framework for discrete-choice reasoning that orchestrates heterogeneous LLMs. ORCH follows a ``many analyses, one decision'' paradigm: multiple base models independently produce structured analyses, and a dedicated merge agent outputs the final choice. The framework uses fixed rules for task decomposition and answer aggregation, keeping the pipeline predictable, reproducible, and training-free. Determinism here refers to fixed routing and aggregation rules under a fixed evaluation protocol, rather than strict bit-level reproducibility across deployments. To exploit model complementarity, we optionally introduce an EMA-guided router that updates agent selection using historical accuracy, latency, or cost; since it relies on answer-based feedback, it is mainly intended for benchmarking, controlled evaluation, or delayed-feedback settings. Experiments on MMLU, MMLU-Pro, and GSM8K show that ORCH consistently outperforms single-model baselines and a majority-vote ensemble. On MMLU-Pro, ORCH improves accuracy by over 10 points compared to the strongest baseline, and on GSM8K it yields gains exceeding 50 points; McNemar tests confirm statistical significance. The EMA router provides an additional 0.7--2.0 point accuracy boost, and ablations show that both multi-agent collaboration and routing contribute substantially. Overall, ORCH offers a practical path toward controllable, interpretable, and deployment-ready LLM-based agent systems for discrete-choice reasoning.",
    "published": "2026-02-02T08:27:58Z",
    "updated": "2026-02-02T08:27:58Z",
    "authors": [
      "Hanlin Zhou",
      "Huah Yong Chan"
    ],
    "primary_category": "cs.AI",
    "categories": [
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01797v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01797v1",
    "comment": null,
    "journal_ref": null,
    "doi": "10.3389/frai.2026.1748735",
    "relevance_score": 10.8,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01710v1",
    "title": "Physics Informed Generative AI Enabling Labour Free Segmentation For Microscopy Analysis",
    "summary": "Semantic segmentation of microscopy images is a critical task for high-throughput materials characterisation, yet its automation is severely constrained by the prohibitive cost, subjectivity, and scarcity of expert-annotated data. While physics-based simulations offer a scalable alternative to manual labelling, models trained on such data historically fail to generalise due to a significant domain gap, lacking the complex textures, noise patterns, and imaging artefacts inherent to experimental data. This paper introduces a novel framework for labour-free segmentation that successfully bridges this simulation-to-reality gap. Our pipeline leverages phase-field simulations to generate an abundant source of microstructural morphologies with perfect, intrinsically-derived ground-truth masks. We then employ a Cycle-Consistent Generative Adversarial Network (CycleGAN) for unpaired image-to-image translation, transforming the clean simulations into a large-scale dataset of high-fidelity, realistic SEM images. A U-Net model, trained exclusively on this synthetic data, demonstrated remarkable generalisation when deployed on unseen experimental images, achieving a mean Boundary F1-Score of 0.90 and an Intersection over Union (IOU) of 0.88. Comprehensive validation using t-SNE feature-space projection and Shannon entropy analysis confirms that our synthetic images are statistically and featurally indistinguishable from the real data manifold. By completely decoupling model training from manual annotation, our generative framework transforms a data-scarce problem into one of data abundance, providing a robust and fully automated solution to accelerate materials discovery and analysis.",
    "published": "2026-02-02T06:36:06Z",
    "updated": "2026-02-02T06:36:06Z",
    "authors": [
      "Salma Zahran",
      "Zhou Ao",
      "Zhengyang Zhang",
      "Chen Chi",
      "Chenchen Yuan",
      "Yanming Wang"
    ],
    "primary_category": "cs.CV",
    "categories": [
      "cs.CV",
      "cond-mat.mtrl-sci",
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01710v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01710v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 10.8,
    "matched_areas": [
      "ai",
      "vision"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01644v1",
    "title": "From Perception to Action: Spatial AI Agents and World Models",
    "summary": "While large language models have become the prevailing approach for agentic reasoning and planning, their success in symbolic domains does not readily translate to the physical world. Spatial intelligence, the ability to perceive 3D structure, reason about object relationships, and act under physical constraints, is an orthogonal capability that proves important for embodied agents. Existing surveys address either agentic architectures or spatial domains in isolation. None provide a unified framework connecting these complementary capabilities. This paper bridges that gap. Through a thorough review of over 2,000 papers, citing 742 works from top-tier venues, we introduce a unified three-axis taxonomy connecting agentic capabilities with spatial tasks across scales. Crucially, we distinguish spatial grounding (metric understanding of geometry and physics) from symbolic grounding (associating images with text), arguing that perception alone does not confer agency. Our analysis reveals three key findings mapped to these axes: (1) hierarchical memory systems (Capability axis) are important for long-horizon spatial tasks. (2) GNN-LLM integration (Task axis) is a promising approach for structured spatial reasoning. (3) World models (Scale axis) are essential for safe deployment across micro-to-macro spatial scales. We conclude by identifying six grand challenges and outlining directions for future research, including the need for unified evaluation frameworks to standardize cross-domain assessment. This taxonomy provides a foundation for unifying fragmented research efforts and enabling the next generation of spatially-aware autonomous systems in robotics, autonomous vehicles, and geospatial intelligence.",
    "published": "2026-02-02T05:00:55Z",
    "updated": "2026-02-02T05:00:55Z",
    "authors": [
      "Gloria Felicia",
      "Nolan Bryant",
      "Handi Putra",
      "Ayaan Gazali",
      "Eliel Lobo",
      "Esteban Rojas"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.MA",
      "cs.RO"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01644v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01644v1",
    "comment": "61 pages, 742 citations, 1 figure, 3 tables. Survey paper on spatial AI agents, embodied AI, graph neural networks, and world models",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 10.8,
    "matched_areas": [
      "ai",
      "agents"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01623v1",
    "title": "Omni-Judge: Can Omni-LLMs Serve as Human-Aligned Judges for Text-Conditioned Audio-Video Generation?",
    "summary": "State-of-the-art text-to-video generation models such as Sora 2 and Veo 3 can now produce high-fidelity videos with synchronized audio directly from a textual prompt, marking a new milestone in multi-modal generation. However, evaluating such tri-modal outputs remains an unsolved challenge. Human evaluation is reliable but costly and difficult to scale, while traditional automatic metrics, such as FVD, CLAP, and ViCLIP, focus on isolated modality pairs, struggle with complex prompts, and provide limited interpretability. Omni-modal large language models (omni-LLMs) present a promising alternative: they naturally process audio, video, and text, support rich reasoning, and offer interpretable chain-of-thought feedback. Driven by this, we introduce Omni-Judge, a study assessing whether omni-LLMs can serve as human-aligned judges for text-conditioned audio-video generation. Across nine perceptual and alignment metrics, Omni-Judge achieves correlation comparable to traditional metrics and excels on semantically demanding tasks such as audio-text alignment, video-text alignment, and audio-video-text coherence. It underperforms on high-FPS perceptual metrics, including video quality and audio-video synchronization, due to limited temporal resolution. Omni-Judge provides interpretable explanations that expose semantic or physical inconsistencies, enabling practical downstream uses such as feedback-based refinement. Our findings highlight both the potential and current limitations of omni-LLMs as unified evaluators for multi-modal generation.",
    "published": "2026-02-02T04:36:23Z",
    "updated": "2026-02-02T04:36:23Z",
    "authors": [
      "Susan Liang",
      "Chao Huang",
      "Filippos Bellos",
      "Yolo Yunlong Tang",
      "Qianxiang Shen",
      "Jing Bi",
      "Luchuan Song",
      "Zeliang Zhang",
      "Jason Corso",
      "Chenliang Xu"
    ],
    "primary_category": "cs.CV",
    "categories": [
      "cs.CV"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01623v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01623v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 10.8,
    "matched_areas": [
      "ai",
      "vision"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01528v1",
    "title": "Making Bias Non-Predictive: Training Robust LLM Judges via Reinforcement Learning",
    "summary": "Large language models (LLMs) increasingly serve as automated judges, yet they remain susceptible to cognitive biases -- often altering their reasoning when faced with spurious prompt-level cues such as consensus claims or authority appeals. Existing mitigations via prompting or supervised fine-tuning fail to generalize, as they modify surface behavior without changing the optimization objective that makes bias cues predictive. To address this gap, we propose Epistemic Independence Training (EIT), a reinforcement learning framework grounded in a key principle: to learn independence, bias cues must be made non-predictive of reward. EIT operationalizes this through a balanced conflict strategy where bias signals are equally likely to support correct and incorrect answers, combined with a reward design that penalizes bias-following without rewarding bias agreement. Experiments on Qwen3-4B demonstrate that EIT improves both accuracy and robustness under adversarial biases, while preserving performance when bias aligns with truth. Notably, models trained only on bandwagon bias generalize to unseen bias types such as authority and distraction, indicating that EIT induces transferable epistemic independence rather than bias-specific heuristics. Code and data are available at https://anonymous.4open.science/r/bias-mitigation-with-rl-BC47.",
    "published": "2026-02-02T01:43:48Z",
    "updated": "2026-02-02T01:43:48Z",
    "authors": [
      "Qian Wang",
      "Xuandong Zhao",
      "Zirui Zhang",
      "Zhanzhi Lou",
      "Nuo Chen",
      "Dawn Song",
      "Bingsheng He"
    ],
    "primary_category": "cs.CY",
    "categories": [
      "cs.CY",
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01528v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01528v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 10.8,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02411v1",
    "title": "Multi-Agent Monte Carlo Tree Search for Makespan-Efficient Object Rearrangement in Cluttered Spaces",
    "summary": "Object rearrangement planning in complex, cluttered environments is a common challenge in warehouses, households, and rescue sites. Prior studies largely address monotone instances, whereas real-world tasks are often non-monotone-objects block one another and must be temporarily relocated to intermediate positions before reaching their final goals. In such settings, effective multi-agent collaboration can substantially reduce the time required to complete tasks. This paper introduces Centralized, Asynchronous, Multi-agent Monte Carlo Tree Search (CAM-MCTS), a novel framework for general-purpose makespan-efficient object rearrangement planning in challenging environments. CAM-MCTS combines centralized task assignment-where agents remain aware of each other's intended actions to facilitate globally optimized planning-with an asynchronous task execution strategy that enables agents to take on new tasks at appropriate time steps, rather than waiting for others, guided by a one-step look-ahead cost estimate. This design minimizes idle time, prevents unnecessary synchronization delays, and enhances overall system efficiency. We evaluate CAM-MCTS across a diverse set of monotone and non-monotone tasks in cluttered environments, demonstrating consistent reductions in makespan compared to strong baselines. Finally, we validate our approach on a real-world multi-agent system under different configurations, further confirming its effectiveness and robustness.",
    "published": "2026-02-02T18:10:45Z",
    "updated": "2026-02-02T18:10:45Z",
    "authors": [
      "Hanwen Ren",
      "Junyong Kim",
      "Aathman Tharmasanthiran",
      "Ahmed H. Qureshi"
    ],
    "primary_category": "cs.RO",
    "categories": [
      "cs.RO"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02411v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02411v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 9.6,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02206v1",
    "title": "Fat-Cat: Document-Driven Metacognitive Multi-Agent System for Complex Reasoning",
    "summary": "The effectiveness of LLM-based agents is often limited not by model capacity alone, but by how efficiently contextual information is utilized at runtime. Existing agent frameworks rely on rigid, syntax-heavy state representations such as nested JSON, which require models to devote a substantial portion of their limited attention to syntactic processing rather than semantic reasoning. In this paper, we propose Fat-Cat, a document-driven agent architecture that improves the signal-to-noise ratio of state management. By integrating three key components: (1) a Semantic File System that represents agent state as Markdown documents aligned with common pre-training corpora, (2) a Textual Strategy Evolution module that accumulates task-solving knowledge without parameter updates, and (3) a Closed-Loop Watcher that monitors reasoning trajectories to reduce hallucinations. Extensive reasoning, retrieval, and coding benchmarks, Fat-Cat consistently improves agent performance. It enables the Kimi-k2 model to outperform the proprietary GPT-4o baseline on HotPotQA. Replacing the document-based state with JSON leads to performance drop, while empirically validating the critical necessity of document-driven state modeling over rigid syntax. The code is available at https://github.com/answeryt/Fat-Cat.",
    "published": "2026-02-02T15:12:13Z",
    "updated": "2026-02-02T15:12:13Z",
    "authors": [
      "Tong Yang",
      "Yemin Wang",
      "Chaoning Zhang",
      "Aming Wu"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02206v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02206v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 9.6,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02170v1",
    "title": "Self-Evolving Coordination Protocol in Multi-Agent AI Systems: An Exploratory Systems Feasibility Study",
    "summary": "Contemporary multi-agent systems increasingly rely on internal coordination mechanisms to combine, arbitrate, or constrain the outputs of heterogeneous components. In safety-critical and regulated domains such as finance, these mechanisms must satisfy strict formal requirements, remain auditable, and operate within explicitly bounded limits. Coordination logic therefore functions as a governance layer rather than an optimization heuristic. This paper presents an exploratory systems feasibility study of Self-Evolving Coordination Protocols (SECP): coordination protocols that permit limited, externally validated self-modification while preserving fixed formal invariants. We study a controlled proof-of-concept setting in which six fixed Byzantine consensus protocol proposals are evaluated by six specialized decision modules. All coordination regimes operate under identical hard constraints, including Byzantine fault tolerance (f < n/3), O(n2) message complexity, complete non-statistical safety and liveness arguments, and bounded explainability. Four coordination regimes are compared in a single-shot design: unanimous hard veto, weighted scalar aggregation, SECP v1.0 (an agent-designed non-scalar protocol), and SECP v2.0 (the result of one governed modification). Outcomes are evaluated using a single metric, proposal coverage, defined as the number of proposals accepted. A single recursive modification increased coverage from two to three accepted proposals while preserving all declared invariants. The study makes no claims regarding statistical significance, optimality, convergence, or learning. Its contribution is architectural: it demonstrates that bounded self-modification of coordination protocols is technically implementable, auditable, and analyzable under explicit formal constraints, establishing a foundation for governed multi-agent systems.",
    "published": "2026-02-02T14:45:04Z",
    "updated": "2026-02-02T14:45:04Z",
    "authors": [
      "Jose Manuel de la Chica Rodriguez",
      "Juan Manuel Vera Daz"
    ],
    "primary_category": "cs.MA",
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02170v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02170v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 9.6,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02137v1",
    "title": "DCoPilot: Generative AI-Empowered Policy Adaptation for Dynamic Data Center Operations",
    "summary": "Modern data centers (DCs) hosting artificial intelligence (AI)-dedicated devices operate at high power densities with rapidly varying workloads, making minute-level adaptation essential for safe and energy-efficient operation. However, manually designing piecewise deep reinforcement learning (DRL) agents cannot keep pace with frequent dynamics shifts and service-level agreement (SLA) changes of an evolving DC. This specification-to-policy lag causes a lack of timely, effective control policies, which may lead to service outages. To bridge the gap, we present DCoPilot, a hybrid framework for generative control policies in dynamic DC operation. DCoPilot synergizes two distinct generative paradigms, i.e., a large language model (LLM) that performs symbolic generation of structured reward forms, and a hypernetwork that conducts parametric generation of policy weights. DCoPilot operates through three coordinated phases: (i) simulation scale-up, which stress-tests reward candidates across diverse simulation-ready (SimReady) scenes; (ii) meta policy distillation, where a hypernetwork is trained to output policy weights conditioned on SLA and scene embeddings; and (iii) online adaptation, enabling zero-shot policy generation in response to updated specifications. Evaluated across five control task families spanning diverse DC components, DCoPilot achieves near-zero constraint violations and outperforms all baselines across specification variations. Ablation studies validate the effectiveness of LLM-based unified reward generation in enabling stable hypernetwork convergence.",
    "published": "2026-02-02T14:18:52Z",
    "updated": "2026-02-02T14:18:52Z",
    "authors": [
      "Minghao Li",
      "Ruihang Wang",
      "Rui Tan",
      "Yonggang Wen"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SY"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02137v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02137v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 9.6,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01937v1",
    "title": "T-LLM: Teaching Large Language Models to Forecast Time Series via Temporal Distillation",
    "summary": "Time series forecasting plays a critical role in decision-making across many real-world applications. Unlike data in vision and language domains, time series data is inherently tied to the evolution of underlying processes and can only accumulate as real-world time progresses, limiting the effectiveness of scale-driven pretraining alone. This time-bound constraint poses a challenge for enabling large language models (LLMs) to acquire forecasting capability, as existing approaches primarily rely on representation-level alignment or inference-time temporal modules rather than explicitly teaching forecasting behavior to the LLM. We propose T-LLM, a temporal distillation framework that equips general-purpose LLMs with time series forecasting capability by transferring predictive behavior from a lightweight temporal teacher during training. The teacher combines trend modeling and frequency-domain analysis to provide structured temporal supervision, and is removed entirely at inference, leaving the LLM as the sole forecasting model. Experiments on benchmark datasets and infectious disease forecasting tasks demonstrate that T-LLM consistently outperforms existing LLM-based forecasting methods under full-shot, few-shot, and zero-shot settings, while enabling a simple and efficient deployment pipeline.",
    "published": "2026-02-02T10:40:27Z",
    "updated": "2026-02-02T10:40:27Z",
    "authors": [
      "Suhan Guo",
      "Bingxu Wang",
      "Shaodan Zhang",
      "Furao Shen"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01937v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01937v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 9.6,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01848v1",
    "title": "ROMA: Recursive Open Meta-Agent Framework for Long-Horizon Multi-Agent Systems",
    "summary": "Current agentic frameworks underperform on long-horizon tasks. As reasoning depth increases, sequential orchestration becomes brittle, context windows impose hard limits that degrade performance, and opaque execution traces make failures difficult to localize or debug. We introduce ROMA (Recursive Open Meta-Agents), a domain-agnostic framework that addresses these limitations through recursive task decomposition and structured aggregation. ROMA decomposes goals into dependency-aware subtask trees that can be executed in parallel, while aggregation compresses and validates intermediate results to control context growth. Our framework standardizes agent construction around four modular roles --Atomizer (which decides whether a task should be decomposed), Planner, Executor, and Aggregator -- which cleanly separate orchestration from model selection and enable transparent, hierarchical execution traces. This design supports heterogeneous multi-agent systems that mix models and tools according to cost, latency, and capability. To adapt ROMA to specific tasks without fine-tuning, we further introduce GEPA$+$, an improved Genetic-Pareto prompt proposer that searches over prompts within ROMA's component hierarchy while preserving interface contracts. We show that ROMA, combined with GEPA+, delivers leading system-level performance on reasoning and long-form generation benchmarks. On SEAL-0, which evaluates reasoning over conflicting web evidence, ROMA instantiated with GLM-4.6 improves accuracy by 9.9\\% over Kimi-Researcher. On EQ-Bench, a long-form writing benchmark, ROMA enables DeepSeek-V3 to match the performance of leading closed-source models such as Claude Sonnet 4.5. Our results demonstrate that recursive, modular agent architectures can scale reasoning depth while remaining interpretable, flexible, and model-agnostic.",
    "published": "2026-02-02T09:20:59Z",
    "updated": "2026-02-02T09:20:59Z",
    "authors": [
      "Salaheddin Alzu'bi",
      "Baran Nama",
      "Arda Kaz",
      "Anushri Eswaran",
      "Weiyuan Chen",
      "Sarvesh Khetan",
      "Rishab Bala",
      "Tu Vu",
      "Sewoong Oh"
    ],
    "primary_category": "cs.AI",
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01848v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01848v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 9.6,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01815v1",
    "title": "INDIBATOR: Diverse and Fact-Grounded Individuality for Multi-Agent Debate in Molecular Discovery",
    "summary": "Multi-agent systems have emerged as a powerful paradigm for automating scientific discovery. To differentiate agent behavior in the multi-agent system, current frameworks typically assign generic role-based personas such as ''reviewer'' or ''writer'' or rely on coarse grained keyword-based personas. While functional, this approach oversimplifies how human scientists operate, whose contributions are shaped by their unique research trajectories. In response, we propose INDIBATOR, a framework for molecular discovery that grounds agents in individualized scientist profiles constructed from two modalities: publication history for literature-derived knowledge and molecular history for structural priors. These agents engage in multi-turn debate through proposal, critique, and voting phases. Our evaluation demonstrates that these fine-grained individuality-grounded agents consistently outperform systems relying on coarse-grained personas, achieving competitive or state-of-the-art performance. These results validate that capturing the ``scientific DNA'' of individual agents is essential for high-quality discovery.",
    "published": "2026-02-02T08:47:36Z",
    "updated": "2026-02-02T08:47:36Z",
    "authors": [
      "Yunhui Jang",
      "Seonghyun Park",
      "Jaehyung Kim",
      "Sungsoo Ahn"
    ],
    "primary_category": "cs.AI",
    "categories": [
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01815v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01815v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 9.6,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01756v1",
    "title": "Mind-Brush: Integrating Agentic Cognitive Search and Reasoning into Image Generation",
    "summary": "While text-to-image generation has achieved unprecedented fidelity, the vast majority of existing models function fundamentally as static text-to-pixel decoders. Consequently, they often fail to grasp implicit user intentions. Although emerging unified understanding-generation models have improved intent comprehension, they still struggle to accomplish tasks involving complex knowledge reasoning within a single model. Moreover, constrained by static internal priors, these models remain unable to adapt to the evolving dynamics of the real world. To bridge these gaps, we introduce Mind-Brush, a unified agentic framework that transforms generation into a dynamic, knowledge-driven workflow. Simulating a human-like 'think-research-create' paradigm, Mind-Brush actively retrieves multimodal evidence to ground out-of-distribution concepts and employs reasoning tools to resolve implicit visual constraints. To rigorously evaluate these capabilities, we propose Mind-Bench, a comprehensive benchmark comprising 500 distinct samples spanning real-time news, emerging concepts, and domains such as mathematical and Geo-Reasoning. Extensive experiments demonstrate that Mind-Brush significantly enhances the capabilities of unified models, realizing a zero-to-one capability leap for the Qwen-Image baseline on Mind-Bench, while achieving superior results on established benchmarks like WISE and RISE.",
    "published": "2026-02-02T07:42:13Z",
    "updated": "2026-02-02T07:42:13Z",
    "authors": [
      "Jun He",
      "Junyan Ye",
      "Zilong Huang",
      "Dongzhi Jiang",
      "Chenjue Zhang",
      "Leqi Zhu",
      "Renrui Zhang",
      "Xiang Zhang",
      "Weijia Li"
    ],
    "primary_category": "cs.CV",
    "categories": [
      "cs.CV"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01756v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01756v1",
    "comment": "36 pages, 24 figures",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 9.6,
    "matched_areas": [
      "ai",
      "vision"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01539v1",
    "title": "MAGIC: A Co-Evolving Attacker-Defender Adversarial Game for Robust LLM Safety",
    "summary": "Ensuring robust safety alignment is crucial for Large Language Models (LLMs), yet existing defenses often lag behind evolving adversarial attacks due to their \\textbf{reliance on static, pre-collected data distributions}. In this paper, we introduce \\textbf{MAGIC}, a novel multi-turn multi-agent reinforcement learning framework that formulates LLM safety alignment as an adversarial asymmetric game. Specifically, an attacker agent learns to iteratively rewrite original queries into deceptive prompts, while a defender agent simultaneously optimizes its policy to recognize and refuse such inputs. This dynamic process triggers a \\textbf{co-evolution}, where the attacker's ever-changing strategies continuously uncover long-tail vulnerabilities, driving the defender to generalize to unseen attack patterns. Remarkably, we observe that the attacker, endowed with initial reasoning ability, evolves \\textbf{novel, previously unseen combinatorial strategies} through iterative RL training, underscoring our method's substantial potential. Theoretically, we provide insights into a more robust game equilibrium and derive safety guarantees. Extensive experiments validate our framework's effectiveness, demonstrating superior defense success rates without compromising the helpfulness of the model. Our code is available at https://github.com/BattleWen/MAGIC.",
    "published": "2026-02-02T02:12:28Z",
    "updated": "2026-02-02T02:12:28Z",
    "authors": [
      "Xiaoyu Wen",
      "Zhida He",
      "Han Qi",
      "Ziyu Wan",
      "Zhongtian Ma",
      "Ying Wen",
      "Tianhang Zheng",
      "Xingcheng Xu",
      "Chaochao Lu",
      "Qiaosheng Zhang"
    ],
    "primary_category": "cs.AI",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.MA"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01539v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01539v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 9.6,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01523v1",
    "title": "A Relative-Budget Theory for Reinforcement Learning with Verifiable Rewards in Large Language Model Reasoning",
    "summary": "Reinforcement learning (RL) is a dominant paradigm for improving the reasoning abilities of large language models, yet its effectiveness varies across tasks and compute budgets. We propose a \\emph{relative-budget} theory explaining this variation through a single quantity called relative budget $:= H/\\mathbb{E}[T]$, where $H$ is the generation horizon (token budget) and $T$ denotes the number of tokens until the first correct solution under a base policy. We show that $$ determines sample efficiency by controlling reward variance and the likelihood of informative trajectories. Our analysis reveals three regimes: in the \\emph{deficient} regime ($\\to 0$), informative trajectories are rare and the sample complexity explodes; in the \\emph{balanced} regime ($=(1)$), informative trajectories occur with non-negligible probability and RL is maximally sample-efficient; and in the \\emph{ample} regime ($\\to \\infty$), learning remains stable but marginal gains per iteration diminish. We further provide finite-sample guarantees for online RL that characterize learning progress across these regimes. Specifically, in a case study under idealized distributional assumptions, we show that the relative budget grows linearly over iterations. Our empirical results confirm these predictions in realistic settings, identifying a budget $\\in [1.5, 2.0]$ that maximizes learning efficiency and coincides with peak reasoning performance.",
    "published": "2026-02-02T01:31:52Z",
    "updated": "2026-02-02T01:31:52Z",
    "authors": [
      "Akifumi Wachi",
      "Hirota Kinoshita",
      "Shokichi Takakura",
      "Rei Higuchi",
      "Taiji Suzuki"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01523v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01523v1",
    "comment": "28 pages",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 9.6,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01493v1",
    "title": "OpInf-LLM: Parametric PDE Solving with LLMs via Operator Inference",
    "summary": "Solving diverse partial differential equations (PDEs) is fundamental in science and engineering. Large language models (LLMs) have demonstrated strong capabilities in code generation, symbolic reasoning, and tool use, but reliably solving PDEs across heterogeneous settings remains challenging. Prior work on LLM-based code generation and transformer-based foundation models for PDE learning has shown promising advances. However, a persistent trade-off between execution success rate and numerical accuracy arises, particularly when generalization to unseen parameters and boundary conditions is required. In this work, we propose OpInf-LLM, an LLM parametric PDE solving framework based on operator inference. The proposed framework leverages a small amount of solution data to enable accurate prediction of diverse PDE instances, including unseen parameters and configurations, and provides seamless integration with LLMs for natural language specification of PDE solving tasks. Its low computational demands and unified tool interface further enable a high execution success rate across heterogeneous settings. By combining operator inference with LLM capabilities, OpInf-LLM opens new possibilities for generalizable reduced-order modeling in LLM-based PDE solving.",
    "published": "2026-02-02T00:04:50Z",
    "updated": "2026-02-02T00:04:50Z",
    "authors": [
      "Zhuoyuan Wang",
      "Hanjiang Hu",
      "Xiyu Deng",
      "Saviz Mowlavi",
      "Yorie Nakahira"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01493v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01493v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 9.6,
    "matched_areas": [
      "ai",
      "agents"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02474v1",
    "title": "MemSkill: Learning and Evolving Memory Skills for Self-Evolving Agents",
    "summary": "Most Large Language Model (LLM) agent memory systems rely on a small set of static, hand-designed operations for extracting memory. These fixed procedures hard-code human priors about what to store and how to revise memory, making them rigid under diverse interaction patterns and inefficient on long histories. To this end, we present \\textbf{MemSkill}, which reframes these operations as learnable and evolvable memory skills, structured and reusable routines for extracting, consolidating, and pruning information from interaction traces. Inspired by the design philosophy of agent skills, MemSkill employs a \\emph{controller} that learns to select a small set of relevant skills, paired with an LLM-based \\emph{executor} that produces skill-guided memories. Beyond learning skill selection, MemSkill introduces a \\emph{designer} that periodically reviews hard cases where selected skills yield incorrect or incomplete memories, and evolves the skill set by proposing refinements and new skills. Together, MemSkill forms a closed-loop procedure that improves both the skill-selection policy and the skill set itself. Experiments on LoCoMo, LongMemEval, HotpotQA, and ALFWorld demonstrate that MemSkill improves task performance over strong baselines and generalizes well across settings. Further analyses shed light on how skills evolve, offering insights toward more adaptive, self-evolving memory management for LLM agents.",
    "published": "2026-02-02T18:53:28Z",
    "updated": "2026-02-02T18:53:28Z",
    "authors": [
      "Haozhen Zhang",
      "Quanyu Long",
      "Jianzhu Bao",
      "Tao Feng",
      "Weizhi Zhang",
      "Haodong Yue",
      "Wenya Wang"
    ],
    "primary_category": "cs.CL",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02474v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02474v1",
    "comment": "Code is available at https://github.com/ViktorAxelsen/MemSkill",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 8.4,
    "matched_areas": [
      "ai",
      "agents"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01966v1",
    "title": "Self-Consolidation for Self-Evolving Agents",
    "summary": "While large language model (LLM) agents have demonstrated impressive problem-solving capabilities, they typically operate as static systems, lacking the ability to evolve through lifelong interaction. Existing attempts to bridge this gap primarily rely on retrieving successful past trajectories as demonstrations. However, this paradigm faces two critical limitations. First, by focusing solely on success, agents overlook the rich pedagogical value embedded in failed attempts, preventing them from identifying and avoiding recurrent pitfalls. Second, continually accumulating textual experiences not only increases the time consumption during retrieval but also inevitably introduces noise and exhausts the largest context window of current LLMs. To address these challenges, we propose a novel self-evolving framework for LLM agents that introduces a complementary evolution mechanism: First, a contrastive reflection strategy is introduced to explicitly summarize error-prone patterns and capture reusable insights. Second, we propose a self-consolidation mechanism that distills non-parametric textual experience into compact learnable parameters. This enables the agent to internalize extensive historical experience directly into its latent space. Extensive experiments demonstrate the advantages of our method in long-term agent evolution.",
    "published": "2026-02-02T11:16:07Z",
    "updated": "2026-02-02T11:16:07Z",
    "authors": [
      "Hongzhuo Yu",
      "Fei Zhu",
      "Guo-Sen Xie",
      "Ling Shao"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01966v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01966v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 8.4,
    "matched_areas": [
      "ai",
      "agents"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01556v1",
    "title": "Autonomous Question Formation for Large Language Model-Driven AI Systems",
    "summary": "Large language model (LLM)-driven AI systems are increasingly important for autonomous decision-making in dynamic and open environments. However, most existing systems rely on predefined tasks and fixed prompts, limiting their ability to autonomously identify what problems should be solved when environmental conditions change. In this paper, we propose a human-simulation-based framework that enables AI systems to autonomously form questions and set tasks by reasoning over their internal states, environmental observations, and interactions with other AI systems. The proposed method treats question formation as a first-class decision process preceding task selection and execution, and integrates internal-driven, environment-aware, and inter-agent-aware prompting scopes to progressively expand cognitive coverage. In addition, the framework supports learning the question-formation process from experience, allowing the system to improve its adaptability and decision quality over time. xperimental results in a multi-agent simulation environment show that environment-aware prompting significantly reduces no-eat events compared with the internal-driven baseline, and inter-agent-aware prompting further reduces cumulative no-eat events by more than 60% over a 20-day simulation, with statistically significant improvements (p < 0.05).",
    "published": "2026-02-02T02:49:35Z",
    "updated": "2026-02-02T02:49:35Z",
    "authors": [
      "Hong Su"
    ],
    "primary_category": "cs.AI",
    "categories": [
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01556v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01556v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 8.4,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01511v1",
    "title": "Alternating Reinforcement Learning for Rubric-Based Reward Modeling in Non-Verifiable LLM Post-Training",
    "summary": "Standard reward models typically predict scalar scores that fail to capture the multifaceted nature of response quality in non-verifiable domains, such as creative writing or open-ended instruction following. To address this limitation, we propose Rubric-ARM, a framework that jointly optimizes a rubric generator and a judge using reinforcement learning from preference feedback. Unlike existing methods that rely on static rubrics or disjoint training pipelines, our approach treats rubric generation as a latent action learned to maximize judgment accuracy. We introduce an alternating optimization strategy to mitigate the non-stationarity of simultaneous updates, providing theoretical analysis that demonstrates how this schedule reduces gradient variance during training. Extensive experiments show that Rubric-ARM achieves state-of-the-art performance among baselines on multiple benchmarks and significantly improves downstream policy alignment in both offline and online reinforcement learning settings.",
    "published": "2026-02-02T00:50:53Z",
    "updated": "2026-02-02T00:50:53Z",
    "authors": [
      "Ran Xu",
      "Tianci Liu",
      "Zihan Dong",
      "Tony You",
      "Ilgee Hong",
      "Carl Yang",
      "Linjun Zhang",
      "Tao Zhao",
      "Haoyu Wang"
    ],
    "primary_category": "cs.CL",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01511v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01511v1",
    "comment": "The first two authors contributed equally",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 8.4,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02369v1",
    "title": "Live-Evo: Online Evolution of Agentic Memory from Continuous Feedback",
    "summary": "Large language model (LLM) agents are increasingly equipped with memory, which are stored experience and reusable guidance that can improve task-solving performance. Recent \\emph{self-evolving} systems update memory based on interaction outcomes, but most existing evolution pipelines are developed for static train/test splits and only approximate online learning by folding static benchmarks, making them brittle under true distribution shift and continuous feedback. We introduce \\textsc{Live-Evo}, an online self-evolving memory system that learns from a stream of incoming data over time. \\textsc{Live-Evo} decouples \\emph{what happened} from \\emph{how to use it} via an Experience Bank and a Meta-Guideline Bank, compiling task-adaptive guidelines from retrieved experiences for each task. To manage memory online, \\textsc{Live-Evo} maintains experience weights and updates them from feedback: experiences that consistently help are reinforced and retrieved more often, while misleading or stale experiences are down-weighted and gradually forgotten, analogous to reinforcement and decay in human memory. On the live \\textit{Prophet Arena} benchmark over a 10-week horizon, \\textsc{Live-Evo} improves Brier score by 20.8\\% and increases market returns by 12.9\\%, while also transferring to deep-research benchmarks with consistent gains over strong baselines. Our code is available at https://github.com/ag2ai/Live-Evo.",
    "published": "2026-02-02T17:34:50Z",
    "updated": "2026-02-02T17:34:50Z",
    "authors": [
      "Yaolun Zhang",
      "Yiran Wu",
      "Yijiong Yu",
      "Qingyun Wu",
      "Huazheng Wang"
    ],
    "primary_category": "cs.AI",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02369v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02369v1",
    "comment": "13 pages",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 7.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02295v1",
    "title": "EvalQReason: A Framework for Step-Level Reasoning Evaluation in Large Language Models",
    "summary": "Large Language Models (LLMs) are increasingly deployed in critical applications requiring reliable reasoning, yet their internal reasoning processes remain difficult to evaluate systematically. Existing methods focus on final-answer correctness, providing limited insight into how reasoning unfolds across intermediate steps. We present EvalQReason, a framework that quantifies LLM reasoning quality through step-level probability distribution analysis without requiring human annotation. The framework introduces two complementary algorithms: Consecutive Step Divergence (CSD), which measures local coherence between adjacent reasoning steps, and Step-to-Final Convergence (SFC), which assesses global alignment with final answers. Each algorithm employs five statistical metrics to capture reasoning dynamics. Experiments across mathematical and medical datasets with open-source 7B-parameter models demonstrate that CSD-based features achieve strong predictive performance for correctness classification, with classical machine learning models reaching F1=0.78 and ROC-AUC=0.82, and sequential neural models substantially improving performance (F1=0.88, ROC-AUC=0.97). CSD consistently outperforms SFC, and sequential architectures outperform classical machine learning approaches. Critically, reasoning dynamics prove domain-specific: mathematical reasoning exhibits clear divergence-based discrimination patterns between correct and incorrect solutions, while medical reasoning shows minimal discriminative signals, revealing fundamental differences in how LLMs process different reasoning types. EvalQReason enables scalable, process-aware evaluation of reasoning reliability, establishing probability-based divergence analysis as a principled approach for trustworthy AI deployment.",
    "published": "2026-02-02T16:32:40Z",
    "updated": "2026-02-02T16:32:40Z",
    "authors": [
      "Shaima Ahmad Freja",
      "Ferhat Ozgur Catak",
      "Betul Yurdem",
      "Chunming Rong"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02295v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02295v1",
    "comment": "15 pages (including appendix), 11 figures",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 7.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02192v1",
    "title": "ECHO-2: A Large Scale Distributed Rollout Framework for Cost-efficient Reinforcement Learning",
    "summary": "Reinforcement learning (RL) is a critical stage in post-training large language models (LLMs), involving repeated interaction between rollout generation, reward evaluation, and centralized learning. Distributing rollout execution offers opportunities to leverage more cost-efficient inference resources, but introduces challenges in wide-area coordination and policy dissemination. We present ECHO-2, a distributed RL framework for post-training with remote inference workers and non-negligible dissemination latency. ECHO-2 combines centralized learning with distributed rollouts and treats bounded policy staleness as a user-controlled parameter, enabling rollout generation, dissemination, and training to overlap. We introduce an overlap-based capacity model that relates training time, dissemination latency, and rollout throughput, yielding a practical provisioning rule for sustaining learner utilization. To mitigate dissemination bottlenecks and lower cost, ECHO-2 employs peer-assisted pipelined broadcast and cost-aware activation of heterogeneous workers. Experiments on GRPO post-training of 4B and 8B models under real wide-area bandwidth regimes show that ECHO-2 significantly improves cost efficiency while preserving RL reward comparable to strong baselines.",
    "published": "2026-02-02T14:57:53Z",
    "updated": "2026-02-02T14:57:53Z",
    "authors": [
      "Jie Xiao",
      "Meng Chen",
      "Qingnan Ren",
      "Song Jingwei",
      "Jiaqi Huang",
      "Yangshen Deng",
      "Chris Tong",
      "Wanyi Chen",
      "Suli Wang",
      "Ziqian Bi",
      "Shuo Lu",
      "Yiqun Duan",
      "Lynn Ai",
      "Eric Yang",
      "Bill Shi"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "cs.DC"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02192v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02192v1",
    "comment": "23 pages, 7 figures",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 7.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02171v1",
    "title": "Lung Nodule Image Synthesis Driven by Two-Stage Generative Adversarial Networks",
    "summary": "The limited sample size and insufficient diversity of lung nodule CT datasets severely restrict the performance and generalization ability of detection models. Existing methods generate images with insufficient diversity and controllability, suffering from issues such as monotonous texture features and distorted anatomical structures. Therefore, we propose a two-stage generative adversarial network (TSGAN) to enhance the diversity and spatial controllability of synthetic data by decoupling the morphological structure and texture features of lung nodules. In the first stage, StyleGAN is used to generate semantic segmentation mask images, encoding lung nodules and tissue backgrounds to control the anatomical structure of lung nodule images; The second stage uses the DL-Pix2Pix model to translate the mask map into CT images, employing local importance attention to capture local features, while utilizing dynamic weight multi-head window attention to enhance the modeling capability of lung nodule texture and background. Compared to the original dataset, the accuracy improved by 4.6% and mAP by 4% on the LUNA16 dataset. Experimental results demonstrate that TSGAN can enhance the quality of synthetic images and the performance of detection models.",
    "published": "2026-02-02T14:45:11Z",
    "updated": "2026-02-02T14:45:11Z",
    "authors": [
      "Lu Cao",
      "Xiquan He",
      "Junying Zeng",
      "Chaoyun Mai",
      "Min Luo"
    ],
    "primary_category": "cs.CV",
    "categories": [
      "cs.CV"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02171v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02171v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 7.2,
    "matched_areas": [
      "vision"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02051v1",
    "title": "SIDiffAgent: Self-Improving Diffusion Agent",
    "summary": "Text-to-image diffusion models have revolutionized generative AI, enabling high-quality and photorealistic image synthesis. However, their practical deployment remains hindered by several limitations: sensitivity to prompt phrasing, ambiguity in semantic interpretation (e.g., ``mouse\" as animal vs. a computer peripheral), artifacts such as distorted anatomy, and the need for carefully engineered input prompts. Existing methods often require additional training and offer limited controllability, restricting their adaptability in real-world applications. We introduce Self-Improving Diffusion Agent (SIDiffAgent), a training-free agentic framework that leverages the Qwen family of models (Qwen-VL, Qwen-Image, Qwen-Edit, Qwen-Embedding) to address these challenges. SIDiffAgent autonomously manages prompt engineering, detects and corrects poor generations, and performs fine-grained artifact removal, yielding more reliable and consistent outputs. It further incorporates iterative self-improvement by storing a memory of previous experiences in a database. This database of past experiences is then used to inject prompt-based guidance at each stage of the agentic pipeline. \\modelour achieved an average VQA score of 0.884 on GenAIBench, significantly outperforming open-source, proprietary models and agentic methods. We will publicly release our code upon acceptance.",
    "published": "2026-02-02T12:53:21Z",
    "updated": "2026-02-02T12:53:21Z",
    "authors": [
      "Shivank Garg",
      "Ayush Singh",
      "Gaurav Kumar Nayak"
    ],
    "primary_category": "cs.AI",
    "categories": [
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02051v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02051v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 7.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02039v1",
    "title": "Hunt Instead of Wait: Evaluating Deep Data Research on Large Language Models",
    "summary": "The agency expected of Agentic Large Language Models goes beyond answering correctly, requiring autonomy to set goals and decide what to explore. We term this investigatory intelligence, distinguishing it from executional intelligence, which merely completes assigned tasks. Data Science provides a natural testbed, as real-world analysis starts from raw data rather than explicit queries, yet few benchmarks focus on it. To address this, we introduce Deep Data Research (DDR), an open-ended task where LLMs autonomously extract key insights from databases, and DDR-Bench, a large-scale, checklist-based benchmark that enables verifiable evaluation. Results show that while frontier models display emerging agency, long-horizon exploration remains challenging. Our analysis highlights that effective investigatory intelligence depends not only on agent scaffolding or merely scaling, but also on intrinsic strategies of agentic models.",
    "published": "2026-02-02T12:36:57Z",
    "updated": "2026-02-02T12:36:57Z",
    "authors": [
      "Wei Liu",
      "Peijie Yu",
      "Michele Orini",
      "Yali Du",
      "Yulan He"
    ],
    "primary_category": "cs.AI",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.DB",
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02039v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02039v1",
    "comment": "14 pages, 7 tables, 8 figures",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 7.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02033v1",
    "title": "One Size, Many Fits: Aligning Diverse Group-Wise Click Preferences in Large-Scale Advertising Image Generation",
    "summary": "Advertising image generation has increasingly focused on online metrics like Click-Through Rate (CTR), yet existing approaches adopt a ``one-size-fits-all\" strategy that optimizes for overall CTR while neglecting preference diversity among user groups. This leads to suboptimal performance for specific groups, limiting targeted marketing effectiveness. To bridge this gap, we present \\textit{One Size, Many Fits} (OSMF), a unified framework that aligns diverse group-wise click preferences in large-scale advertising image generation. OSMF begins with product-aware adaptive grouping, which dynamically organizes users based on their attributes and product characteristics, representing each group with rich collective preference features. Building on these groups, preference-conditioned image generation employs a Group-aware Multimodal Large Language Model (G-MLLM) to generate tailored images for each group. The G-MLLM is pre-trained to simultaneously comprehend group features and generate advertising images. Subsequently, we fine-tune the G-MLLM using our proposed Group-DPO for group-wise preference alignment, which effectively enhances each group's CTR on the generated images. To further advance this field, we introduce the Grouped Advertising Image Preference Dataset (GAIP), the first large-scale public dataset of group-wise image preferences, including around 600K groups built from 40M users. Extensive experiments demonstrate that our framework achieves the state-of-the-art performance in both offline and online settings. Our code and datasets will be released at https://github.com/JD-GenX/OSMF.",
    "published": "2026-02-02T12:30:53Z",
    "updated": "2026-02-02T12:30:53Z",
    "authors": [
      "Shuo Lu",
      "Haohan Wang",
      "Wei Feng",
      "Weizhen Wang",
      "Shen Zhang",
      "Yaoyu Li",
      "Ao Ma",
      "Zheng Zhang",
      "Jingjing Lv",
      "Junjie Shen",
      "Ching Law",
      "Bing Zhan",
      "Yuan Xu",
      "Huizai Yao",
      "Yongcan Yu",
      "Chenyang Si",
      "Jian Liang"
    ],
    "primary_category": "cs.CV",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02033v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02033v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 7.2,
    "matched_areas": [
      "ai",
      "vision"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02029v1",
    "title": "Canonical Intermediate Representation for LLM-based optimization problem formulation and code generation",
    "summary": "Automatically formulating optimization models from natural language descriptions is a growing focus in operations research, yet current LLM-based approaches struggle with the composite constraints and appropriate modeling paradigms required by complex operational rules. To address this, we introduce the Canonical Intermediate Representation (CIR): a schema that LLMs explicitly generate between problem descriptions and optimization models. CIR encodes the semantics of operational rules through constraint archetypes and candidate modeling paradigms, thereby decoupling rule logic from its mathematical instantiation. Upon a newly generated CIR knowledge base, we develop the rule-to-constraint (R2C) framework, a multi-agent pipeline that parses problem texts, synthesizes CIR implementations by retrieving domain knowledge, and instantiates optimization models. To systematically evaluate rule-to-constraint reasoning, we test R2C on our newly constructed benchmark featuring rich operational rules, and benchmarks from prior work. Extensive experiments show that R2C achieves state-of-the-art accuracy on the proposed benchmark (47.2% Accuracy Rate). On established benchmarks from the literature, R2C delivers highly competitive results, approaching the performance of proprietary models (e.g., GPT-5). Moreover, with a reflection mechanism, R2C achieves further gains and sets new best-reported results on some benchmarks.",
    "published": "2026-02-02T12:26:27Z",
    "updated": "2026-02-02T12:26:27Z",
    "authors": [
      "Zhongyuan Lyu",
      "Shuoyu Hu",
      "Lujie Liu",
      "Hongxia Yang",
      "Ming LI"
    ],
    "primary_category": "cs.AI",
    "categories": [
      "cs.AI",
      "cs.SE"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02029v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02029v1",
    "comment": "41 pages, 4 figures, 5 tables",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 7.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02025v1",
    "title": "Hippasus: Effective and Efficient Automatic Feature Augmentation for Machine Learning Tasks on Relational Data",
    "summary": "Machine learning models depend critically on feature quality, yet useful features are often scattered across multiple relational tables. Feature augmentation enriches a base table by discovering and integrating features from related tables through join operations. However, scaling this process to complex schemas with many tables and multi-hop paths remains challenging. Feature augmentation must address three core tasks: identify promising join paths that connect the base table to candidate tables, execute these joins to materialize augmented data, and select the most informative features from the results. Existing approaches face a fundamental tradeoff between effectiveness and efficiency: achieving high accuracy requires exploring many candidate paths, but exhaustive exploration is computationally prohibitive. Some methods compromise by considering only immediate neighbors, limiting their effectiveness, while others employ neural models that require expensive training data and introduce scalability limitations. We present Hippasus, a modular framework that achieves both goals through three key contributions. First, we combine lightweight statistical signals with semantic reasoning from Large Language Models to prune unpromising join paths before execution, focusing computational resources on high-quality candidates. Second, we employ optimized multi-way join algorithms and consolidate features from multiple paths, substantially reducing execution time. Third, we integrate LLM-based semantic understanding with statistical measures to select features that are both semantically meaningful and empirically predictive. Our experimental evaluation on publicly available datasets shows that Hippasus substantially improves feature augmentation accuracy by up to 26.8% over state-of-the-art baselines while also offering high runtime performance.",
    "published": "2026-02-02T12:21:24Z",
    "updated": "2026-02-02T12:21:24Z",
    "authors": [
      "Serafeim Papadias",
      "Kostas Patroumpas",
      "Dimitrios Skoutas"
    ],
    "primary_category": "cs.DB",
    "categories": [
      "cs.DB",
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02025v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02025v1",
    "comment": "13 pages, 7 figures, 9 tables",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 7.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01992v1",
    "title": "Emergent Analogical Reasoning in Transformers",
    "summary": "Analogy is a central faculty of human intelligence, enabling abstract patterns discovered in one domain to be applied to another. Despite its central role in cognition, the mechanisms by which Transformers acquire and implement analogical reasoning remain poorly understood. In this work, inspired by the notion of functors in category theory, we formalize analogical reasoning as the inference of correspondences between entities across categories. Based on this formulation, we introduce synthetic tasks that evaluate the emergence of analogical reasoning under controlled settings. We find that the emergence of analogical reasoning is highly sensitive to data characteristics, optimization choices, and model scale. Through mechanistic analysis, we show that analogical reasoning in Transformers decomposes into two key components: (1) geometric alignment of relational structure in the embedding space, and (2) the application of a functor within the Transformer. These mechanisms enable models to transfer relational structure from one category to another, realizing analogy. Finally, we quantify these effects and find that the same trends are observed in pretrained LLMs. In doing so, we move analogy from an abstract cognitive notion to a concrete, mechanistically grounded phenomenon in modern neural networks.",
    "published": "2026-02-02T11:49:36Z",
    "updated": "2026-02-02T11:49:36Z",
    "authors": [
      "Gouki Minegishi",
      "Jingyuan Feng",
      "Hiroki Furuta",
      "Takeshi Kojima",
      "Yusuke Iwasawa",
      "Yutaka Matsuo"
    ],
    "primary_category": "cs.AI",
    "categories": [
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01992v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01992v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 7.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01983v1",
    "title": "Evolving from Tool User to Creator via Training-Free Experience Reuse in Multimodal Reasoning",
    "summary": "Existing Tool-Integrated Reasoning (TIR) models have effectively extended the question-answering capabilities of LLMs by incorporating external tools. However, real-world scenarios present numerous open-ended problems where fixed tools often fail to meet task requirements. Furthermore, the lack of self-optimization mechanisms means that erroneous tool outputs can mislead the LLM's responses. Additionally, the construction of existing tools entails significant manual effort, which consequently constrains their applicability. Recognizing that the reasoning traces of LLMs encapsulate implicit problem-solving capabilities, we propose UCT, a novel training-free framework that transforms agents from tool users to tool creators. This approach harvests reasoning experiences and distills them into reusable assets. This method transforms the agent from a mere tool user into a tool creator, enabling adaptive tool creation and self-updating during the inference process. We also introduce a memory consolidation mechanism to maintain the tool library, ensuring high reusability of retained experiential memory for subsequent reasoning tasks. This novel automated tool construction paradigm continuously improves tool quality during reasoning, allowing the overall agent system to progress without additional training. Extensive experiments demonstrate that our method serves as a novel paradigm for enhancing the capabilities of TIR models. In particular, the significant performance gains achieved +20.86%$\\uparrow$ and +23.04%$\\uparrow$ on benchmarks across multi-domain mathematical and scientific reasoning tasks validate the self-evolving capability of the agent.",
    "published": "2026-02-02T11:37:45Z",
    "updated": "2026-02-02T11:37:45Z",
    "authors": [
      "Xintian Shen",
      "Jiawei Chen",
      "Lihao Zheng",
      "Hao Ma",
      "Tao Wei",
      "Kun Zhan"
    ],
    "primary_category": "cs.AI",
    "categories": [
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01983v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01983v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 7.2,
    "matched_areas": [
      "ai",
      "agents"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01975v1",
    "title": "IntraSlice: Towards High-Performance Structural Pruning with Block-Intra PCA for LLMs",
    "summary": "Large Language Models (LLMs) achieve strong performance across diverse tasks but face deployment challenges due to their massive size. Structured pruning offers acceleration benefits but leads to significant performance degradation. Recent PCA-based pruning methods have alleviated this issue by retaining key activation components, but are only applied between modules in order to fuse the transformation matrix, which introduces extra parameters and severely disrupts activation distributions due to residual connections. To address these issues, we propose IntraSlice, a framework that applies block-wise module-intra PCA compression pruning. By leveraging the structural characteristics of Transformer modules, we design an approximate PCA method whose transformation matrices can be fully fused into the model without additional parameters. We also introduce a PCA-based global pruning ratio estimator that further considers the distribution of compressed activations, building on conventional module importance. We validate our method on Llama2, Llama3, and Phi series across various language benchmarks. Experimental results demonstrate that our approach achieves superior compression performance compared to recent baselines at the same compression ratio or inference speed.",
    "published": "2026-02-02T11:28:56Z",
    "updated": "2026-02-02T11:28:56Z",
    "authors": [
      "Meng Li",
      "Peisong Wang",
      "Yuantian Shao",
      "Qinghao Hu",
      "Hongjian Fang",
      "Yifan Zhang",
      "Zhihui Wei",
      "Jian Cheng"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01975v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01975v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 7.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01935v1",
    "title": "COLT: Lightweight Multi-LLM Collaboration through Shared MCTS Reasoning for Model Compilation",
    "summary": "Model serving costs dominate AI systems, making compiler optimization essential for scalable deployment. Recent works show that a large language model (LLM) can guide compiler search by reasoning over program structure and optimization history. However, using a single large model throughout the search is expensive, while smaller models are less reliable when used alone. Thus, this paper seeks to answer whether multi-LLM collaborative reasoning relying primarily on small LLMs can match or exceed the performance of a single large model. As such, we propose a lightweight collaborative multi-LLM framework, dubbed COLT, for compiler optimization that enables coordinated reasoning across multiple models within a single Monte Carlo tree search (MCTS) process. A key contribution is the use of a single shared MCTS tree as the collaboration substrate across LLMs, enabling the reuse of transformation prefixes and cross-model value propagation. Hence, we circumvent both heavy internal reasoning mechanisms and conventional agentic machinery that relies on external planners, multiple concurrent LLMs, databases, external memory/versioning of intermediate results, and controllers by simply endogenizing model selection within the lightweight MCTS optimization loop. Every iteration, the acting LLM proposes a joint action: (compiler transformation, model to be queried next). We also introduce a model-aware tree policy that biases search toward smaller models while preserving exploration, and a course-alteration mechanism that escalates to the largest model when the search exhibits persistent regressions attributable to smaller models.",
    "published": "2026-02-02T10:37:05Z",
    "updated": "2026-02-02T10:37:05Z",
    "authors": [
      "Annabelle Sujun Tang",
      "Christopher Priebe",
      "Lianhui Qin",
      "Hadi Esmaeilzadeh"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.PL"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01935v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01935v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 7.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01885v1",
    "title": "ES-MemEval: Benchmarking Conversational Agents on Personalized Long-Term Emotional Support",
    "summary": "Large Language Models (LLMs) have shown strong potential as conversational agents. Yet, their effectiveness remains limited by deficiencies in robust long-term memory, particularly in complex, long-term web-based services such as online emotional support. However, existing long-term dialogue benchmarks primarily focus on static and explicit fact retrieval, failing to evaluate agents in critical scenarios where user information is dispersed, implicit, and continuously evolving. To address this gap, we introduce ES-MemEval, a comprehensive benchmark that systematically evaluates five core memory capabilities: information extraction, temporal reasoning, conflict detection, abstention, and user modeling, in long-term emotional support settings, covering question answering, summarization, and dialogue generation tasks. To support the benchmark, we also propose EvoEmo, a multi-session dataset for personalized long-term emotional support that captures fragmented, implicit user disclosures and evolving user states. Extensive experiments on open-source long-context, commercial, and retrieval-augmented (RAG) LLMs show that explicit long-term memory is essential for reducing hallucinations and enabling effective personalization. At the same time, RAG improves factual consistency but struggles with temporal dynamics and evolving user states. These findings highlight both the potential and limitations of current paradigms and motivate more robust integration of memory and retrieval for long-term personalized dialogue systems.",
    "published": "2026-02-02T09:58:26Z",
    "updated": "2026-02-02T09:58:26Z",
    "authors": [
      "Tiantian Chen",
      "Jiaqi Lu",
      "Ying Shen",
      "Lin Zhang"
    ],
    "primary_category": "cs.CL",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01885v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01885v1",
    "comment": "12 pages, 7 figures. Accepted to The Web Conference (WWW) 2026",
    "journal_ref": null,
    "doi": "10.1145/3774904.3792143",
    "relevance_score": 7.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01865v1",
    "title": "GRAB: An LLM-Inspired Sequence-First Click-Through Rate Prediction Modeling Paradigm",
    "summary": "Traditional Deep Learning Recommendation Models (DLRMs) face increasing bottlenecks in performance and efficiency, often struggling with generalization and long-sequence modeling. Inspired by the scaling success of Large Language Models (LLMs), we propose Generative Ranking for Ads at Baidu (GRAB), an end-to-end generative framework for Click-Through Rate (CTR) prediction. GRAB integrates a novel Causal Action-aware Multi-channel Attention (CamA) mechanism to effectively capture temporal dynamics and specific action signals within user behavior sequences. Full-scale online deployment demonstrates that GRAB significantly outperforms established DLRMs, delivering a 3.05% increase in revenue and a 3.49% rise in CTR. Furthermore, the model demonstrates desirable scaling behavior: its expressive power shows a monotonic and approximately linear improvement as longer interaction sequences are utilized.",
    "published": "2026-02-02T09:38:03Z",
    "updated": "2026-02-02T09:38:03Z",
    "authors": [
      "Shaopeng Chen",
      "Chuyue Xie",
      "Huimin Ren",
      "Shaozong Zhang",
      "Han Zhang",
      "Ruobing Cheng",
      "Zhiqiang Cao",
      "Zehao Ju",
      "Gao Yu",
      "Jie Ding",
      "Xiaodong Chen",
      "Xuewu Jiao",
      "Shuanglong Li",
      "Liu Lin"
    ],
    "primary_category": "cs.IR",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01865v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01865v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 7.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01766v1",
    "title": "CoMeT: Collaborative Memory Transformer for Efficient Long Context Modeling",
    "summary": "The quadratic complexity and indefinitely growing key-value (KV) cache of standard Transformers pose a major barrier to long-context processing. To overcome this, we introduce the Collaborative Memory Transformer (CoMeT), a novel architecture that enables LLMs to handle arbitrarily long sequences with constant memory usage and linear time complexity. Designed as an efficient, plug-in module, CoMeT can be integrated into pre-trained models with only minimal fine-tuning. It operates on sequential data chunks, using a dual-memory system to manage context: a temporary memory on a FIFO queue for recent events, and a global memory with a gated update rule for long-range dependencies. These memories then act as a dynamic soft prompt for the next chunk. To enable efficient fine-tuning on extremely long contexts, we introduce a novel layer-level pipeline parallelism strategy. The effectiveness of our approach is remarkable: a model equipped with CoMeT and fine-tuned on 32k contexts can accurately retrieve a passkey from any position within a 1M token sequence. On the SCROLLS benchmark, CoMeT surpasses other efficient methods and achieves performance comparable to a full-attention baseline on summarization tasks. Its practical effectiveness is further validated on real-world agent and user behavior QA tasks. The code is available at: https://anonymous.4open.science/r/comet-B00B/",
    "published": "2026-02-02T07:49:44Z",
    "updated": "2026-02-02T07:49:44Z",
    "authors": [
      "Runsong Zhao",
      "Shilei Liu",
      "Jiwei Tang",
      "Langming Liu",
      "Haibin Chen",
      "Weidong Zhang",
      "Yujin Yuan",
      "Tong Xiao",
      "Jingbo Zhu",
      "Wenbo Su",
      "Bo Zheng"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01766v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01766v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 7.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01711v1",
    "title": "Optimizing Prompts for Large Language Models: A Causal Approach",
    "summary": "Large Language Models (LLMs) are increasingly embedded in enterprise workflows, yet their performance remains highly sensitive to prompt design. Automatic Prompt Optimization (APO) seeks to mitigate this instability, but existing approaches face two persistent challenges. First, commonly used prompt strategies rely on static instructions that perform well on average but fail to adapt to heterogeneous queries. Second, more dynamic approaches depend on offline reward models that are fundamentally correlational, confounding prompt effectiveness with query characteristics. We propose Causal Prompt Optimization (CPO), a framework that reframes prompt design as a problem of causal estimation. CPO operates in two stages. First, it learns an offline causal reward model by applying Double Machine Learning (DML) to semantic embeddings of prompts and queries, isolating the causal effect of prompt variations from confounding query attributes. Second, it utilizes this unbiased reward signal to guide a resource-efficient search for query-specific prompts without relying on costly online evaluation. We evaluate CPO across benchmarks in mathematical reasoning, visualization, and data analytics. CPO consistently outperforms human-engineered prompts and state-of-the-art automated optimizers. The gains are driven primarily by improved robustness on hard queries, where existing methods tend to deteriorate. Beyond performance, CPO fundamentally reshapes the economics of prompt optimization: by shifting evaluation from real-time model execution to an offline causal model, it enables high-precision, per-query customization at a fraction of the inference cost required by online methods. Together, these results establish causal inference as a scalable foundation for reliable and cost-efficient prompt optimization in enterprise LLM deployments.",
    "published": "2026-02-02T06:37:11Z",
    "updated": "2026-02-02T06:37:11Z",
    "authors": [
      "Wei Chen",
      "Yanbin Fang",
      "Shuran Fu",
      "Fasheng Xu",
      "Xuan Wei"
    ],
    "primary_category": "cs.AI",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01711v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01711v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 7.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01685v1",
    "title": "Semantic-aware Wasserstein Policy Regularization for Large Language Model Alignment",
    "summary": "Large language models (LLMs) are commonly aligned with human preferences using reinforcement learning from human feedback (RLHF). In this method, LLM policies are generally optimized through reward maximization with Kullback-Leibler (KL) divergence regularization of the reference policy. However, KL and its $f$-divergence variants only compare token probabilities at identical indices, failing to capture semantic similarity. We propose Wasserstein Policy Regularization (WPR), a semantic-aware regularization for the RLHF framework based on the entropy-regularized Wasserstein distance, which incorporates the geometry of the token space. The dual formulation of the distance expresses the regularization as penalty terms applied to the reward via optimal dual variables, which yield a tractable objective compatible with standard RL algorithms. Empirically, our method outperforms KL- and $f$-divergence-based baselines, demonstrating the benefits of semantic-aware policy distances for alignment. Our code is available at https://github.com/aailab-kaist/WPR.",
    "published": "2026-02-02T05:56:16Z",
    "updated": "2026-02-02T05:56:16Z",
    "authors": [
      "Byeonghu Na",
      "Hyungho Na",
      "Yeongmin Kim",
      "Suhyeon Jo",
      "HeeSun Bae",
      "Mina Kang",
      "Il-Chul Moon"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01685v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01685v1",
    "comment": "Accepted at ICLR 2026",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 7.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01684v1",
    "title": "The Strategic Foresight of LLMs: Evidence from a Fully Prospective Venture Tournament",
    "summary": "Can artificial intelligence outperform humans at strategic foresight -- the capacity to form accurate judgments about uncertain, high-stakes outcomes before they unfold? We address this question through a fully prospective prediction tournament using live Kickstarter crowdfunding projects. Thirty U.S.-based technology ventures, launched after the training cutoffs of all models studied, were evaluated while fundraising remained in progress and outcomes were unknown. A diverse suite of frontier and open-weight large language models (LLMs) completed 870 pairwise comparisons, producing complete rankings of predicted fundraising success. We benchmarked these forecasts against 346 experienced managers recruited via Prolific and three MBA-trained investors working under monitored conditions. The results are striking: human evaluators achieved rank correlations with actual outcomes between 0.04 and 0.45, while several frontier LLMs exceeded 0.60, with the best (Gemini 2.5 Pro) reaching 0.74 -- correctly ordering nearly four of every five venture pairs. These differences persist across multiple performance metrics and robustness checks. Neither wisdom-of-the-crowd ensembles nor human-AI hybrid teams outperformed the best standalone model.",
    "published": "2026-02-02T05:52:16Z",
    "updated": "2026-02-02T05:52:16Z",
    "authors": [
      "Felipe A. Csaszar",
      "Aticus Peterson",
      "Daniel Wilde"
    ],
    "primary_category": "econ.GN",
    "categories": [
      "econ.GN",
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01684v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01684v1",
    "comment": "60 pages, 11 figures, 4 tables",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 7.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01675v1",
    "title": "TRIP-Bench: A Benchmark for Long-Horizon Interactive Agents in Real-World Scenarios",
    "summary": "As LLM-based agents are deployed in increasingly complex real-world settings, existing benchmarks underrepresent key challenges such as enforcing global constraints, coordinating multi-tool reasoning, and adapting to evolving user behavior over long, multi-turn interactions. To bridge this gap, we introduce \\textbf{TRIP-Bench}, a long-horizon benchmark grounded in realistic travel-planning scenarios. TRIP-Bench leverages real-world data, offers 18 curated tools and 40+ travel requirements, and supports automated evaluation. It includes splits of varying difficulty; the hard split emphasizes long and ambiguous interactions, style shifts, feasibility changes, and iterative version revision. Dialogues span up to 15 user turns, can involve 150+ tool calls, and may exceed 200k tokens of context. Experiments show that even advanced models achieve at most 50\\% success on the easy split, with performance dropping below 10\\% on hard subsets. We further propose \\textbf{GTPO}, an online multi-turn reinforcement learning method with specialized reward normalization and reward differencing. Applied to Qwen2.5-32B-Instruct, GTPO improves constraint satisfaction and interaction robustness, outperforming Gemini-3-Pro in our evaluation. We expect TRIP-Bench to advance practical long-horizon interactive agents, and GTPO to provide an effective online RL recipe for robust long-horizon training.",
    "published": "2026-02-02T05:43:08Z",
    "updated": "2026-02-02T05:43:08Z",
    "authors": [
      "Yuanzhe Shen",
      "Zisu Huang",
      "Zhengyuan Wang",
      "Muzhao Tian",
      "Zhengkang Guo",
      "Chenyang Zhang",
      "Shuaiyu Zhou",
      "Zengjie Hu",
      "Dailin Li",
      "Jingwen Xu",
      "Kaimin Wang",
      "Wenhao Liu",
      "Tianlong Li",
      "Fengpeng Yue",
      "Feng Hong",
      "Cao Liu",
      "Ke Zeng"
    ],
    "primary_category": "cs.AI",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01675v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01675v1",
    "comment": "40 pages, 6figures",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 7.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01639v1",
    "title": "ReCALL: Recalibrating Capability Degradation for MLLM-based Composed Image Retrieval",
    "summary": "Composed Image Retrieval (CIR) aims to retrieve target images based on a hybrid query comprising a reference image and a modification text. Early dual-tower Vision-Language Models (VLMs) struggle with cross-modality compositional reasoning required for this task. Recently, adapting generative Multimodal Large Language Models (MLLMs) for retrieval offers a promising direction. However, we identify that this adaptation strategy overlooks a fundamental issue: adapting a generative MLLM into a single-embedding discriminative retriever triggers a paradigm conflict, which leads to Capability Degradation - the deterioration of native fine-grained reasoning after retrieval adaptation. To address this challenge, we propose ReCALL (Recalibrating Capability Degradation), a model-agnostic framework that follows a diagnose-generate-refine pipeline: Firstly, we diagnose cognitive blind spots of the retriever via self-guided informative instance mining. Next, we generate corrective instructions and triplets by CoT prompting the foundation MLLM and conduct quality control with VQA-based consistency filtering. Finally, we refine the retriever through continual training on these triplets with a grouped contrastive scheme, thereby internalizing fine-grained visual-semantic distinctions and realigning the discriminative embedding space of retriever with intrinsic compositional reasoning within the MLLM. Extensive experiments on CIRR and FashionIQ show that ReCALL consistently recalibrates degraded capabilities and achieves state-of-the-art performance. Code will be released soon.",
    "published": "2026-02-02T04:52:54Z",
    "updated": "2026-02-02T04:52:54Z",
    "authors": [
      "Tianyu Yang",
      "ChenWei He",
      "Xiangzhao Hao",
      "Tianyue Wang",
      "Jiarui Guo",
      "Haiyun Guo",
      "Leigang Qu",
      "Jinqiao Wang",
      "Tat-Seng Chua"
    ],
    "primary_category": "cs.CV",
    "categories": [
      "cs.CV"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01639v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01639v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 7.2,
    "matched_areas": [
      "ai",
      "manufacturing"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01593v1",
    "title": "Samba+: General and Accurate Salient Object Detection via A More Unified Mamba-based Framework",
    "summary": "Existing salient object detection (SOD) models are generally constrained by the limited receptive fields of convolutional neural networks (CNNs) and quadratic computational complexity of Transformers. Recently, the emerging state-space model, namely Mamba, has shown great potential in balancing global receptive fields and computational efficiency. As a solution, we propose Saliency Mamba (Samba), a pure Mamba-based architecture that flexibly handles various distinct SOD tasks, including RGB/RGB-D/RGB-T SOD, video SOD (VSOD), RGB-D VSOD, and visible-depth-thermal SOD. Specifically, we rethink the scanning strategy of Mamba for SOD, and introduce a saliency-guided Mamba block (SGMB) that features a spatial neighborhood scanning (SNS) algorithm to preserve the spatial continuity of salient regions. A context-aware upsampling (CAU) method is also proposed to promote hierarchical feature alignment and aggregation by modeling contextual dependencies. As one step further, to avoid the \"task-specific\" problem as in previous SOD solutions, we develop Samba+, which is empowered by training Samba in a multi-task joint manner, leading to a more unified and versatile model. Two crucial components that collaboratively tackle challenges encountered in input of arbitrary modalities and continual adaptation are investigated. Specifically, a hub-and-spoke graph attention (HGA) module facilitates adaptive cross-modal interactive fusion, and a modality-anchored continual learning (MACL) strategy alleviates inter-modal conflicts together with catastrophic forgetting. Extensive experiments demonstrate that Samba individually outperforms existing methods across six SOD tasks on 22 datasets with lower computational cost, whereas Samba+ achieves even superior results on these tasks and datasets by using a single trained versatile model. Additional results further demonstrate the potential of our Samba framework.",
    "published": "2026-02-02T03:34:25Z",
    "updated": "2026-02-02T03:34:25Z",
    "authors": [
      "Wenzhuo Zhao",
      "Keren Fu",
      "Jiahao He",
      "Xiaohong Liu",
      "Qijun Zhao",
      "Guangtao Zhai"
    ],
    "primary_category": "cs.CV",
    "categories": [
      "cs.CV"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01593v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01593v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 7.2,
    "matched_areas": [
      "ai",
      "vision"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01558v1",
    "title": "How Implicit Bias Accumulates and Propagates in LLM Long-term Memory",
    "summary": "Long-term memory mechanisms enable Large Language Models (LLMs) to maintain continuity and personalization across extended interaction lifecycles, but they also introduce new and underexplored risks related to fairness. In this work, we study how implicit bias, defined as subtle statistical prejudice, accumulates and propagates within LLMs equipped with long-term memory. To support systematic analysis, we introduce the Decision-based Implicit Bias (DIB) Benchmark, a large-scale dataset comprising 3,776 decision-making scenarios across nine social domains, designed to quantify implicit bias in long-term decision processes. Using a realistic long-horizon simulation framework, we evaluate six state-of-the-art LLMs integrated with three representative memory architectures on DIB and demonstrate that LLMs' implicit bias does not remain static but intensifies over time and propagates across unrelated domains. We further analyze mitigation strategies and show that a static system-level prompting baseline provides limited and short-lived debiasing effects. To address this limitation, we propose Dynamic Memory Tagging (DMT), an agentic intervention that enforces fairness constraints at memory write time. Extensive experimental results show that DMT substantially reduces bias accumulation and effectively curtails cross-domain bias propagation.",
    "published": "2026-02-02T02:52:56Z",
    "updated": "2026-02-02T02:52:56Z",
    "authors": [
      "Yiming Ma",
      "Lixu Wang",
      "Lionel Z. Wang",
      "Hongkun Yang",
      "Haoming Sun",
      "Xin Xu",
      "Jiaqi Wu",
      "Bin Chen",
      "Wei Dong"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01558v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01558v1",
    "comment": "Under review, and the first two authors contribute equally",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 7.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01553v1",
    "title": "Plain Transformers are Surprisingly Powerful Link Predictors",
    "summary": "Link prediction is a core challenge in graph machine learning, demanding models that capture rich and complex topological dependencies. While Graph Neural Networks (GNNs) are the standard solution, state-of-the-art pipelines often rely on explicit structural heuristics or memory-intensive node embeddings -- approaches that struggle to generalize or scale to massive graphs. Emerging Graph Transformers (GTs) offer a potential alternative but often incur significant overhead due to complex structural encodings, hindering their applications to large-scale link prediction. We challenge these sophisticated paradigms with PENCIL, an encoder-only plain Transformer that replaces hand-crafted priors with attention over sampled local subgraphs, retaining the scalability and hardware efficiency of standard Transformers. Through experimental and theoretical analysis, we show that PENCIL extracts richer structural signals than GNNs, implicitly generalizing a broad class of heuristics and subgraph-based expressivity. Empirically, PENCIL outperforms heuristic-informed GNNs and is far more parameter-efficient than ID-embedding--based alternatives, while remaining competitive across diverse benchmarks -- even without node features. Our results challenge the prevailing reliance on complex engineering techniques, demonstrating that simple design choices are potentially sufficient to achieve the same capabilities.",
    "published": "2026-02-02T02:45:52Z",
    "updated": "2026-02-02T02:45:52Z",
    "authors": [
      "Quang Truong",
      "Yu Song",
      "Donald Loveland",
      "Mingxuan Ju",
      "Tong Zhao",
      "Neil Shah",
      "Jiliang Tang"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01553v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01553v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 7.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01541v1",
    "title": "Toward Cognitive Supersensing in Multimodal Large Language Model",
    "summary": "Multimodal Large Language Models (MLLMs) have achieved remarkable success in open-vocabulary perceptual tasks, yet their ability to solve complex cognitive problems remains limited, especially when visual details are abstract and require visual memory. Current approaches primarily scale Chain-of-Thought (CoT) reasoning in the text space, even when language alone is insufficient for clear and structured reasoning, and largely neglect visual reasoning mechanisms analogous to the human visuospatial sketchpad and visual imagery. To mitigate this deficiency, we introduce Cognitive Supersensing, a novel training paradigm that endows MLLMs with human-like visual imagery capabilities by integrating a Latent Visual Imagery Prediction (LVIP) head that jointly learns sequences of visual cognitive latent embeddings and aligns them with the answer, thereby forming vision-based internal reasoning chains. We further introduce a reinforcement learning stage that optimizes text reasoning paths based on this grounded visual latent. To evaluate the cognitive capabilities of MLLMs, we present CogSense-Bench, a comprehensive visual question answering (VQA) benchmark assessing five cognitive dimensions. Extensive experiments demonstrate that MLLMs trained with Cognitive Supersensing significantly outperform state-of-the-art baselines on CogSense-Bench and exhibit superior generalization on out-of-domain mathematics and science VQA benchmarks, suggesting that internal visual imagery is potentially key to bridging the gap between perceptual recognition and cognitive understanding. We will open-source the CogSense-Bench and our model weights.",
    "published": "2026-02-02T02:19:50Z",
    "updated": "2026-02-02T02:19:50Z",
    "authors": [
      "Boyi Li",
      "Yifan Shen",
      "Yuanzhe Liu",
      "Yifan Xu",
      "Jiateng Liu",
      "Xinzhuo Li",
      "Zhengyuan Li",
      "Jingyuan Zhu",
      "Yunhan Zhong",
      "Fangzhou Lan",
      "Jianguo Cao",
      "James M. Rehg",
      "Heng Ji",
      "Ismini Lourentzou",
      "Xu Cao"
    ],
    "primary_category": "cs.CV",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01541v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01541v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 7.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02486v1",
    "title": "RE-TRAC: REcursive TRAjectory Compression for Deep Search Agents",
    "summary": "LLM-based deep research agents are largely built on the ReAct framework. This linear design makes it difficult to revisit earlier states, branch into alternative search directions, or maintain global awareness under long contexts, often leading to local optima, redundant exploration, and inefficient search. We propose Re-TRAC, an agentic framework that performs cross-trajectory exploration by generating a structured state representation after each trajectory to summarize evidence, uncertainties, failures, and future plans, and conditioning subsequent trajectories on this state representation. This enables iterative reflection and globally informed planning, reframing research as a progressive process. Empirical results show that Re-TRAC consistently outperforms ReAct by 15-20% on BrowseComp with frontier LLMs. For smaller models, we introduce Re-TRAC-aware supervised fine-tuning, achieving state-of-the-art performance at comparable scales. Notably, Re-TRAC shows a monotonic reduction in tool calls and token usage across rounds, indicating progressively targeted exploration driven by cross-trajectory reflection rather than redundant search.",
    "published": "2026-02-02T18:58:07Z",
    "updated": "2026-02-02T18:58:07Z",
    "authors": [
      "Jialiang Zhu",
      "Gongrui Zhang",
      "Xiaolong Ma",
      "Lin Xu",
      "Miaosen Zhang",
      "Ruiqi Yang",
      "Song Wang",
      "Kai Qiu",
      "Zhirong Wu",
      "Qi Dai",
      "Ruichun Ma",
      "Bei Liu",
      "Yifan Yang",
      "Chong Luo",
      "Zhengyuan Yang",
      "Linjie Li",
      "Lijuan Wang",
      "Weizhu Chen",
      "Xin Geng",
      "Baining Guo"
    ],
    "primary_category": "cs.CL",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02486v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02486v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 6.0,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02468v1",
    "title": "Avenir-Web: Human-Experience-Imitating Multimodal Web Agents with Mixture of Grounding Experts",
    "summary": "Despite advances in multimodal large language models, autonomous web agents still struggle to reliably execute long-horizon tasks on complex and dynamic web interfaces. Existing agents often suffer from inaccurate element grounding, the absence of site-specific procedural knowledge, and unstable long-term task tracking and memory, particularly when operating over complex Document Object Model structures. To address these limitations, we introduce Avenir-Web, a web agent that achieves a new open-source state of the art on the Online-Mind2Web benchmark in real-world deployment. Avenir-Web leverages a Mixture of Grounding Experts, Experience-Imitation Planning for incorporating procedural priors, and a task-tracking checklist combined with adaptive memory to enable robust and seamless interaction across diverse user interface paradigms. We evaluate Avenir-Web on Online-Mind2Web, a rigorous benchmark of live and user-centered web tasks. Our results demonstrate that Avenir-Web significantly surpasses prior open-source agents and attains performance parity with top-tier proprietary models, thereby establishing a new open-source state of the art for reliable web agents on live websites.",
    "published": "2026-02-02T18:50:07Z",
    "updated": "2026-02-02T18:50:07Z",
    "authors": [
      "Aiden Yiliu Li",
      "Xinyue Hao",
      "Shilong Liu",
      "Mengdi Wang"
    ],
    "primary_category": "cs.AI",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02468v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02468v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 6.0,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02462v1",
    "title": "Abstract Activation Spaces for Content-Invariant Reasoning in Large Language Models",
    "summary": "Large Language Models (LLMs) often struggle with deductive judgment in syllogistic reasoning, systematically conflating semantic plausibility with formal validity a phenomenon known as content effect. This bias persists even when models generate step-wise explanations, indicating that intermediate rationales may inherit the same semantic shortcuts that affect answers. Recent approaches propose mitigating this issue by increasing inference-time structural constraints, either by encouraging abstract intermediate representations or by intervening directly in the model's internal computations; however, reliably suppressing semantic interference remains an open challenge. To make formal deduction less sensitive to semantic content, we introduce a framework for abstraction-guided reasoning that explicitly separates structural inference from lexical semantics. We construct paired content-laden and abstract syllogisms and use the model's activations on abstract inputs to define an abstract reasoning space. We then learn lightweight Abstractors that, from content-conditioned residual-stream states, predict representations aligned with this space and integrate these predictions via multi-layer interventions during the forward pass. Using cross-lingual transfer as a test bed, we show that abstraction-aligned steering reduces content-driven errors and improves validity-sensitive performance. Our results position activation-level abstraction as a scalable mechanism for enhancing the robustness of formal reasoning in LLMs against semantic interference.",
    "published": "2026-02-02T18:48:44Z",
    "updated": "2026-02-02T18:48:44Z",
    "authors": [
      "Gabriele Maraia",
      "Marco Valentino",
      "Fabio Massimo Zanzotto",
      "Leonardo Ranaldi"
    ],
    "primary_category": "cs.CL",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02462v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02462v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 6.0,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02454v1",
    "title": "World-Gymnast: Training Robots with Reinforcement Learning in a World Model",
    "summary": "Robot learning from interacting with the physical world is fundamentally bottlenecked by the cost of physical interaction. The two alternatives, supervised finetuning (SFT) from expert demonstrations and reinforcement learning (RL) in a software-based simulator, are limited by the amount of expert data available and the sim-to-real gap for manipulation. With the recent emergence of world models learned from real-world video-action data, we ask the question of whether training a policy in a world model can be more effective than supervised learning or software simulation in achieving better real-robot performance. We propose World-Gymnast, which performs RL finetuning of a vision-language-action (VLA) policy by rolling out the policy in an action-conditioned video world model and rewarding the rollouts with a vision-language model (VLM). On the Bridge robot setup, World-Gymnast outperforms SFT by as much as 18x and outperforms software simulator by as much as 2x. More importantly, World-Gymnast demonstrates intriguing capabilities of RL with a world model, including training on diverse language instructions and novel scenes from the world model, test-time training in a novel scene, and online iterative world model and policy improvement. Our results suggest learning a world model and training robot policies in the cloud could be the key to bridging the gap between robots that work in demonstrations and robots that can work in anyone's household.",
    "published": "2026-02-02T18:44:45Z",
    "updated": "2026-02-02T18:44:45Z",
    "authors": [
      "Ansh Kumar Sharma",
      "Yixiang Sun",
      "Ninghao Lu",
      "Yunzhe Zhang",
      "Jiarao Liu",
      "Sherry Yang"
    ],
    "primary_category": "cs.RO",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02454v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02454v1",
    "comment": "https://world-gymnast.github.io/",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 6.0,
    "matched_areas": [
      "ai",
      "agents"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02437v1",
    "title": "UniReason 1.0: A Unified Reasoning Framework for World Knowledge Aligned Image Generation and Editing",
    "summary": "Unified multimodal models often struggle with complex synthesis tasks that demand deep reasoning, and typically treat text-to-image generation and image editing as isolated capabilities rather than interconnected reasoning steps. To address this, we propose UniReason, a unified framework that harmonizes these two tasks through a dual reasoning paradigm. We formulate generation as world knowledge-enhanced planning to inject implicit constraints, and leverage editing capabilities for fine-grained visual refinement to further correct visual errors via self-reflection. This approach unifies generation and editing within a shared representation, mirroring the human cognitive process of planning followed by refinement. We support this framework by systematically constructing a large-scale reasoning-centric dataset (~300k samples) covering five major knowledge domains (e.g., cultural commonsense, physics, etc.) for planning, alongside an agent-generated corpus for visual self-correction. Extensive experiments demonstrate that UniReason achieves advanced performance on reasoning-intensive benchmarks such as WISE, KrisBench and UniREditBench, while maintaining superior general synthesis capabilities.",
    "published": "2026-02-02T18:34:35Z",
    "updated": "2026-02-02T18:34:35Z",
    "authors": [
      "Dianyi Wang",
      "Chaofan Ma",
      "Feng Han",
      "Size Wu",
      "Wei Song",
      "Yibin Wang",
      "Zhixiong Zhang",
      "Tianhang Wang",
      "Siyuan Wang",
      "Zhongyu Wei",
      "Jiaqi Wang"
    ],
    "primary_category": "cs.CV",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02437v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02437v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 6.0,
    "matched_areas": [
      "ai",
      "vision"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02430v1",
    "title": "3D Foundation Model-Based Loop Closing for Decentralized Collaborative SLAM",
    "summary": "Decentralized Collaborative Simultaneous Localization And Mapping (C-SLAM) techniques often struggle to identify map overlaps due to significant viewpoint variations among robots. Motivated by recent advancements in 3D foundation models, which can register images despite large viewpoint differences, we propose a robust loop closing approach that leverages these models to establish inter-robot measurements. In contrast to resource-intensive methods requiring full 3D reconstruction within a centralized map, our approach integrates foundation models into existing SLAM pipelines, yielding scalable and robust multi-robot mapping. Our contributions include: (1) integrating 3D foundation models to reliably estimate relative poses from monocular image pairs within decentralized C-SLAM; (2) introducing robust outlier mitigation techniques critical to the use of these relative poses; and (3) developing specialized pose graph optimization formulations that efficiently resolve scale ambiguities. We evaluate our method against state-of-the-art approaches, demonstrating improvements in localization and mapping accuracy, alongside significant gains in computational and memory efficiency. These results highlight the potential of our approach for deployment in large-scale multi-robot scenarios.",
    "published": "2026-02-02T18:30:32Z",
    "updated": "2026-02-02T18:30:32Z",
    "authors": [
      "Pierre-Yves Lajoie",
      "Benjamin Ramtoula",
      "Daniele De Martini",
      "Giovanni Beltrame"
    ],
    "primary_category": "cs.RO",
    "categories": [
      "cs.RO"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02430v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02430v1",
    "comment": null,
    "journal_ref": null,
    "doi": "10.1109/LRA.2025.3609204",
    "relevance_score": 6.0,
    "matched_areas": [
      "ai",
      "vision"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02427v1",
    "title": "Embedding Perturbation may Better Reflect the Uncertainty in LLM Reasoning",
    "summary": "Large language Models (LLMs) have achieved significant breakthroughs across diverse domains; however, they can still produce unreliable or misleading outputs. For responsible LLM application, Uncertainty Quantification (UQ) techniques are used to estimate a model's uncertainty about its outputs, indicating the likelihood that those outputs may be problematic. For LLM reasoning tasks, it is essential to estimate the uncertainty not only for the final answer, but also for the intermediate steps of the reasoning, as this can enable more fine-grained and targeted interventions. In this study, we explore what UQ metrics better reflect the LLM's ``intermediate uncertainty''during reasoning. Our study reveals that an LLMs' incorrect reasoning steps tend to contain tokens which are highly sensitive to the perturbations on the preceding token embeddings. In this way, incorrect (uncertain) intermediate steps can be readily identified using this sensitivity score as guidance in practice. In our experiments, we show such perturbation-based metric achieves stronger uncertainty quantification performance compared with baseline methods such as token (generation) probability and token entropy. Besides, different from approaches that rely on multiple sampling, the perturbation-based metrics offer better simplicity and efficiency.",
    "published": "2026-02-02T18:27:26Z",
    "updated": "2026-02-02T18:27:26Z",
    "authors": [
      "Qihao Wen",
      "Jiahao Wang",
      "Yang Nan",
      "Pengfei He",
      "Ravi Tandon",
      "Han Xu"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02427v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02427v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 6.0,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02400v1",
    "title": "An Empirical Study on Noisy Data and LLM Pretraining Loss Divergence",
    "summary": "Large-scale pretraining datasets drive the success of large language models (LLMs). However, these web-scale corpora inevitably contain large amounts of noisy data due to unregulated web content or randomness inherent in data. Although LLM pretrainers often speculate that such noise contributes to instabilities in large-scale LLM pretraining and, in the worst cases, loss divergence, this phenomenon remains poorly understood.In this work, we present a systematic empirical study of whether noisy data causes LLM pretraining divergences and how it does so. By injecting controlled synthetic uniformly random noise into otherwise clean datasets, we analyze training dynamics across model sizes ranging from 480M to 5.2B parameters. We show that noisy data indeed induces training loss divergence, and that the probability of divergence depends strongly on the noise type, amount of noise, and model scale. We further find that noise-induced divergences exhibit activation patterns distinct from those caused by high learning rates, and we provide diagnostics that differentiate these two failure modes. Together, these results provide a large-scale, controlled characterization of how noisy data affects loss divergence in LLM pretraining.",
    "published": "2026-02-02T17:58:50Z",
    "updated": "2026-02-02T17:58:50Z",
    "authors": [
      "Qizhen Zhang",
      "Ankush Garg",
      "Jakob Foerster",
      "Niladri Chatterji",
      "Kshitiz Malik",
      "Mike Lewis"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02400v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02400v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 6.0,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02388v1",
    "title": "Personalized Image Generation via Human-in-the-loop Bayesian Optimization",
    "summary": "Imagine Alice has a specific image $x^\\ast$ in her mind, say, the view of the street in which she grew up during her childhood. To generate that exact image, she guides a generative model with multiple rounds of prompting and arrives at an image $x^{p*}$. Although $x^{p*}$ is reasonably close to $x^\\ast$, Alice finds it difficult to close that gap using language prompts. This paper aims to narrow this gap by observing that even after language has reached its limits, humans can still tell when a new image $x^+$ is closer to $x^\\ast$ than $x^{p*}$. Leveraging this observation, we develop MultiBO (Multi-Choice Preferential Bayesian Optimization) that carefully generates $K$ new images as a function of $x^{p*}$, gets preferential feedback from the user, uses the feedback to guide the diffusion model, and ultimately generates a new set of $K$ images. We show that within $B$ rounds of user feedback, it is possible to arrive much closer to $x^\\ast$, even though the generative model has no information about $x^\\ast$. Qualitative scores from $30$ users, combined with quantitative metrics compared across $5$ baselines, show promising results, suggesting that multi-choice feedback from humans can be effectively harnessed for personalized image generation.",
    "published": "2026-02-02T17:51:30Z",
    "updated": "2026-02-02T17:51:30Z",
    "authors": [
      "Rajalaxmi Rajagopalan",
      "Debottam Dutta",
      "Yu-Lin Wei",
      "Romit Roy Choudhury"
    ],
    "primary_category": "cs.CV",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02388v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02388v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 6.0,
    "matched_areas": [
      "ai",
      "vision"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02386v1",
    "title": "Trust by Design: Skill Profiles for Transparent, Cost-Aware LLM Routing",
    "summary": "How should Large Language Model (LLM) practitioners select the right model for a task without wasting money? We introduce BELLA (Budget-Efficient LLM Selection via Automated skill-profiling), a framework that recommends optimal LLM selection for tasks through interpretable skill-based model selection. Standard benchmarks report aggregate metrics that obscure which specific capabilities a task requires and whether a cheaper model could suffice. BELLA addresses this gap through three stages: (1) decomposing LLM outputs and extract the granular skills required by using critic-based profiling, (2) clustering skills into structured capability matrices, and (3) multi-objective optimization to select the right models to maximize performance while respecting budget constraints. BELLA provides natural-language rationale for recommendations, providing transparency that current black-box routing systems lack. We describe the framework architecture, situate it within the landscape of LLM routing and evaluation, and discuss its application to financial reasoning as a representative domain exhibiting diverse skill requirements and cost-variation across models. Our framework enables practitioners to make principled and cost-performance trade-offs for deploying LLMs.",
    "published": "2026-02-02T17:49:30Z",
    "updated": "2026-02-02T17:49:30Z",
    "authors": [
      "Mika Okamoto",
      "Ansel Kaplan Erol",
      "Glenn Matlin"
    ],
    "primary_category": "cs.AI",
    "categories": [
      "cs.AI",
      "cs.IR",
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02386v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02386v1",
    "comment": "Appeared at MLSys YPS 2025",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 6.0,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02366v1",
    "title": "ReasonCACHE: Teaching LLMs To Reason Without Weight Updates",
    "summary": "Can Large language models (LLMs) learn to reason without any weight update and only through in-context learning (ICL)? ICL is strikingly sample-efficient, often learning from only a handful of demonstrations, but complex reasoning tasks typically demand many training examples to learn from. However, naively scaling ICL by adding more demonstrations breaks down at this scale: attention costs grow quadratically, performance saturates or degrades with longer contexts, and the approach remains a shallow form of learning. Due to these limitations, practitioners predominantly rely on in-weight learning (IWL) to induce reasoning. In this work, we show that by using Prefix Tuning, LLMs can learn to reason without overloading the context window and without any weight updates. We introduce $\\textbf{ReasonCACHE}$, an instantiation of this mechanism that distills demonstrations into a fixed key-value cache. Empirically, across challenging reasoning benchmarks, including GPQA-Diamond, ReasonCACHE outperforms standard ICL and matches or surpasses IWL approaches. Further, it achieves this all while being more efficient across three key axes: data, inference cost, and trainable parameters. We also theoretically prove that ReasonCACHE can be strictly more expressive than low-rank weight update since the latter ties expressivity to input rank, whereas ReasonCACHE bypasses this constraint by directly injecting key-values into the attention mechanism. Together, our findings identify ReasonCACHE as a middle path between in-context and in-weight learning, providing a scalable algorithm for learning reasoning skills beyond the context window without modifying parameters. Our project page: https://reasoncache.github.io/",
    "published": "2026-02-02T17:24:23Z",
    "updated": "2026-02-02T17:24:23Z",
    "authors": [
      "Sharut Gupta",
      "Phillip Isola",
      "Stefanie Jegelka",
      "David Lopez-Paz",
      "Kartik Ahuja",
      "Mark Ibrahim",
      "Mohammad Pezeshki"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02366v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02366v1",
    "comment": "26 pages, 17 Figures",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 6.0,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02351v1",
    "title": "Artificial Intelligence and Symmetries: Learning, Encoding, and Discovering Structure in Physical Data",
    "summary": "Symmetries play a central role in physics, organizing dynamics, constraining interactions, and determining the effective number of physical degrees of freedom. In parallel, modern artificial intelligence methods have demonstrated a remarkable ability to extract low-dimensional structure from high-dimensional data through representation learning. This review examines the interplay between these two perspectives, focusing on the extent to which symmetry-induced constraints can be identified, encoded, or diagnosed using machine learning techniques. Rather than emphasizing architectures that enforce known symmetries by construction, we concentrate on data-driven approaches and latent representation learning, with particular attention to variational autoencoders. We discuss how symmetries and conservation laws reduce the intrinsic dimensionality of physical datasets, and how this reduction may manifest itself through self-organization of latent spaces in generative models trained to balance reconstruction and compression. We review recent results, including case studies from simple geometric systems and particle physics processes, and analyze the theoretical and practical limitations of inferring symmetry structure without explicit inductive bias.",
    "published": "2026-02-02T17:15:52Z",
    "updated": "2026-02-02T17:15:52Z",
    "authors": [
      "Veronica Sanz"
    ],
    "primary_category": "hep-ph",
    "categories": [
      "hep-ph",
      "cs.AI",
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02351v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02351v1",
    "comment": "25 pages, 9 figures. This manuscript is an invited review at the International Journal of Modern Physics A",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 6.0,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02338v1",
    "title": "Rethinking Generative Recommender Tokenizer: Recsys-Native Encoding and Semantic Quantization Beyond LLMs",
    "summary": "Semantic ID (SID)-based recommendation is a promising paradigm for scaling sequential recommender systems, but existing methods largely follow a semantic-centric pipeline: item embeddings are learned from foundation models and discretized using generic quantization schemes. This design is misaligned with generative recommendation objectives: semantic embeddings are weakly coupled with collaborative prediction, and generic quantization is inefficient at reducing sequential uncertainty for autoregressive modeling. To address these, we propose ReSID, a recommendation-native, principled SID framework that rethinks representation learning and quantization from the perspective of information preservation and sequential predictability, without relying on LLMs. ReSID consists of two components: (i) Field-Aware Masked Auto-Encoding (FAMAE), which learns predictive-sufficient item representations from structured features, and (ii) Globally Aligned Orthogonal Quantization (GAOQ), which produces compact and predictable SID sequences by jointly reducing semantic ambiguity and prefix-conditional uncertainty. Theoretical analysis and extensive experiments across ten datasets show the effectiveness of ReSID. ReSID consistently outperforms strong sequential and SID-based generative baselines by an average of over 10%, while reducing tokenization cost by up to 122x. Code is available at https://github.com/FuCongResearchSquad/ReSID.",
    "published": "2026-02-02T17:00:04Z",
    "updated": "2026-02-02T17:00:04Z",
    "authors": [
      "Yu Liang",
      "Zhongjin Zhang",
      "Yuxuan Zhu",
      "Kerui Zhang",
      "Zhiluohan Guo",
      "Wenhang Zhou",
      "Zonqi Yang",
      "Kangle Wu",
      "Yabo Ni",
      "Anxiang Zeng",
      "Cong Fu",
      "Jianxin Wang",
      "Jiazhi Xia"
    ],
    "primary_category": "cs.IR",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02338v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02338v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 6.0,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02313v1",
    "title": "Interpreting and Controlling LLM Reasoning through Integrated Policy Gradient",
    "summary": "Large language models (LLMs) demonstrate strong reasoning abilities in solving complex real-world problems. Yet, the internal mechanisms driving these complex reasoning behaviors remain opaque. Existing interpretability approaches targeting reasoning either identify components (e.g., neurons) correlated with special textual patterns, or rely on human-annotated contrastive pairs to derive control vectors. Consequently, current methods struggle to precisely localize complex reasoning mechanisms or capture sequential influence from model internal workings to the reasoning outputs. In this paper, built on outcome-oriented and sequential-influence-aware principles, we focus on identifying components that have sequential contribution to reasoning behavior where outcomes are cumulated by long-range effects. We propose Integrated Policy Gradient (IPG), a novel framework that attributes reasoning behaviors to model's inner components by propagating compound outcome-based signals such as post reasoning accuracy backward through model inference trajectories. Empirical evaluations demonstrate that our approach achieves more precise localization and enables reliable modulation of reasoning behaviors (e.g., reasoning capability, reasoning strength) across diverse reasoning models.",
    "published": "2026-02-02T16:43:09Z",
    "updated": "2026-02-02T16:43:09Z",
    "authors": [
      "Changming Li",
      "Kaixing Zhang",
      "Haoyun Xu",
      "Yingdong Shi",
      "Zheng Zhang",
      "Kaitao Song",
      "Kan Ren"
    ],
    "primary_category": "cs.AI",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02313v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02313v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 6.0,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02306v1",
    "title": "Spark: Modular Spiking Neural Networks",
    "summary": "Nowadays, neural networks act as a synonym for artificial intelligence. Present neural network models, although remarkably powerful, are inefficient both in terms of data and energy. Several alternative forms of neural networks have been proposed to address some of these problems. Specifically, spiking neural networks are suitable for efficient hardware implementations. However, effective learning algorithms for spiking networks remain elusive, although it is suspected that effective plasticity mechanisms could alleviate the problem of data efficiency. Here, we present a new framework for spiking neural networks - Spark - built upon the idea of modular design, from simple components to entire models. The aim of this framework is to provide an efficient and streamlined pipeline for spiking neural networks. We showcase this framework by solving the sparse-reward cartpole problem with simple plasticity mechanisms. We hope that a framework compatible with traditional ML pipelines may accelerate research in the area, specifically for continuous and unbatched learning, akin to the one animals exhibit.",
    "published": "2026-02-02T16:36:58Z",
    "updated": "2026-02-02T16:36:58Z",
    "authors": [
      "Mario Franco",
      "Carlos Gershenson"
    ],
    "primary_category": "cs.NE",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02306v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02306v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 6.0,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02304v1",
    "title": "Position: Explaining Behavioral Shifts in Large Language Models Requires a Comparative Approach",
    "summary": "Large-scale foundation models exhibit behavioral shifts: intervention-induced behavioral changes that appear after scaling, fine-tuning, reinforcement learning or in-context learning. While investigating these phenomena have recently received attention, explaining their appearance is still overlooked. Classic explainable AI (XAI) methods can surface failures at a single checkpoint of a model, but they are structurally ill-suited to justify what changed internally across different checkpoints and which explanatory claims are warranted about that change. We take the position that behavioral shifts should be explained comparatively: the core target should be the intervention-induced shift between a reference model and an intervened model, rather than any single model in isolation. To this aim we formulate a Comparative XAI ($$-XAI) framework with a set of desiderata to be taken into account when designing proper explaining methods. To highlight how $$-XAI methods work, we introduce a set of possible pipelines, relate them to the desiderata, and provide a concrete $$-XAI experiment.",
    "published": "2026-02-02T16:36:21Z",
    "updated": "2026-02-02T16:36:21Z",
    "authors": [
      "Martino Ciaperoni",
      "Marzio Di Vece",
      "Luca Pappalardo",
      "Fosca Giannotti",
      "Francesco Giannini"
    ],
    "primary_category": "cs.AI",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02304v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02304v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 6.0,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02296v1",
    "title": "Decoupling Generalizability and Membership Privacy Risks in Neural Networks",
    "summary": "A deep learning model usually has to sacrifice some utilities when it acquires some other abilities or characteristics. Privacy preservation has such trade-off relationships with utilities. The loss disparity between various defense approaches implies the potential to decouple generalizability and privacy risks to maximize privacy gain. In this paper, we identify that the model's generalization and privacy risks exist in different regions in deep neural network architectures. Based on the observations that we investigate, we propose Privacy-Preserving Training Principle (PPTP) to protect model components from privacy risks while minimizing the loss in generalizability. Through extensive evaluations, our approach shows significantly better maintenance in model generalizability while enhancing privacy preservation.",
    "published": "2026-02-02T16:32:42Z",
    "updated": "2026-02-02T16:32:42Z",
    "authors": [
      "Xingli Fang",
      "Jung-Eun Kim"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02296v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02296v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 6.0,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02280v1",
    "title": "RACA: Representation-Aware Coverage Criteria for LLM Safety Testing",
    "summary": "Recent advancements in LLMs have led to significant breakthroughs in various AI applications. However, their sophisticated capabilities also introduce severe safety concerns, particularly the generation of harmful content through jailbreak attacks. Current safety testing for LLMs often relies on static datasets and lacks systematic criteria to evaluate the quality and adequacy of these tests. While coverage criteria have been effective for smaller neural networks, they are not directly applicable to LLMs due to scalability issues and differing objectives. To address these challenges, this paper introduces RACA, a novel set of coverage criteria specifically designed for LLM safety testing. RACA leverages representation engineering to focus on safety-critical concepts within LLMs, thereby reducing dimensionality and filtering out irrelevant information. The framework operates in three stages: first, it identifies safety-critical representations using a small, expert-curated calibration set of jailbreak prompts. Second, it calculates conceptual activation scores for a given test suite based on these representations. Finally, it computes coverage results using six sub-criteria that assess both individual and compositional safety concepts. We conduct comprehensive experiments to validate RACA's effectiveness, applicability, and generalization, where the results demonstrate that RACA successfully identifies high-quality jailbreak prompts and is superior to traditional neuron-level criteria. We also showcase its practical application in real-world scenarios, such as test set prioritization and attack prompt sampling. Furthermore, our findings confirm RACA's generalization to various scenarios and its robustness across various configurations. Overall, RACA provides a new framework for evaluating the safety of LLMs, contributing a valuable technique to the field of testing for AI.",
    "published": "2026-02-02T16:20:51Z",
    "updated": "2026-02-02T16:20:51Z",
    "authors": [
      "Zeming Wei",
      "Zhixin Zhang",
      "Chengcan Wu",
      "Yihao Zhang",
      "Xiaokun Luan",
      "Meng Sun"
    ],
    "primary_category": "cs.SE",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL",
      "cs.CR",
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02280v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02280v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 6.0,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02266v1",
    "title": "OpenSeal: Good, Fast, and Cheap Construction of an Open-Source Southeast Asian LLM via Parallel Data",
    "summary": "Large language models (LLMs) have proven to be effective tools for a wide range of natural language processing (NLP) applications. Although many LLMs are multilingual, most remain English-centric and perform poorly on low-resource languages. Recently, several Southeast Asia-focused LLMs have been developed, but none are truly open source, as they do not publicly disclose their training data. Truly open-source models are important for transparency and for enabling a deeper and more precise understanding of LLM internals and development, including biases, generalization, and multilinguality. Motivated by recent advances demonstrating the effectiveness of parallel data in improving multilingual performance, we conduct controlled and comprehensive experiments to study the effectiveness of parallel data in continual pretraining of LLMs. Our findings show that using only parallel data is the most effective way to extend an LLM to new languages. Using just 34.7B tokens of parallel data and 180 hours on 8x NVIDIA H200 GPUs, we built OpenSeal, the first truly open Southeast Asian LLM that rivals the performance of existing models of similar size.",
    "published": "2026-02-02T16:09:10Z",
    "updated": "2026-02-02T16:09:10Z",
    "authors": [
      "Tan Sang Nguyen",
      "Muhammad Reza Qorib",
      "Hwee Tou Ng"
    ],
    "primary_category": "cs.CL",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02266v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02266v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 6.0,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02262v1",
    "title": "OmniCode: A Benchmark for Evaluating Software Engineering Agents",
    "summary": "LLM-powered coding agents are redefining how real-world software is developed. To drive the research towards better coding agents, we require challenging benchmarks that can rigorously evaluate the ability of such agents to perform various software engineering tasks. However, popular coding benchmarks such as HumanEval and SWE-Bench focus on narrowly scoped tasks such as competition programming and patch generation. In reality, software engineers have to handle a broader set of tasks for real-world software development. To address this gap, we propose OmniCode, a novel software engineering benchmark that contains a broader and more diverse set of task categories beyond code or patch generation. Overall, OmniCode contains 1794 tasks spanning three programming languages (Python, Java, and C++) and four key categories: bug fixing, test generation, code review fixing, and style fixing. In contrast to prior software engineering benchmarks, the tasks in OmniCode are (1) manually validated to eliminate ill-defined problems, and (2) synthetically crafted or recently curated to avoid data leakage issues, presenting a new framework for synthetically generating diverse software tasks from limited real-world data. We evaluate OmniCode with popular agent frameworks such as SWE-Agent and show that while they may perform well on bug fixing for Python, they fall short on tasks such as Test Generation and in languages such as C++ and Java. For instance, SWE-Agent achieves a maximum of 20.9% with DeepSeek-V3.1 on Java Test Generation tasks. OmniCode aims to serve as a robust benchmark and spur the development of agents that can perform well across different aspects of software development. Code and data are available at https://github.com/seal-research/OmniCode.",
    "published": "2026-02-02T16:04:10Z",
    "updated": "2026-02-02T16:04:10Z",
    "authors": [
      "Atharv Sonwane",
      "Eng-Shen Tu",
      "Wei-Chung Lu",
      "Claas Beger",
      "Carter Larsen",
      "Debjit Dhar",
      "Rachel Chen",
      "Ronit Pattanayak",
      "Tuan Anh Dang",
      "Guohao Chen",
      "Gloria Geng",
      "Kevin Ellis",
      "Saikat Dutta"
    ],
    "primary_category": "cs.SE",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02262v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02262v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 6.0,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02230v1",
    "title": "SEDformer: Event-Synchronous Spiking Transformers for Irregular Telemetry Time Series Forecasting",
    "summary": "Telemetry streams from large-scale Internet-connected systems (e.g., IoT deployments and online platforms) naturally form an irregular multivariate time series (IMTS) whose accurate forecasting is operationally vital. A closer examination reveals a defining Sparsity-Event Duality (SED) property of IMTS, i.e., long stretches with sparse or no observations are punctuated by short, dense bursts where most semantic events (observations) occur. However, existing Graph- and Transformer-based forecasters ignore SED: pre-alignment to uniform grids with heavy padding violates sparsity by inflating sequences and forcing computation at non-informative steps, while relational recasting weakens event semantics by disrupting local temporal continuity. These limitations motivate a more faithful and natural modeling paradigm for IMTS that aligns with its SED property. We find that Spiking Neural Networks meet this requirement, as they communicate via sparse binary spikes and update in an event-driven manner, aligning naturally with the SED nature of IMTS. Therefore, we present SEDformer, an SED-enhanced Spiking Transformer for telemetry IMTS forecasting that couples: (1) a SED-based Spike Encoder converts raw observations into event synchronous spikes using an Event-Aligned LIF neuron, (2) an Event-Preserving Temporal Downsampling module compresses long gaps while retaining salient firings and (3) a stack of SED-based Spike Transformer blocks enable intra-series dependency modeling with a membrane-based linear attention driven by EA-LIF spiking features. Experiments on public telemetry IMTS datasets show that SEDformer attains state-of-the-art forecasting accuracy while reducing energy and memory usage, providing a natural and efficient path for modeling IMTS.",
    "published": "2026-02-02T15:33:30Z",
    "updated": "2026-02-02T15:33:30Z",
    "authors": [
      "Ziyu Zhou",
      "Yuchen Fang",
      "Weilin Ruan",
      "Shiyu Wang",
      "James Kwok",
      "Yuxuan Liang"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02230v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02230v1",
    "comment": "Under review",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 6.0,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02214v1",
    "title": "Causal Forcing: Autoregressive Diffusion Distillation Done Right for High-Quality Real-Time Interactive Video Generation",
    "summary": "To achieve real-time interactive video generation, current methods distill pretrained bidirectional video diffusion models into few-step autoregressive (AR) models, facing an architectural gap when full attention is replaced by causal attention. However, existing approaches do not bridge this gap theoretically. They initialize the AR student via ODE distillation, which requires frame-level injectivity, where each noisy frame must map to a unique clean frame under the PF-ODE of an AR teacher. Distilling an AR student from a bidirectional teacher violates this condition, preventing recovery of the teacher's flow map and instead inducing a conditional-expectation solution, which degrades performance. To address this issue, we propose Causal Forcing that uses an AR teacher for ODE initialization, thereby bridging the architectural gap. Empirical results show that our method outperforms all baselines across all metrics, surpassing the SOTA Self Forcing by 19.3\\% in Dynamic Degree, 8.7\\% in VisionReward, and 16.7\\% in Instruction Following. Project page and the code: \\href{https://thu-ml.github.io/CausalForcing.github.io/}{https://thu-ml.github.io/CausalForcing.github.io/}",
    "published": "2026-02-02T15:19:22Z",
    "updated": "2026-02-02T15:19:22Z",
    "authors": [
      "Hongzhou Zhu",
      "Min Zhao",
      "Guande He",
      "Hang Su",
      "Chongxuan Li",
      "Jun Zhu"
    ],
    "primary_category": "cs.CV",
    "categories": [
      "cs.CV"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02214v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02214v1",
    "comment": "Project page and the code: \\href{https://thu-ml.github.io/CausalForcing.github.io/}{https://thu-ml.github.io/CausalForcing.github.io/}",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 6.0,
    "matched_areas": [
      "ai",
      "vision"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02195v1",
    "title": "State Rank Dynamics in Linear Attention LLMs",
    "summary": "Linear Attention Large Language Models (LLMs) offer a compelling recurrent formulation that compresses context into a fixed-size state matrix, enabling constant-time inference. However, the internal dynamics of this compressed state remain largely opaque. In this work, we present a comprehensive study on the runtime state dynamics of state-of-the-art Linear Attention models. We uncover a fundamental phenomenon termed State Rank Stratification, characterized by a distinct spectral bifurcation among linear attention heads: while one group maintains an effective rank oscillating near zero, the other exhibits rapid growth that converges to an upper bound. Extensive experiments across diverse inference contexts reveal that these dynamics remain strikingly consistent, indicating that the identity of a head,whether low-rank or high-rank,is an intrinsic structural property acquired during pre-training, rather than a transient state dependent on the input data. Furthermore, our diagnostic probes reveal a surprising functional divergence: low-rank heads are indispensable for model reasoning, whereas high-rank heads exhibit significant redundancy. Leveraging this insight, we propose Joint Rank-Norm Pruning, a zero-shot strategy that achieves a 38.9\\% reduction in KV-cache overhead while largely maintaining model accuracy.",
    "published": "2026-02-02T15:00:42Z",
    "updated": "2026-02-02T15:00:42Z",
    "authors": [
      "Ao Sun",
      "Hongtao Zhang",
      "Heng Zhou",
      "Yixuan Ma",
      "Yiran Qin",
      "Tongrui Su",
      "Yan Liu",
      "Zhanyu Ma",
      "Jun Xu",
      "Jiuchong Gao",
      "Jinghua Hao",
      "Renqing He"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02195v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02195v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 6.0,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02188v1",
    "title": "Reasoning in a Combinatorial and Constrained World: Benchmarking LLMs on Natural-Language Combinatorial Optimization",
    "summary": "While large language models (LLMs) have shown strong performance in math and logic reasoning, their ability to handle combinatorial optimization (CO) -- searching high-dimensional solution spaces under hard constraints -- remains underexplored. To bridge the gap, we introduce NLCO, a \\textbf{N}atural \\textbf{L}anguage \\textbf{C}ombinatorial \\textbf{O}ptimization benchmark that evaluates LLMs on end-to-end CO reasoning: given a language-described decision-making scenario, the model must output a discrete solution without writing code or calling external solvers. NLCO covers 43 CO problems and is organized using a four-layer taxonomy of variable types, constraint families, global patterns, and objective classes, enabling fine-grained evaluation. We provide solver-annotated solutions and comprehensively evaluate LLMs by feasibility, solution optimality, and reasoning efficiency. Experiments across a wide range of modern LLMs show that high-performing models achieve strong feasibility and solution quality on small instances, but both degrade as instance size grows, even if more tokens are used for reasoning. We also observe systematic effects across the taxonomy: set-based tasks are relatively easy, whereas graph-structured problems and bottleneck objectives lead to more frequent failures.",
    "published": "2026-02-02T14:55:48Z",
    "updated": "2026-02-02T14:55:48Z",
    "authors": [
      "Xia Jiang",
      "Jing Chen",
      "Cong Zhang",
      "Jie Gao",
      "Chengpeng Hu",
      "Chenhao Zhang",
      "Yaoxin Wu",
      "Yingqian Zhang"
    ],
    "primary_category": "cs.AI",
    "categories": [
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02188v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02188v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 6.0,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02185v1",
    "title": "Vision-DeepResearch Benchmark: Rethinking Visual and Textual Search for Multimodal Large Language Models",
    "summary": "Multimodal Large Language Models (MLLMs) have advanced VQA and now support Vision-DeepResearch systems that use search engines for complex visual-textual fact-finding. However, evaluating these visual and textual search abilities is still difficult, and existing benchmarks have two major limitations. First, existing benchmarks are not visual search-centric: answers that should require visual search are often leaked through cross-textual cues in the text questions or can be inferred from the prior world knowledge in current MLLMs. Second, overly idealized evaluation scenario: On the image-search side, the required information can often be obtained via near-exact matching against the full image, while the text-search side is overly direct and insufficiently challenging. To address these issues, we construct the Vision-DeepResearch benchmark (VDR-Bench) comprising 2,000 VQA instances. All questions are created via a careful, multi-stage curation pipeline and rigorous expert review, designed to assess the behavior of Vision-DeepResearch systems under realistic real-world conditions. Moreover, to address the insufficient visual retrieval capabilities of current MLLMs, we propose a simple multi-round cropped-search workflow. This strategy is shown to effectively improve model performance in realistic visual retrieval scenarios. Overall, our results provide practical guidance for the design of future multimodal deep-research systems. The code will be released in https://github.com/Osilly/Vision-DeepResearch.",
    "published": "2026-02-02T14:53:11Z",
    "updated": "2026-02-02T14:53:11Z",
    "authors": [
      "Yu Zeng",
      "Wenxuan Huang",
      "Zhen Fang",
      "Shuang Chen",
      "Yufan Shen",
      "Yishuo Cai",
      "Xiaoman Wang",
      "Zhenfei Yin",
      "Lin Chen",
      "Zehui Chen",
      "Shiting Huang",
      "Yiming Zhao",
      "Yao Hu",
      "Philip Torr",
      "Wanli Ouyang",
      "Shaosheng Cao"
    ],
    "primary_category": "cs.CV",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02185v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02185v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 6.0,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02180v1",
    "title": "STILL: Selecting Tokens for Intra-Layer Hybrid Attention to Linearize LLMs",
    "summary": "Linearizing pretrained large language models (LLMs) primarily relies on intra-layer hybrid attention mechanisms to alleviate the quadratic complexity of standard softmax attention. Existing methods perform token routing based on sliding-window partitions, resulting in position-based selection and fails to capture token-specific global importance. Meanwhile, linear attention further suffers from distribution shift caused by learnable feature maps that distort pretrained feature magnitudes. Motivated by these limitations, we propose STILL, an intra-layer hybrid linearization framework for efficiently linearizing LLMs. STILL introduces a Self-Saliency Score with strong local-global consistency, enabling accurate token selection using sliding-window computation, and retains salient tokens for sparse softmax attention while summarizing the remaining context via linear attention. To preserve pretrained representations, we design a Norm-Preserved Feature Map (NP-Map) that decouples feature direction from magnitude and reinjects pretrained norms. We further adopt a unified training-inference architecture with chunk-wise parallelization and delayed selection to improve hardware efficiency. Experiments show that STILL matches or surpasses the original pretrained model on commonsense and general reasoning tasks, and achieves up to a 86.2% relative improvement over prior linearized attention methods on long-context benchmarks.",
    "published": "2026-02-02T14:49:18Z",
    "updated": "2026-02-02T14:49:18Z",
    "authors": [
      "Weikang Meng",
      "Liangyu Huo",
      "Yadan Luo",
      "Jiawen Guan",
      "Jingyi Zhang",
      "Yingjian Li",
      "Zheng Zhang"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02180v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02180v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 6.0,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02154v1",
    "title": "Deep learning enables urban change profiling through alignment of historical maps",
    "summary": "Prior to modern Earth observation technologies, historical maps provide a unique record of long-term urban transformation and offer a lens on the evolving identity of cities. However, extracting consistent and fine-grained change information from historical map series remains challenging due to spatial misalignment, cartographic variation, and degrading document quality, limiting most analyses to small-scale or qualitative approaches. We propose a fully automated, deep learning-based framework for fine-grained urban change analysis from large collections of historical maps, built on a modular design that integrates dense map alignment, multi-temporal object detection, and change profiling. This framework shifts the analysis of historical maps from ad hoc visual comparison toward systematic, quantitative characterization of urban change. Experiments demonstrate the robust performance of the proposed alignment and object detection methods. Applied to Paris between 1868 and 1937, the framework reveals the spatial and temporal heterogeneity in urban transformation, highlighting its relevance for research in the social sciences and humanities. The modular design of our framework further supports adaptation to diverse cartographic contexts and downstream applications.",
    "published": "2026-02-02T14:31:33Z",
    "updated": "2026-02-02T14:31:33Z",
    "authors": [
      "Sidi Wu",
      "Yizi Chen",
      "Maurizio Gribaudi",
      "Konrad Schindler",
      "Clment Mallet",
      "Julien Perret",
      "Lorenz Hurni"
    ],
    "primary_category": "cs.CV",
    "categories": [
      "cs.CV",
      "cs.IR"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02154v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02154v1",
    "comment": "40 pages",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 6.0,
    "matched_areas": [
      "ai",
      "vision"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02153v1",
    "title": "Learning Beyond the Gaussian Data: Learning Dynamics of Neural Networks on an Expressive and Cumulant-Controllable Data Model",
    "summary": "We study the effect of high-order statistics of data on the learning dynamics of neural networks (NNs) by using a moment-controllable non-Gaussian data model. Considering the expressivity of two-layer neural networks, we first construct the data model as a generative two-layer NN where the activation function is expanded by using Hermite polynomials. This allows us to achieve interpretable control over high-order cumulants such as skewness and kurtosis through the Hermite coefficients while keeping the data model realistic. Using samples generated from the data model, we perform controlled online learning experiments with a two-layer NN. Our results reveal a moment-wise progression in training: networks first capture low-order statistics such as mean and covariance, and progressively learn high-order cumulants. Finally, we pretrain the generative model on the Fashion-MNIST dataset and leverage the generated samples for further experiments. The results of these additional experiments confirm our conclusions and show the utility of the data model in a real-world scenario. Overall, our proposed approach bridges simplified data assumptions and practical data complexity, which offers a principled framework for investigating distributional effects in machine learning and signal processing.",
    "published": "2026-02-02T14:29:33Z",
    "updated": "2026-02-02T14:29:33Z",
    "authors": [
      "Onat Ure",
      "Samet Demir",
      "Zafer Dogan"
    ],
    "primary_category": "stat.ML",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02153v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02153v1",
    "comment": "ICASSP 2026, 5 pages, 2 figures",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 6.0,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02151v1",
    "title": "Revisiting Adaptive Rounding with Vectorized Reparameterization for LLM Quantization",
    "summary": "Adaptive Rounding has emerged as an alternative to round-to-nearest (RTN) for post-training quantization by enabling cross-element error cancellation. Yet, dense and element-wise rounding matrices are prohibitively expensive for billion-parameter large language models (LLMs). We revisit adaptive rounding from an efficiency perspective and propose VQRound, a parameter-efficient optimization framework that reparameterizes the rounding matrix into a compact codebook. Unlike low-rank alternatives, VQRound minimizes the element-wise worst-case error under $L_\\infty$ norm, which is critical for handling heavy-tailed weight distributions in LLMs. Beyond reparameterization, we identify rounding initialization as a decisive factor and develop a lightweight end-to-end finetuning pipeline that optimizes codebooks across all layers using only 128 samples. Extensive experiments on OPT, LLaMA, LLaMA2, and Qwen3 models demonstrate that VQRound achieves better convergence than traditional adaptive rounding at the same number of steps while using as little as 0.2% of the trainable parameters. Our results show that adaptive rounding can be made both scalable and fast-fitting. The code is available at https://github.com/zhoustan/VQRound.",
    "published": "2026-02-02T14:27:12Z",
    "updated": "2026-02-02T14:27:12Z",
    "authors": [
      "Yuli Zhou",
      "Qingxuan Chen",
      "Luca Benini",
      "Guolei Sun",
      "Yawei Li"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02151v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02151v1",
    "comment": "17 pages, 6 figures, 14 tables",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 6.0,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02126v1",
    "title": "Two-Stage Grid Optimization for Group-wise Quantization of LLMs",
    "summary": "Group-wise quantization is an effective strategy for mitigating accuracy degradation in low-bit quantization of large language models (LLMs). Among existing methods, GPTQ has been widely adopted due to its efficiency; however, it neglects input statistics and inter-group correlations when determining group scales, leading to a mismatch with its goal of minimizing layer-wise reconstruction loss. In this work, we propose a two-stage optimization framework for group scales that explicitly minimizes the layer-wise reconstruction loss. In the first stage, performed prior to GPTQ, we initialize each group scale to minimize the group-wise reconstruction loss, thereby incorporating input statistics. In the second stage, we freeze the integer weights obtained via GPTQ and refine the group scales to minimize the layer-wise reconstruction loss. To this end, we employ the coordinate descent algorithm and derive a closed-form update rule, which enables efficient refinement without costly numerical optimization. Notably, our derivation incorporates the quantization errors from preceding layers to prevent error accumulation. Experimental results demonstrate that our method consistently enhances group-wise quantization, achieving higher accuracy with negligible overhead.",
    "published": "2026-02-02T14:12:34Z",
    "updated": "2026-02-02T14:12:34Z",
    "authors": [
      "Junhan Kim",
      "Gukryeol Lee",
      "Seungwoo Son",
      "Jeewook Kim",
      "Yongkweon Jeon"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02126v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02126v1",
    "comment": "ICASSP 2026",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 6.0,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02103v1",
    "title": "No Global Plan in Chain-of-Thought: Uncover the Latent Planning Horizon of LLMs",
    "summary": "This work stems from prior complementary observations on the dynamics of Chain-of-Thought (CoT): Large Language Models (LLMs) is shown latent planning of subsequent reasoning prior to CoT emergence, thereby diminishing the significance of explicit CoT; whereas CoT remains critical for tasks requiring multi-step reasoning. To deepen the understanding between LLM's internal states and its verbalized reasoning trajectories, we investigate the latent planning strength of LLMs, through our probing method, Tele-Lens, applying to hidden states across diverse task domains. Our empirical results indicate that LLMs exhibit a myopic horizon, primarily conducting incremental transitions without precise global planning. Leveraging this characteristic, we propose a hypothesis on enhancing uncertainty estimation of CoT, which we validate that a small subset of CoT positions can effectively represent the uncertainty of the entire path. We further underscore the significance of exploiting CoT dynamics, and demonstrate that automatic recognition of CoT bypass can be achieved without performance degradation. Our code, data and models are released at https://github.com/lxucs/tele-lens.",
    "published": "2026-02-02T13:46:56Z",
    "updated": "2026-02-02T13:46:56Z",
    "authors": [
      "Liyan Xu",
      "Mo Yu",
      "Fandong Meng",
      "Jie Zhou"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02103v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02103v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 6.0,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02090v1",
    "title": "LEC-KG: An LLM-Embedding Collaborative Framework for Domain-Specific Knowledge Graph Construction -- A Case Study on SDGs",
    "summary": "Constructing domain-specific knowledge graphs from unstructured text remains challenging due to heterogeneous entity mentions, long-tail relation distributions, and the absence of standardized schemas. We present LEC-KG, a bidirectional collaborative framework that integrates the semantic understanding of Large Language Models (LLMs) with the structural reasoning of Knowledge Graph Embeddings (KGE). Our approach features three key components: (1) hierarchical coarse-to-fine relation extraction that mitigates long-tail bias, (2) evidence-guided Chain-of-Thought feedback that grounds structural suggestions in source text, and (3) semantic initialization that enables structural validation for unseen entities. The two modules enhance each other iteratively-KGE provides structure-aware feedback to refine LLM extractions, while validated triples progressively improve KGE representations. We evaluate LEC-KG on Chinese Sustainable Development Goal (SDG) reports, demonstrating substantial improvements over LLM baselines, particularly on low-frequency relations. Through iterative refinement, our framework reliably transforms unstructured policy text into validated knowledge graph triples.",
    "published": "2026-02-02T13:37:17Z",
    "updated": "2026-02-02T13:37:17Z",
    "authors": [
      "Yikai Zeng",
      "Yingchao Piao",
      "Jianhui Li"
    ],
    "primary_category": "cs.CL",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02090v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02090v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 6.0,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02063v1",
    "title": "See2Refine: Vision-Language Feedback Improves LLM-Based eHMI Action Designers",
    "summary": "Automated vehicles lack natural communication channels with other road users, making external Human-Machine Interfaces (eHMIs) essential for conveying intent and maintaining trust in shared environments. However, most eHMI studies rely on developer-crafted message-action pairs, which are difficult to adapt to diverse and dynamic traffic contexts. A promising alternative is to use Large Language Models (LLMs) as action designers that generate context-conditioned eHMI actions, yet such designers lack perceptual verification and typically depend on fixed prompts or costly human-annotated feedback for improvement. We present See2Refine, a human-free, closed-loop framework that uses vision-language model (VLM) perceptual evaluation as automated visual feedback to improve an LLM-based eHMI action designer. Given a driving context and a candidate eHMI action, the VLM evaluates the perceived appropriateness of the action, and this feedback is used to iteratively revise the designer's outputs, enabling systematic refinement without human supervision. We evaluate our framework across three eHMI modalities (lightbar, eyes, and arm) and multiple LLM model sizes. Across settings, our framework consistently outperforms prompt-only LLM designers and manually specified baselines in both VLM-based metrics and human-subject evaluations. Results further indicate that the improvements generalize across modalities and that VLM evaluations are well aligned with human preferences, supporting the robustness and effectiveness of See2Refine for scalable action design.",
    "published": "2026-02-02T13:03:48Z",
    "updated": "2026-02-02T13:03:48Z",
    "authors": [
      "Ding Xia",
      "Xinyue Gui",
      "Mark Colley",
      "Fan Gao",
      "Zhongyi Zhou",
      "Dongyuan Li",
      "Renhe Jiang",
      "Takeo Igarashi"
    ],
    "primary_category": "cs.HC",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02063v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02063v1",
    "comment": "Under Review",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 6.0,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02027v1",
    "title": "Light Alignment Improves LLM Safety via Model Self-Reflection with a Single Neuron",
    "summary": "The safety of large language models (LLMs) has increasingly emerged as a fundamental aspect of their development. Existing safety alignment for LLMs is predominantly achieved through post-training methods, which are computationally expensive and often fail to generalize well across different models. A small number of lightweight alignment approaches either rely heavily on prior-computed safety injections or depend excessively on the model's own capabilities, resulting in limited generalization and degraded efficiency and usability during generation. In this work, we propose a safety-aware decoding method that requires only low-cost training of an expert model and employs a single neuron as a gating mechanism. By effectively balancing the model's intrinsic capabilities with external guidance, our approach simultaneously preserves utility and enhances output safety. It demonstrates clear advantages in training overhead and generalization across model scales, offering a new perspective on lightweight alignment for the safe and practical deployment of large language models. Code: https://github.com/Beijing-AISI/NGSD.",
    "published": "2026-02-02T12:21:54Z",
    "updated": "2026-02-02T12:21:54Z",
    "authors": [
      "Sicheng Shen",
      "Mingyang Lv",
      "Han Shen",
      "Jialin Wu",
      "Binghao Wang",
      "Zhou Yang",
      "Guobin Shen",
      "Dongcheng Zhao",
      "Feifei Zhao",
      "Yi Zeng"
    ],
    "primary_category": "cs.AI",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02027v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02027v1",
    "comment": "21 pages, 3 figures",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 6.0,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02007v1",
    "title": "Beyond RAG for Agent Memory: Retrieval by Decoupling and Aggregation",
    "summary": "Agent memory systems often adopt the standard Retrieval-Augmented Generation (RAG) pipeline, yet its underlying assumptions differ in this setting. RAG targets large, heterogeneous corpora where retrieved passages are diverse, whereas agent memory is a bounded, coherent dialogue stream with highly correlated spans that are often duplicates. Under this shift, fixed top-$k$ similarity retrieval tends to return redundant context, and post-hoc pruning can delete temporally linked prerequisites needed for correct reasoning. We argue retrieval should move beyond similarity matching and instead operate over latent components, following decoupling to aggregation: disentangle memories into semantic components, organise them into a hierarchy, and use this structure to drive retrieval. We propose xMemory, which builds a hierarchy of intact units and maintains a searchable yet faithful high-level node organisation via a sparsity--semantics objective that guides memory split and merge. At inference, xMemory retrieves top-down, selecting a compact, diverse set of themes and semantics for multi-fact queries, and expanding to episodes and raw messages only when it reduces the reader's uncertainty. Experiments on LoCoMo and PerLTQA across the three latest LLMs show consistent gains in answer quality and token efficiency.",
    "published": "2026-02-02T12:04:58Z",
    "updated": "2026-02-02T12:04:58Z",
    "authors": [
      "Zhanghao Hu",
      "Qinglin Zhu",
      "Hanqi Yan",
      "Yulan He",
      "Lin Gui"
    ],
    "primary_category": "cs.CL",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02007v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02007v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 6.0,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01997v1",
    "title": "On the Limits of Layer Pruning for Generative Reasoning in LLMs",
    "summary": "Recent works have shown that layer pruning can compress large language models (LLMs) while retaining strong performance on classification benchmarks with little or no finetuning. However, existing pruning techniques often suffer severe degradation on generative reasoning tasks. Through a systematic study across multiple model families, we find that tasks requiring multi-step reasoning are particularly sensitive to depth reduction. Beyond surface-level text degeneration, we observe degradation of critical algorithmic capabilities, including arithmetic computation for mathematical reasoning and balanced parenthesis generation for code synthesis. Under realistic post-training constraints, without access to pretraining-scale data or compute, we evaluate a simple mitigation strategy based on supervised finetuning with Self-Generated Responses. This approach achieves strong recovery on classification tasks, retaining up to 90\\% of baseline performance, and yields substantial gains of up to 20--30 percentage points on generative benchmarks compared to prior post-pruning techniques. Crucially, despite these gains, recovery for generative reasoning remains fundamentally limited relative to classification tasks and is viable primarily at lower pruning ratios. Overall, we characterize the practical limits of layer pruning for generative reasoning and provide guidance on when depth reduction can be applied effectively under constrained post-training regimes.",
    "published": "2026-02-02T11:57:22Z",
    "updated": "2026-02-02T11:57:22Z",
    "authors": [
      "Safal Shrestha",
      "Anubhav Shrestha",
      "Aadim Nepal",
      "Minwu Kim",
      "Keith Ross"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01997v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01997v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 6.0,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01956v1",
    "title": "Efficient Epistemic Uncertainty Estimation for Large Language Models via Knowledge Distillation",
    "summary": "Quantifying uncertainty in Large Language Models (LLMs) is essential for mitigating hallucinations and enabling risk-aware deployment in safety-critical tasks. However, estimating Epistemic Uncertainty(EU) via Deep Ensembles is computationally prohibitive at the scale of modern models. We propose a framework that leverages the small draft models to efficiently estimate token-level EU, bypassing the need for full-scale ensembling. Theoretically grounded in a Bias-Variance Decomposition, our approach approximates EU via Jensen-Shannon divergence among drafts (variance proxy) and KL divergence between the draft mixture and the target (bias proxy). To further ensure accuracy without significant overhead, we introduce Online Stochastic Distillation (OSD) to efficiently approximate target aggregation and the Data-Diverse Drafts (DDD) strategy to enhance draft diversity for better target approximation. Extensive experiments on GSM8K demonstrate that our method reduces the estimation error (RMSE) by up to 37% compared to baselines. Crucially, our approach achieves Hallucination Detection performance competitive with heavy perturbation-based methods like TokUR while incurring negligible inference costs, offering a practical solution for uncertainty-aware LLM deployment.",
    "published": "2026-02-02T11:03:37Z",
    "updated": "2026-02-02T11:03:37Z",
    "authors": [
      "Seonghyeon Park",
      "Jewon Yeom",
      "Jaewon Sok",
      "Jeongjae Park",
      "Heejun Kim",
      "Taesup Kim"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01956v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01956v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 6.0,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01942v1",
    "title": "Human Society-Inspired Approaches to Agentic AI Security: The 4C Framework",
    "summary": "AI is moving from domain-specific autonomy in closed, predictable settings to large-language-model-driven agents that plan and act in open, cross-organizational environments. As a result, the cybersecurity risk landscape is changing in fundamental ways. Agentic AI systems can plan, act, collaborate, and persist over time, functioning as participants in complex socio-technical ecosystems rather than as isolated software components. Although recent work has strengthened defenses against model and pipeline level vulnerabilities such as prompt injection, data poisoning, and tool misuse, these system centric approaches may fail to capture risks that arise from autonomy, interaction, and emergent behavior. This article introduces the 4C Framework for multi-agent AI security, inspired by societal governance. It organizes agentic risks across four interdependent dimensions: Core (system, infrastructure, and environmental integrity), Connection (communication, coordination, and trust), Cognition (belief, goal, and reasoning integrity), and Compliance (ethical, legal, and institutional governance). By shifting AI security from a narrow focus on system-centric protection to the broader preservation of behavioral integrity and intent, the framework complements existing AI security strategies and offers a principled foundation for building agentic AI systems that are trustworthy, governable, and aligned with human values.",
    "published": "2026-02-02T10:45:16Z",
    "updated": "2026-02-02T10:45:16Z",
    "authors": [
      "Alsharif Abuadbba",
      "Nazatul Sultan",
      "Surya Nepal",
      "Sanjay Jha"
    ],
    "primary_category": "cs.CR",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01942v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01942v1",
    "comment": "10 pages",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 6.0,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01933v1",
    "title": "Large Language Model and Formal Concept Analysis: a comparative study for Topic Modeling",
    "summary": "Topic modeling is a research field finding increasing applications: historically from document retrieving, to sentiment analysis and text summarization. Large Language Models (LLM) are currently a major trend in text processing, but few works study their usefulness for this task. Formal Concept Analysis (FCA) has recently been presented as a candidate for topic modeling, but no real applied case study has been conducted. In this work, we compare LLM and FCA to better understand their strengths and weakneses in the topic modeling field. FCA is evaluated through the CREA pipeline used in past experiments on topic modeling and visualization, whereas GPT-5 is used for the LLM. A strategy based on three prompts is applied with GPT-5 in a zero-shot setup: topic generation from document batches, merging of batch results into final topics, and topic labeling. A first experiment reuses the teaching materials previously used to evaluate CREA, while a second experiment analyzes 40 research articles in information systems to compare the extracted topics with the underling subfields.",
    "published": "2026-02-02T10:35:42Z",
    "updated": "2026-02-02T10:35:42Z",
    "authors": [
      "Fabrice Boissier",
      "Monica Sen",
      "Irina Rychkova"
    ],
    "primary_category": "cs.AI",
    "categories": [
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01933v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01933v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 6.0,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01910v1",
    "title": "DomusFM: A Foundation Model for Smart-Home Sensor Data",
    "summary": "Smart-home sensor data holds significant potential for several applications, including healthcare monitoring and assistive technologies. Existing approaches, however, face critical limitations. Supervised models require impractical amounts of labeled data. Foundation models for activity recognition focus only on inertial sensors, failing to address the unique characteristics of smart-home binary sensor events: their sparse, discrete nature combined with rich semantic associations. LLM-based approaches, while tested in this domain, still raise several issues regarding the need for natural language descriptions or prompting, and reliance on either external services or expensive hardware, making them infeasible in real-life scenarios due to privacy and cost concerns. We introduce DomusFM, the first foundation model specifically designed and pretrained for smart-home sensor data. DomusFM employs a self-supervised dual contrastive learning paradigm to capture both token-level semantic attributes and sequence-level temporal dependencies. By integrating semantic embeddings from a lightweight language model and specialized encoders for temporal patterns and binary states, DomusFM learns generalizable representations that transfer across environments and tasks related to activity and event analysis. Through leave-one-dataset-out evaluation across seven public smart-home datasets, we demonstrate that DomusFM outperforms state-of-the-art baselines on different downstream tasks, achieving superior performance even with only 5% of labeled training data available for fine-tuning. Our approach addresses data scarcity while maintaining practical deployability for real-world smart-home systems.",
    "published": "2026-02-02T10:16:34Z",
    "updated": "2026-02-02T10:16:34Z",
    "authors": [
      "Michele Fiori",
      "Gabriele Civitarese",
      "Flora D. Salim",
      "Claudio Bettini"
    ],
    "primary_category": "cs.AI",
    "categories": [
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01910v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01910v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 6.0,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01901v1",
    "title": "Q Cache: Visual Attention is Valuable in Less than Half of Decode Layers for Multimodal Large Language Model",
    "summary": "Multimodal large language models (MLLMs) are plagued by exorbitant inference costs attributable to the profusion of visual tokens within the vision encoder. The redundant visual tokens engenders a substantial computational load and key-value (KV) cache footprint bottleneck. Existing approaches focus on token-wise optimization, leveraging diverse intricate token pruning techniques to eliminate non-crucial visual tokens. Nevertheless, these methods often unavoidably undermine the integrity of the KV cache, resulting in failures in long-text generation tasks. To this end, we conduct an in-depth investigation towards the attention mechanism of the model from a new perspective, and discern that attention within more than half of all decode layers are semantic similar. Upon this finding, we contend that the attention in certain layers can be streamlined by inheriting the attention from their preceding layers. Consequently, we propose Lazy Attention, an efficient attention mechanism that enables cross-layer sharing of similar attention patterns. It ingeniously reduces layer-wise redundant computation in attention. In Lazy Attention, we develop a novel layer-shared cache, Q Cache, tailored for MLLMs, which facilitates the reuse of queries across adjacent layers. In particular, Q Cache is lightweight and fully compatible with existing inference frameworks, including Flash Attention and KV cache. Additionally, our method is highly flexible as it is orthogonal to existing token-wise techniques and can be deployed independently or combined with token pruning approaches. Empirical evaluations on multiple benchmarks demonstrate that our method can reduce KV cache usage by over 35% and achieve 1.5x throughput improvement, while sacrificing only approximately 1% of performance on various MLLMs. Compared with SOTA token-wise methods, our technique achieves superior accuracy preservation.",
    "published": "2026-02-02T10:08:00Z",
    "updated": "2026-02-02T10:08:00Z",
    "authors": [
      "Jiedong Zhuang",
      "Lu Lu",
      "Ming Dai",
      "Rui Hu",
      "Jian Chen",
      "Qiang Liu",
      "Haoji Hu"
    ],
    "primary_category": "cs.CV",
    "categories": [
      "cs.CV"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01901v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01901v1",
    "comment": "Accepted by AAAI26",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 6.0,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01897v1",
    "title": "Internal Flow Signatures for Self-Checking and Refinement in LLMs",
    "summary": "Large language models can generate fluent answers that are unfaithful to the provided context, while many safeguards rely on external verification or a separate judge after generation. We introduce \\emph{internal flow signatures} that audit decision formation from depthwise dynamics at a fixed inter-block monitoring boundary. The method stabilizes token-wise motion via bias-centered monitoring, then summarizes trajectories in compact \\emph{moving} readout-aligned subspaces constructed from the top token and its close competitors within each depth window. Neighboring window frames are aligned by an orthogonal transport, yielding depth-comparable transported step lengths, turning angles, and subspace drift summaries that are invariant to within-window basis choices. A lightweight GRU validator trained on these signatures performs self-checking without modifying the base model. Beyond detection, the validator localizes a culprit depth event and enables a targeted refinement: the model rolls back to the culprit token and clamps an abnormal transported step at the identified block while preserving the orthogonal residual. The resulting pipeline provides actionable localization and low-overhead self-checking from internal decision dynamics. \\emph{Code is available at} \\texttt{github.com/EavnJeong/Internal-Flow-Signatures-for-Self-Checking-and-Refinement-in-LLMs}.",
    "published": "2026-02-02T10:05:54Z",
    "updated": "2026-02-02T10:05:54Z",
    "authors": [
      "Sungheon Jeong",
      "Sanggeon Yun",
      "Ryozo Masukawa",
      "Wenjun Haung",
      "Hanning Chen",
      "Mohsen Imani"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01897v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01897v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 6.0,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01855v1",
    "title": "Time2Vec-Integrated Transformer for Robust Gesture Recognition from Low-Density sEMG",
    "summary": "Accurate and responsive myoelectric prosthesis control typically relies on complex, dense multi-sensor arrays, which limits consumer accessibility. This paper presents a novel, data-efficient deep learning framework designed to achieve precise and accurate control using minimal sensor hardware. Leveraging an external dataset of 8 subjects, our approach implements a hybrid Transformer optimized for sparse, two-channel surface electromyography (sEMG). Unlike standard architectures that use fixed positional encodings, we integrate Time2Vec learnable temporal embeddings to capture the stochastic temporal warping inherent in biological signals. Furthermore, we employ a normalized additive fusion strategy that aligns the latent distributions of spatial and temporal features, preventing the destructive interference common in standard implementations. A two-stage curriculum learning protocol is utilized to ensure robust feature extraction despite data scarcity. The proposed architecture achieves a state-of-the-art multi-subject F1-score of 95.7% $\\pm$ 0.20% for a 10-class movement set, statistically outperforming both a standard Transformer with fixed encodings and a recurrent CNN-LSTM model. Architectural optimization reveals that a balanced allocation of model capacity between spatial and temporal dimensions yields the highest stability. Furthermore, while direct transfer to a new unseen subject led to poor accuracy due to domain shifts, a rapid calibration protocol utilizing only two trials per gesture recovered performance from 21.0% $\\pm$ 2.98% to 96.9% $\\pm$ 0.52%. By validating that high-fidelity temporal embeddings can compensate for low spatial resolution, this work challenges the necessity of high-density sensing. The proposed framework offers a robust, cost-effective blueprint for next-generation prosthetic interfaces capable of rapid personalization.",
    "published": "2026-02-02T09:28:27Z",
    "updated": "2026-02-02T09:28:27Z",
    "authors": [
      "Blagoj Hristov",
      "Hristijan Gjoreski",
      "Vesna Ojleska Latkoska",
      "Gorjan Nadzinski"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SP"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01855v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01855v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 6.0,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01816v1",
    "title": "Seeing Is Believing? A Benchmark for Multimodal Large Language Models on Visual Illusions and Anomalies",
    "summary": "Multimodal Large Language Models (MLLMs) have shown remarkable proficiency on general-purpose vision-language benchmarks, reaching or even exceeding human-level performance. However, these evaluations typically rely on standard in-distribution data, leaving the robustness of MLLMs largely unexamined when faced with scenarios that defy common-sense priors. To address this gap, we introduce VIA-Bench, a challenging benchmark designed to probe model performance on visual illusions and anomalies. It includes six core categories: color illusions, motion illusions, gestalt illusions, geometric and spatial illusions, general visual illusions, and visual anomalies. Through careful human-in-the-loop review, we construct over 1K high-quality question-answer pairs that require nuanced visual reasoning. Extensive evaluation of over 20 state-of-the-art MLLMs, including proprietary, open-source, and reasoning-enhanced models, uncovers significant vulnerabilities. Notably, we find that Chain-of-Thought (CoT) reasoning offers negligible robustness, often yielding ``brittle mirages'' where the model's logic collapses under illusory stimuli. Our findings reveal a fundamental divergence between machine and human perception, suggesting that resolving such perceptual bottlenecks is critical for the advancement of artificial general intelligence. The benchmark data and code will be released.",
    "published": "2026-02-02T08:48:03Z",
    "updated": "2026-02-02T08:48:03Z",
    "authors": [
      "Wenjin Hou",
      "Wei Liu",
      "Han Hu",
      "Xiaoxiao Sun",
      "Serena Yeung-Levy",
      "Hehe Fan"
    ],
    "primary_category": "cs.CV",
    "categories": [
      "cs.CV"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01816v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01816v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 6.0,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01814v1",
    "title": "GPD: Guided Progressive Distillation for Fast and High-Quality Video Generation",
    "summary": "Diffusion models have achieved remarkable success in video generation; however, the high computational cost of the denoising process remains a major bottleneck. Existing approaches have shown promise in reducing the number of diffusion steps, but they often suffer from significant quality degradation when applied to video generation. We propose Guided Progressive Distillation (GPD), a framework that accelerates the diffusion process for fast and high-quality video generation. GPD introduces a novel training strategy in which a teacher model progressively guides a student model to operate with larger step sizes. The framework consists of two key components: (1) an online-generated training target that reduces optimization difficulty while improving computational efficiency, and (2) frequency-domain constraints in the latent space that promote the preservation of fine-grained details and temporal dynamics. Applied to the Wan2.1 model, GPD reduces the number of sampling steps from 48 to 6 while maintaining competitive visual quality on VBench. Compared with existing distillation methods, GPD demonstrates clear advantages in both pipeline simplicity and quality preservation.",
    "published": "2026-02-02T08:47:33Z",
    "updated": "2026-02-02T08:47:33Z",
    "authors": [
      "Xiao Liang",
      "Yunzhu Zhang",
      "Linchao Zhu"
    ],
    "primary_category": "cs.CV",
    "categories": [
      "cs.CV"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01814v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01814v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 6.0,
    "matched_areas": [
      "ai",
      "vision"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01791v1",
    "title": "Grad2Reward: From Sparse Judgment to Dense Rewards for Improving Open-Ended LLM Reasoning",
    "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has catalyzed significant breakthroughs in complex LLM reasoning within verifiable domains, such as mathematics and programming. Recent efforts have sought to extend this paradigm to open-ended tasks by employing LLMs-as-a-Judge to provide sequence-level rewards for policy optimization. However, these rewards are inherently sparse, failing to provide the fine-grained supervision necessary for generating complex, long-form trajectories. Furthermore, current work treats the Judge as a black-box oracle, discarding the rich intermediate feedback signals encoded in it. To address these limitations, we introduce Grad2Reward, a novel framework that extracts dense process rewards directly from the Judge's model inference process via a single backward pass. By leveraging gradient-based attribution, Grad2Reward enables precise token-level credit assignment, substantially enhancing training efficiency and reasoning quality. Additionally, Grad2Reward introduces a self-judging mechanism, allowing the policy to improve through its own evaluative signals without training specialized reward models or reliance on superior external Judges. The experiments demonstrate that policies optimized with Grad2Reward achieve outstanding performance across diverse open-ended tasks, affirming its effectiveness and broad generalizability.",
    "published": "2026-02-02T08:13:13Z",
    "updated": "2026-02-02T08:13:13Z",
    "authors": [
      "Zheng Zhang",
      "Ao Lu",
      "Yuanhao Zeng",
      "Ziwei Shan",
      "Jinjin Guo",
      "Lufei Li",
      "Yexin Li",
      "Kan Ren"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01791v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01791v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 6.0,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01789v1",
    "title": "RFS: Reinforcement learning with Residual flow steering for dexterous manipulation",
    "summary": "Imitation learning has emerged as an effective approach for bootstrapping sequential decision-making in robotics, achieving strong performance even in high-dimensional dexterous manipulation tasks. Recent behavior cloning methods further leverage expressive generative models, such as diffusion models and flow matching, to represent multimodal action distributions. However, policies pretrained in this manner often exhibit limited generalization and require additional fine-tuning to achieve robust performance at deployment time. Such adaptation must preserve the global exploration benefits of pretraining while enabling rapid correction of local execution errors.We propose \\emph{Residual Flow Steering} (RFS), a data-efficient reinforcement learning framework for adapting pretrained generative policies. RFS steers a pretrained flow-matching policy by jointly optimizing a residual action and a latent noise distribution, enabling complementary forms of exploration: local refinement through residual corrections and global exploration through latent-space modulation. This design allows efficient adaptation while retaining the expressive structure of the pretrained policy.We demonstrate the effectiveness of RFS on dexterous manipulation tasks, showing efficient fine-tuning both in simulation and in real-world settings when adapting pretrained base policies.Project website:https://weirdlabuw.github.io/rfs.",
    "published": "2026-02-02T08:11:57Z",
    "updated": "2026-02-02T08:11:57Z",
    "authors": [
      "Entong Su",
      "Tyler Westenbroek",
      "Anusha Nagabandi",
      "Abhishek Gupta"
    ],
    "primary_category": "cs.RO",
    "categories": [
      "cs.RO"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01789v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01789v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 6.0,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01779v1",
    "title": "LingLanMiDian: Systematic Evaluation of LLMs on TCM Knowledge and Clinical Reasoning",
    "summary": "Large language models (LLMs) are advancing rapidly in medical NLP, yet Traditional Chinese Medicine (TCM) with its distinctive ontology, terminology, and reasoning patterns requires domain-faithful evaluation. Existing TCM benchmarks are fragmented in coverage and scale and rely on non-unified or generation-heavy scoring that hinders fair comparison. We present the LingLanMiDian (LingLan) benchmark, a large-scale, expert-curated, multi-task suite that unifies evaluation across knowledge recall, multi-hop reasoning, information extraction, and real-world clinical decision-making. LingLan introduces a consistent metric design, a synonym-tolerant protocol for clinical labels, a per-dataset 400-item Hard subset, and a reframing of diagnosis and treatment recommendation into single-choice decision recognition. We conduct comprehensive, zero-shot evaluations on 14 leading open-source and proprietary LLMs, providing a unified perspective on their strengths and limitations in TCM commonsense knowledge understanding, reasoning, and clinical decision support; critically, the evaluation on Hard subset reveals a substantial gap between current models and human experts in TCM-specialized reasoning. By bridging fundamental knowledge and applied reasoning through standardized evaluation, LingLan establishes a unified, quantitative, and extensible foundation for advancing TCM LLMs and domain-specific medical AI research. All evaluation data and code are available at https://github.com/TCMAI-BJTU/LingLan and http://tcmnlp.com.",
    "published": "2026-02-02T08:02:25Z",
    "updated": "2026-02-02T08:02:25Z",
    "authors": [
      "Rui Hua",
      "Yu Wei",
      "Zixin Shu",
      "Kai Chang",
      "Dengying Yan",
      "Jianan Xia",
      "Zeyu Liu",
      "Hui Zhu",
      "Shujie Song",
      "Mingzhong Xiao",
      "Xiaodong Li",
      "Dongmei Jia",
      "Zhuye Gao",
      "Yanyan Meng",
      "Naixuan Zhao",
      "Yu Fu",
      "Haibin Yu",
      "Benman Yu",
      "Yuanyuan Chen",
      "Fei Dong",
      "Zhizhou Meng",
      "Pengcheng Yang",
      "Songxue Zhao",
      "Lijuan Pei",
      "Yunhui Hu",
      "Kan Ding",
      "Jiayuan Duan",
      "Wenmao Yin",
      "Yang Gu",
      "Runshun Zhang",
      "Qiang Zhu",
      "Jian Yu",
      "Jiansheng Li",
      "Baoyan Liu",
      "Wenjia Wang",
      "Xuezhong Zhou"
    ],
    "primary_category": "cs.AI",
    "categories": [
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01779v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01779v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 6.0,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01776v1",
    "title": "Position: Beyond Model-Centric Prediction -- Agentic Time Series Forecasting",
    "summary": "Time series forecasting has traditionally been formulated as a model-centric, static, and single-pass prediction problem that maps historical observations to future values. While this paradigm has driven substantial progress, it proves insufficient in adaptive and multi-turn settings where forecasting requires informative feature extraction, reasoning-driven inference, iterative refinement, and continual adaptation over time. In this paper, we argue for agentic time series forecasting (ATSF), which reframes forecasting as an agentic process composed of perception, planning, action, reflection, and memory. Rather than focusing solely on predictive models, ATSF emphasizes organizing forecasting as an agentic workflow that can interact with tools, incorporate feedback from outcomes, and evolve through experience accumulation. We outline three representative implementation paradigms -- workflow-based design, agentic reinforcement learning, and a hybrid agentic workflow paradigm -- and discuss the opportunities and challenges that arise when shifting from model-centric prediction to agentic forecasting. Together, this position aims to establish agentic forecasting as a foundation for future research at the intersection of time series forecasting.",
    "published": "2026-02-02T08:01:11Z",
    "updated": "2026-02-02T08:01:11Z",
    "authors": [
      "Mingyue Cheng",
      "Xiaoyu Tao",
      "Qi Liu",
      "Ze Guo",
      "Enhong Chen"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01776v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01776v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 6.0,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01771v1",
    "title": "<SOG_k>: One LLM Token for Explicit Graph Structural Understanding",
    "summary": "Large language models show great potential in unstructured data understanding, but still face significant challenges with graphs due to their structural hallucination. Existing approaches mainly either verbalize graphs into natural language, which leads to excessive token consumption and scattered attention, or transform graphs into trainable continuous embeddings (i.e., soft prompt), but exhibit severe misalignment with original text tokens. To solve this problem, we propose to incorporate one special token <SOG_k> to fully represent the Structure Of Graph within a unified token space, facilitating explicit topology input and structural information sharing. Specifically, we propose a topology-aware structural tokenizer that maps each graph topology into a highly selective single token. Afterwards, we construct a set of hybrid structure Question-Answering corpora to align new structural tokens with existing text tokens. With this approach, <SOG_k> empowers LLMs to understand, generate, and reason in a concise and accurate manner. Extensive experiments on five graph-level benchmarks demonstrate the superiority of our method, achieving a performance improvement of 9.9% to 41.4% compared to the baselines while exhibiting interpretability and consistency. Furthermore, our method provides a flexible extension to node-level tasks, enabling both global and local structural understanding. The codebase is publicly available at https://github.com/Jingyao-Wu/SOG.",
    "published": "2026-02-02T07:55:09Z",
    "updated": "2026-02-02T07:55:09Z",
    "authors": [
      "Jingyao Wu",
      "Bin Lu",
      "Zijun Di",
      "Xiaoying Gan",
      "Meng Jin",
      "Luoyi Fu",
      "Xinbing Wang",
      "Chenghu Zhou"
    ],
    "primary_category": "cs.CL",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.NI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01771v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01771v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 6.0,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01734v1",
    "title": "MSign: An Optimizer Preventing Training Instability in Large Language Models via Stable Rank Restoration",
    "summary": "Training instability remains a critical challenge in large language model (LLM) pretraining, often manifesting as sudden gradient explosions that waste significant computational resources. We study training failures in a 5M-parameter NanoGPT model scaled via $$P, identifying two key phenomena preceding collapse: (1) rapid decline in weight matrix stable rank (ratio of squared Frobenius norm to squared spectral norm), and (2) increasing alignment between adjacent layer Jacobians. We prove theoretically that these two conditions jointly cause exponential gradient norm growth with network depth. To break this instability mechanism, we propose MSign, a new optimizer that periodically applies matrix sign operations to restore stable rank. Experiments on models from 5M to 3B parameters demonstrate that MSign effectively prevents training failures with a computational overhead of less than 7.0%.",
    "published": "2026-02-02T07:18:45Z",
    "updated": "2026-02-02T07:18:45Z",
    "authors": [
      "Lianhai Ren",
      "Yucheng Ding",
      "Xiao Liu",
      "Qianxiao Li",
      "Peng Cheng",
      "Yeyun Gong"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01734v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01734v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 6.0,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01726v1",
    "title": "Cross-Domain Fake News Detection on Unseen Domains via LLM-Based Domain-Aware User Modeling",
    "summary": "Cross-domain fake news detection (CD-FND) transfers knowledge from a source domain to a target domain and is crucial for real-world fake news mitigation. This task becomes particularly important yet more challenging when the target domain is previously unseen (e.g., the COVID-19 outbreak or the Russia-Ukraine war). However, existing CD-FND methods overlook such scenarios and consequently suffer from the following two key limitations: (1) insufficient modeling of high-level semantics in news and user engagements; and (2) scarcity of labeled data in unseen domains. Targeting these limitations, we find that large language models (LLMs) offer strong potential for CD-FND on unseen domains, yet their effective use remains non-trivial. Nevertheless, two key challenges arise: (1) how to capture high-level semantics from both news content and user engagements using LLMs; and (2) how to make LLM-generated features more reliable and transferable for CD-FND on unseen domains. To tackle these challenges, we propose DAUD, a novel LLM-Based Domain-Aware framework for fake news detection on Unseen Domains. DAUD employs LLMs to extract high-level semantics from news content. It models users' single- and cross-domain engagements to generate domain-aware behavioral representations. In addition, DAUD captures the relations between original data-driven features and LLM-derived features of news, users, and user engagements. This allows it to extract more reliable domain-shared representations that improve knowledge transfer to unseen domains. Extensive experiments on real-world datasets demonstrate that DAUD outperforms state-of-the-art baselines in both general and unseen-domain CD-FND settings.",
    "published": "2026-02-02T07:04:13Z",
    "updated": "2026-02-02T07:04:13Z",
    "authors": [
      "Xuankai Yang",
      "Yan Wang",
      "Jiajie Zhu",
      "Pengfei Ding",
      "Hongyang Liu",
      "Xiuzhen Zhang",
      "Huan Liu"
    ],
    "primary_category": "cs.SI",
    "categories": [
      "cs.SI",
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01726v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01726v1",
    "comment": "This paper has been accepted by The 2026 ACM Web Conference (WWW 2026)",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 6.0,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01708v1",
    "title": "Game of Thought: Robust Information Seeking with Large Language Models Using Game Theory",
    "summary": "Large Language Models (LLMs) are increasingly deployed in real-world scenarios where they may lack sufficient information to complete a given task. In such settings, the ability to actively seek out missing information becomes a critical capability. Existing approaches to enhancing this ability often rely on simplifying assumptions that degrade \\textit{worst-case} performance. This is an issue with serious implications in high-stakes applications. In this work, we use the game of Twenty Questions to evaluate the information-seeking ability of LLMs. We introduce and formalize its adversarial counterpart, the Strategic Language Search (SLS) problem along with its variants as a two-player zero-sum extensive form game. We propose Game of Thought (GoT), a framework that applies game-theoretic techniques to approximate a Nash equilibrium (NE) strategy for the restricted variant of the game. Empirical results demonstrate that our approach consistently improves worst-case performance compared to (1) direct prompting-based methods and (2) heuristic-guided search methods across all tested settings.",
    "published": "2026-02-02T06:33:18Z",
    "updated": "2026-02-02T06:33:18Z",
    "authors": [
      "Langyuan Cui",
      "Chun Kai Ling",
      "Hwee Tou Ng"
    ],
    "primary_category": "cs.CL",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.GT"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01708v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01708v1",
    "comment": "23 pages, 10 figures, under review at ICML 2026",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 6.0,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01705v1",
    "title": "Beyond Mode Elicitation: Diversity-Preserving Reinforcement Learning via Latent Diffusion Reasoner",
    "summary": "Recent reinforcement learning (RL) methods improve LLM reasoning by optimizing discrete Chain-of-Thought (CoT) generation; however, exploration in token space often suffers from diversity collapse as policy entropy decreases due to mode elicitation behavior in discrete RL. To mitigate this issue, we propose Latent Diffusion Reasoning with Reinforcement Learning (LaDi-RL), a framework that conducts exploration directly in a continuous latent space, where latent variables encode semantic-level reasoning trajectories. By modeling exploration via guided diffusion, multi-step denoising distributes stochasticity and preserves multiple coexisting solution modes without mutual suppression. Furthermore, by decoupling latent-space exploration from text-space generation, we show that latent diffusion-based optimization is more effective than text-space policy optimization alone, while a complementary text policy provides additional gains when combined with latent exploration. Experiments on code generation and mathematical reasoning benchmarks demonstrate consistent improvements in both pass@1 and pass@k over discrete RL baselines, with absolute pass@1 gains of +9.4% on code generation and +5.7% on mathematical reasoning, highlighting diffusion-based latent RL as a principled alternative to discrete token-level RL for reasoning.",
    "published": "2026-02-02T06:26:31Z",
    "updated": "2026-02-02T06:26:31Z",
    "authors": [
      "Haoqiang Kang",
      "Yizhe Zhang",
      "Nikki Lijing Kuang",
      "Yi-An Ma",
      "Lianhui Qin"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01705v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01705v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 6.0,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01703v1",
    "title": "$\\textbf{AGT$^{AO}$}$: Robust and Stabilized LLM Unlearning via Adversarial Gating Training with Adaptive Orthogonality",
    "summary": "While Large Language Models (LLMs) have achieved remarkable capabilities, they unintentionally memorize sensitive data, posing critical privacy and security risks. Machine unlearning is pivotal for mitigating these risks, yet existing paradigms face a fundamental dilemma: aggressive unlearning often induces catastrophic forgetting that degrades model utility, whereas conservative strategies risk superficial forgetting, leaving models vulnerable to adversarial recovery. To address this trade-off, we propose $\\textbf{AGT$^{AO}$}$ (Adversarial Gating Training with Adaptive Orthogonality), a unified framework designed to reconcile robust erasure with utility preservation. Specifically, our approach introduces $\\textbf{Adaptive Orthogonality (AO)}$ to dynamically mitigate geometric gradient conflicts between forgetting and retention objectives, thereby minimizing unintended knowledge degradation. Concurrently, $\\textbf{Adversarial Gating Training (AGT)}$ formulates unlearning as a latent-space min-max game, employing a curriculum-based gating mechanism to simulate and counter internal recovery attempts. Extensive experiments demonstrate that $\\textbf{AGT$^{AO}$}$ achieves a superior trade-off between unlearning efficacy (KUR $\\approx$ 0.01) and model utility (MMLU 58.30). Code is available at https://github.com/TiezMind/AGT-unlearning.",
    "published": "2026-02-02T06:19:27Z",
    "updated": "2026-02-02T06:19:27Z",
    "authors": [
      "Pengyu Li",
      "Lingling Zhang",
      "Zhitao Gao",
      "Yanrui Wu",
      "Yuxuan Dong",
      "Huan Liu",
      "Bifan Wei",
      "Jun Liu"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01703v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01703v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 6.0,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01701v1",
    "title": "Meta Engine: A Unified Semantic Query Engine on Heterogeneous LLM-Based Query Systems",
    "summary": "With the increasingly use of multi-modal data, semantic query has become more and more demanded in data management systems, which is an important way to access and analyze multi-modal data. As unstructured data, most information of multi-modal data (text, image, video, etc) hides in the semantics, which cannot be accessed by the traditional database queries like SQL. Given the power of Large Language Model (LLM) in understanding semantics and processing natural language, in recent years several LLM-based semantic query systems have been proposed, to support semantic querying over unstructured data. However, this rapid growth has produced a fragmented ecosystem. Applications face significant integration challenges due to (1) disparate APIs of different semantic query systems and (2) a fundamental trade-off between specialization and generality. Many semantic query systems are highly specialized, offering state-of-the-art performance within a single modality but struggling with multi-modal data. Conversely, some \"all-in-one\" systems handle multiple modalities but often exhibit suboptimal performance compared to their specialized counterparts in specific modalities. This paper introduces Meta Engine, a novel \"query system on query systems\", designed to resolve those aforementioned challenges. Meta Engine is a unified semantic query engine that integrates heterogeneous, specialized LLM-based query systems. Its architecture comprises five key components: (1) a Natural Language (NL) Query Parser, (2) an Operator Generator, (3) a Query Router, (4) a set of Adapters, and (5) a Result Aggregator. In the evaluation, Meta Engine consistently outperforms all baselines, yielding 3-6x higher F1 in most cases and up to 24x on specific datasets.",
    "published": "2026-02-02T06:16:04Z",
    "updated": "2026-02-02T06:16:04Z",
    "authors": [
      "Ruyu Li",
      "Tinghui Zhang",
      "Haodi Ma",
      "Daisy Zhe Wang",
      "Yifan Wang"
    ],
    "primary_category": "cs.DB",
    "categories": [
      "cs.DB",
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01701v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01701v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 6.0,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01696v1",
    "title": "Cross-Modal Alignment and Fusion for RGB-D Transmission-Line Defect Detection",
    "summary": "Transmission line defect detection remains challenging for automated UAV inspection due to the dominance of small-scale defects, complex backgrounds, and illumination variations. Existing RGB-based detectors, despite recent progress, struggle to distinguish geometrically subtle defects from visually similar background structures under limited chromatic contrast. This paper proposes CMAFNet, a Cross-Modal Alignment and Fusion Network that integrates RGB appearance and depth geometry through a principled purify-then-fuse paradigm. CMAFNet consists of a Semantic Recomposition Module that performs dictionary-based feature purification via a learned codebook to suppress modality-specific noise while preserving defect-discriminative information, and a Contextual Semantic Integration Framework that captures global spatial dependencies using partial-channel attention to enhance structural semantic reasoning. Position-wise normalization within the purification stage enforces explicit reconstruction-driven cross-modal alignment, ensuring statistical compatibility between heterogeneous features prior to fusion. Extensive experiments on the TLRGBD benchmark, where 94.5% of instances are small objects, demonstrate that CMAFNet achieves 32.2% mAP@50 and 12.5% APs, outperforming the strongest baseline by 9.8 and 4.0 percentage points, respectively. A lightweight variant reaches 24.8% mAP50 at 228 FPS with only 4.9M parameters, surpassing all YOLO-based detectors while matching transformer-based methods at substantially lower computational cost.",
    "published": "2026-02-02T06:11:33Z",
    "updated": "2026-02-02T06:11:33Z",
    "authors": [
      "Jiaming Cui",
      "Shuai Zhou",
      "Wenqiang Li",
      "Ruifeng Qin",
      "Feng Shen"
    ],
    "primary_category": "cs.CV",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01696v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01696v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 6.0,
    "matched_areas": [
      "ai",
      "manufacturing"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01689v1",
    "title": "What LLMs Think When You Don't Tell Them What to Think About?",
    "summary": "Characterizing the behavior of large language models (LLMs) across diverse settings is critical for reliable monitoring and AI safety. However, most existing analyses rely on topic- or task-specific prompts, which can substantially limit what can be observed. In this work, we study what LLMs generate from minimal, topic-neutral inputs and probe their near-unconstrained generative behavior. Despite the absence of explicit topics, model outputs cover a broad semantic space, and surprisingly, each model family exhibits strong and systematic topical preferences. GPT-OSS predominantly generates programming (27.1%) and mathematical content (24.6%), whereas Llama most frequently generates literary content (9.1%). DeepSeek often generates religious content, while Qwen frequently generates multiple-choice questions. Beyond topical preferences, we also observe differences in content specialization and depth: GPT-OSS often generates more technically advanced content (e.g., dynamic programming) compared with other models (e.g., basic Python). Furthermore, we find that the near-unconstrained generation often degenerates into repetitive phrases, revealing interesting behaviors unique to each model family. For instance, degenerate outputs from Llama include multiple URLs pointing to personal Facebook and Instagram accounts. We release the complete dataset of 256,000 samples from 16 LLMs, along with a reproducible codebase.",
    "published": "2026-02-02T06:06:06Z",
    "updated": "2026-02-02T06:06:06Z",
    "authors": [
      "Yongchan Kwon",
      "James Zou"
    ],
    "primary_category": "cs.AI",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01689v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01689v1",
    "comment": "NA",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 6.0,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01655v1",
    "title": "ProjDevBench: Benchmarking AI Coding Agents on End-to-End Project Development",
    "summary": "Recent coding agents can generate complete codebases from simple prompts, yet existing evaluations focus on issue-level bug fixing and lag behind end-to-end development. We introduce ProjDevBench, an end-to-end benchmark that provides project requirements to coding agents and evaluates the resulting repositories. Combining Online Judge (OJ) testing with LLM-assisted code review, the benchmark evaluates agents on (1) system architecture design, (2) functional correctness, and (3) iterative solution refinement. We curate 20 programming problems across 8 categories, covering both concept-oriented tasks and real-world application scenarios, and evaluate six coding agents built on different LLM backends. Our evaluation reports an overall acceptance rate of 27.38%: agents handle basic functionality and data structures but struggle with complex system design, time complexity optimization, and resource management. Our benchmark is available at https://github.com/zsworld6/projdevbench.",
    "published": "2026-02-02T05:17:23Z",
    "updated": "2026-02-02T05:17:23Z",
    "authors": [
      "Pengrui Lu",
      "Shiqi Zhang",
      "Yunzhong Hou",
      "Lyumanshan Ye",
      "Chaoyi Huang",
      "Zixi Chen",
      "Ji Zeng",
      "Hantao Jiang",
      "Pengfei Liu",
      "Yiwei Wang",
      "Ming-Hsuan Yang"
    ],
    "primary_category": "cs.AI",
    "categories": [
      "cs.AI",
      "cs.SE"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01655v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01655v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 6.0,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01649v1",
    "title": "Contribution-aware Token Compression for Efficient Video Understanding via Reinforcement Learning",
    "summary": "Video large language models have demonstrated remarkable capabilities in video understanding tasks. However, the redundancy of video tokens introduces significant computational overhead during inference, limiting their practical deployment. Many compression algorithms are proposed to prioritize retaining features with the highest attention scores to minimize perturbations in attention computations. However, the correlation between attention scores and their actual contribution to correct answers remains ambiguous. To address the above limitation, we propose a novel \\textbf{C}ontribution-\\textbf{a}ware token \\textbf{Co}mpression algorithm for \\textbf{VID}eo understanding (\\textbf{CaCoVID}) that explicitly optimizes the token selection policy based on the contribution of tokens to correct predictions. First, we introduce a reinforcement learning-based framework that optimizes a policy network to select video token combinations with the greatest contribution to correct predictions. This paradigm shifts the focus from passive token preservation to active discovery of optimal compressed token combinations. Secondly, we propose a combinatorial policy optimization algorithm with online combination space sampling, which dramatically reduces the exploration space for video token combinations and accelerates the convergence speed of policy optimization. Extensive experiments on diverse video understanding benchmarks demonstrate the effectiveness of CaCoVID. Codes will be released.",
    "published": "2026-02-02T05:09:48Z",
    "updated": "2026-02-02T05:09:48Z",
    "authors": [
      "Yinchao Ma",
      "Qiang Zhou",
      "Zhibin Wang",
      "Xianing Chen",
      "Hanqing Yang",
      "Jun Song",
      "Bo Zheng"
    ],
    "primary_category": "cs.CV",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01649v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01649v1",
    "comment": "This paper is accepted by AAAI2026",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 6.0,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01633v1",
    "title": "Federated Vision Transformer with Adaptive Focal Loss for Medical Image Classification",
    "summary": "While deep learning models like Vision Transformer (ViT) have achieved significant advances, they typically require large datasets. With data privacy regulations, access to many original datasets is restricted, especially medical images. Federated learning (FL) addresses this challenge by enabling global model aggregation without data exchange. However, the heterogeneity of the data and the class imbalance that exist in local clients pose challenges for the generalization of the model. This study proposes a FL framework leveraging a dynamic adaptive focal loss (DAFL) and a client-aware aggregation strategy for local training. Specifically, we design a dynamic class imbalance coefficient that adjusts based on each client's sample distribution and class data distribution, ensuring minority classes receive sufficient attention and preventing sparse data from being ignored. To address client heterogeneity, a weighted aggregation strategy is adopted, which adapts to data size and characteristics to better capture inter-client variations. The classification results on three public datasets (ISIC, Ocular Disease and RSNA-ICH) show that the proposed framework outperforms DenseNet121, ResNet50, ViT-S/16, ViT-L/32, FedCLIP, Swin Transformer, CoAtNet, and MixNet in most cases, with accuracy improvements ranging from 0.98\\% to 41.69\\%. Ablation studies on the imbalanced ISIC dataset validate the effectiveness of the proposed loss function and aggregation strategy compared to traditional loss functions and other FL approaches. The codes can be found at: https://github.com/AIPMLab/ViT-FLDAF.",
    "published": "2026-02-02T04:47:33Z",
    "updated": "2026-02-02T04:47:33Z",
    "authors": [
      "Xinyuan Zhao",
      "Yihang Wu",
      "Ahmad Chaddad",
      "Tareef Daqqaq",
      "Reem Kateb"
    ],
    "primary_category": "cs.CV",
    "categories": [
      "cs.CV"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01633v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01633v1",
    "comment": "Accepted in Knowledge-Based Systems",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 6.0,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01613v1",
    "title": "A Practical Tensor-Network Compression Pipeline for Production-Scale Large Language Models",
    "summary": "Large language models are limited in deployment by GPU memory and inference latency. We present Minima, a production compression pipeline that learns where and how to structurally compress a Transformer and turns that compression into real serving gains. Minima trains a lightweight convolutional predictor to estimate layer- and patch-level sensitivity, applies a mixture of Tucker, tensor-train, and tensor-ring decompositions to low-sensitivity regions, performs a short healing fine-tune, and executes the resulting operators with custom Triton and CUDA kernels. The reduced memory footprint enables speculative decoding with a small draft model and a larger verifier. On Qwen3-32B at an 8k-token context window, Minima reduces peak VRAM from 64 GiB to 40 GiB. For a single active request, throughput increases from 40 tokens per second (baseline) to 50 tokens per second (Minima) and 75 tokens per second (Minima with speculative decoding). Under 50 parallel requests, throughput is 34, 44, and 53 tokens per second respectively, showing that Minima remains effective under high concurrency even when speculative decoding gains compress. We position Minima relative to recent tensor-network, low-rank plus quantization, and cross-layer sharing methods, and argue that it is a practical step toward more aggressive structural compression via shared tensor backbones with tiny per-layer adapters.",
    "published": "2026-02-02T04:03:39Z",
    "updated": "2026-02-02T04:03:39Z",
    "authors": [
      "Sergii Kozyrev",
      "Davyd Maiboroda"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01613v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01613v1",
    "comment": "13 pages, 5 figures",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 6.0,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01611v1",
    "title": "What Do Agents Learn from Trajectory-SFT: Semantics or Interfaces?",
    "summary": "Large language models are increasingly evaluated as interactive agents, yet standard agent benchmarks conflate two qualitatively distinct sources of success: semantic tool-use and interface-specific interaction pattern memorization. Because both mechanisms can yield identical task success on the original interface, benchmark scores alone are not identifiable evidence of environment-invariant capability. We propose PIPE, a protocol-level evaluation augmentation for diagnosing interface reliance by minimally rewriting environment interfaces while preserving task semantics and execution behavior. Across 16 environments from AgentBench and AgentGym and a range of open-source and API-based agents, PIPE reveals that trajectory-SFT substantially amplifies interface shortcutting: trained agents degrade sharply under minimal interface rewrites, while non-trajectory-trained models remain largely stable. We further introduce Interface Reliance (IR), a counterbalanced alias-based metric that quantifies preference for training-time interfaces, and show that interface shortcutting exhibits environment-dependent, non-monotonic training dynamics that remain invisible under standard evaluation. Our code is available at https://anonymous.4open.science/r/What-Do-Agents-Learn-from-Trajectory-SFT-Semantics-or-Interfaces--0831/.",
    "published": "2026-02-02T04:02:03Z",
    "updated": "2026-02-02T04:02:03Z",
    "authors": [
      "Weizheng Gu",
      "Chengze Li",
      "Zhuohao Yu",
      "Mengyuan Sun",
      "Zhibang Yang",
      "Wei Wang",
      "Hongrui Jia",
      "Shikun Zhang",
      "Wei Ye"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01611v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01611v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 6.0,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01609v1",
    "title": "Token Pruning for In-Context Generation in Diffusion Transformers",
    "summary": "In-context generation significantly enhances Diffusion Transformers (DiTs) by enabling controllable image-to-image generation through reference examples. However, the resulting input concatenation drastically increases sequence length, creating a substantial computational bottleneck. Existing token reduction techniques, primarily tailored for text-to-image synthesis, fall short in this paradigm as they apply uniform reduction strategies, overlooking the inherent role asymmetry between reference contexts and target latents across spatial, temporal, and functional dimensions. To bridge this gap, we introduce ToPi, a training-free token pruning framework tailored for in-context generation in DiTs. Specifically, ToPi utilizes offline calibration-driven sensitivity analysis to identify pivotal attention layers, serving as a robust proxy for redundancy estimation. Leveraging these layers, we derive a novel influence metric to quantify the contribution of each context token for selective pruning, coupled with a temporal update strategy that adapts to the evolving diffusion trajectory. Empirical evaluations demonstrate that ToPi can achieve over 30\\% speedup in inference while maintaining structural fidelity and visual consistency across complex image generation tasks.",
    "published": "2026-02-02T03:54:32Z",
    "updated": "2026-02-02T03:54:32Z",
    "authors": [
      "Junqing Lin",
      "Xingyu Zheng",
      "Pei Cheng",
      "Bin Fu",
      "Jingwei Sun",
      "Guangzhong Sun"
    ],
    "primary_category": "cs.CV",
    "categories": [
      "cs.CV"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01609v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01609v1",
    "comment": "20 pages",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 6.0,
    "matched_areas": [
      "ai",
      "vision"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01605v1",
    "title": "Universal Redundancies in Time Series Foundation Models",
    "summary": "Time Series Foundation Models (TSFMs) leverage extensive pretraining to accurately predict unseen time series during inference, without the need for task-specific fine-tuning. Through large-scale evaluations on standard benchmarks, we find that leading transformer-based TSFMs exhibit redundant components in their intermediate layers. We introduce a set of tools for mechanistic interpretability of TSFMs, including ablations of specific components and direct logit attribution on the residual stream. Our findings are consistent across several leading TSFMs with diverse architectures, and across a diverse set of real-world and synthetic time-series datasets. We discover that all models in our study are robust to ablations of entire layers. Furthermore, we develop a theoretical framework framing transformers as kernel regressors, motivating a purely intrinsic strategy for ablating heads based on the stable rank of the per-head projection matrices. Using this approach, we uncover the specific heads responsible for degenerate phenomena widely observed in TSFMs, such as parroting of motifs from the context and seasonality bias. Our study sheds light on the universal properties of this emerging class of architectures for continuous-time sequence modeling.",
    "published": "2026-02-02T03:53:46Z",
    "updated": "2026-02-02T03:53:46Z",
    "authors": [
      "Anthony Bao",
      "Venkata Hasith Vattikuti",
      "Jeffrey Lai",
      "William Gilpin"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01605v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01605v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 6.0,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01603v1",
    "title": "Inference-Aware Meta-Alignment of LLMs via Non-Linear GRPO",
    "summary": "Aligning large language models (LLMs) to diverse human preferences is fundamentally challenging since criteria can often conflict with each other. Inference-time alignment methods have recently gained popularity as they allow LLMs to be aligned to multiple criteria via different alignment algorithms at inference time. However, inference-time alignment is computationally expensive since it often requires multiple forward passes of the base model. In this work, we propose inference-aware meta-alignment (IAMA), a novel approach that enables LLMs to be aligned to multiple criteria with limited computational budget at inference time. IAMA trains a base model such that it can be effectively aligned to multiple tasks via different inference-time alignment algorithms. To solve the non-linear optimization problems involved in IAMA, we propose non-linear GRPO, which provably converges to the optimal solution in the space of probability measures.",
    "published": "2026-02-02T03:50:42Z",
    "updated": "2026-02-02T03:50:42Z",
    "authors": [
      "Shokichi Takakura",
      "Akifumi Wachi",
      "Rei Higuchi",
      "Kohei Miyaguchi",
      "Taiji Suzuki"
    ],
    "primary_category": "stat.ML",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01603v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01603v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 6.0,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01587v1",
    "title": "Provable Defense Framework for LLM Jailbreaks via Noise-Augumented Alignment",
    "summary": "Large Language Models (LLMs) remain vulnerable to adaptive jailbreaks that easily bypass empirical defenses like GCG. We propose a framework for certifiable robustness that shifts safety guarantees from single-pass inference to the statistical stability of an ensemble. We introduce Certified Semantic Smoothing (CSS) via Stratified Randomized Ablation, a technique that partitions inputs into immutable structural prompts and mutable payloads to derive rigorous lo norm guarantees using the Hypergeometric distribution. To resolve performance degradation on sparse contexts, we employ Noise-Augmented Alignment Tuning (NAAT), which transforms the base model into a semantic denoiser. Extensive experiments on Llama-3 show that our method reduces the Attack Success Rate of gradient-based attacks from 84.2% to 1.2% while maintaining 94.1% benign utility, significantly outperforming character-level baselines which degrade utility to 74.3%. This framework provides a deterministic certificate of safety, ensuring that a model remains robust against all adversarial variants within a provable radius.",
    "published": "2026-02-02T03:26:45Z",
    "updated": "2026-02-02T03:26:45Z",
    "authors": [
      "Zehua Cheng",
      "Jianwei Yang",
      "Wei Dai",
      "Jiahao Sun"
    ],
    "primary_category": "cs.CL",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01587v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01587v1",
    "comment": "10 pages",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 6.0,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01581v1",
    "title": "Nearly Optimal Active Preference Learning and Its Application to LLM Alignment",
    "summary": "Aligning large language models (LLMs) depends on high-quality datasets of human preference labels, which are costly to collect. Although active learning has been studied to improve sample efficiency relative to passive collection, many existing approaches adopt classical experimental design criteria such as G- or D-optimality. These objectives are not tailored to the structure of preference learning, leaving open the design of problem-specific algorithms. In this work, we identify a simple intuition specific to preference learning that calls into question the suitability of these existing design objectives. Motivated by this insight, we propose two active learning algorithms. The first provides the first instance-dependent label complexity guarantee for this setting, and the second is a simple, practical greedy method. We evaluate our algorithm on real-world preference datasets and observe improved sample efficiency compared to existing methods.",
    "published": "2026-02-02T03:21:29Z",
    "updated": "2026-02-02T03:21:29Z",
    "authors": [
      "Yao Zhao",
      "Kwang-Sung Jun"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01581v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01581v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 6.0,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01554v1",
    "title": "InfoTok: Regulating Information Flow for Capacity-Constrained Shared Visual Tokenization in Unified MLLMs",
    "summary": "Unified multimodal large language models (MLLMs) integrate image understanding and generation in a single framework, with the visual tokenizer acting as the sole interface that maps visual inputs into tokens for downstream tasks. However, existing shared-token designs are mostly architecture-driven and lack an explicit criterion for what information tokens should preserve to support both understanding and generation. Therefore, we introduce a capacity-constrained perspective, highlighting that in shared-token unified MLLMs the visual tokenizer behaves as a compute-bounded learner, so the token budget should prioritize reusable structure over hard-to-exploit high-entropy variations and redundancy. Motivated by this perspective, we propose InfoTok, an information-regularized visual tokenization mechanism grounded in the Information Bottleneck (IB) principle. InfoTok formulates tokenization as controlling information flow from images to shared tokens to multimodal outputs, yielding a principled trade-off between compression and task relevance via mutual-information regularization. We integrate InfoTok into three representative unified MLLMs without introducing any additional training data. Experiments show consistent improvements on both understanding and generation, supporting information-regularized tokenization as a principled foundation for learning a shared token space in unified MLLMs.",
    "published": "2026-02-02T02:47:48Z",
    "updated": "2026-02-02T02:47:48Z",
    "authors": [
      "Lv Tang",
      "Tianyi Zheng",
      "Bo Li",
      "Xingyu Li"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01554v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01554v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 6.0,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01550v1",
    "title": "S1-NexusAgent: a Self-Evolving Agent Framework for Multidisciplinary Scientific Research",
    "summary": "Modern scientific research relies on large-scale data, complex workflows, and specialized tools, which existing LLMs and tool-based agents struggle to handle due to limitations in long-horizon planning, robust goal maintenance, and continual learning from execution. To address these issues, in this work, we propose S1-NexusAgent, a self-evolving agent framework designed for multidisciplinary scientific research. S1-NexusAgent adopts a hierarchical Plan-and-CodeAct execution paradigm, decoupling global scientific planning from subtask-level tool execution through a dual-loop architecture, thereby enabling stable modeling of complex research workflows. The system natively supports the Model Context Protocol (MCP), integrates up to thousands of cross-disciplinary scientific tools, and achieves efficient orchestration of heterogeneous research tools via intention-aware dynamic tool retrieval and hot-plug mechanisms. To address long-context and large-scale data challenges in scientific settings, S1-NexusAgent introduces object-reference-based sparse context management, which enables sub-task context isolation and intermediate result compression. Building on this, a Critic Agent automatically evaluates complete execution trajectories and distills high-quality research paths into reusable Scientific Skills, forming a closed loop for continuous self-evolution, which is valuable for sustainable and long-horizon scientific research. Experiments on authoritative scientific benchmarks involving long-horizon planning and complex specialized tool orchestration, including biomini-eval (biology), ChemBench (chemistry), and MatSciBench (material science), demonstrate that S1-NexusAgent achieves state-of-the-art performance, validating its effectiveness and generalization capability in complex scientific tasks.",
    "published": "2026-02-02T02:33:25Z",
    "updated": "2026-02-02T02:33:25Z",
    "authors": [
      "S1-NexusAgent Team"
    ],
    "primary_category": "cs.AI",
    "categories": [
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01550v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01550v1",
    "comment": "In progress",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 6.0,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02482v1",
    "title": "Expanding the Capabilities of Reinforcement Learning via Text Feedback",
    "summary": "The success of RL for LLM post-training stems from an unreasonably uninformative source: a single bit of information per rollout as binary reward or preference label. At the other extreme, distillation offers dense supervision but requires demonstrations, which are costly and difficult to scale. We study text feedback as an intermediate signal: richer than scalar rewards, yet cheaper than complete demonstrations. Textual feedback is a natural mode of human interaction and is already abundant in many real-world settings, where users, annotators, and automated judges routinely critique LLM outputs. Towards leveraging text feedback at scale, we formalize a multi-turn RL setup, RL from Text Feedback (RLTF), where text feedback is available during training but not at inference. Therefore, models must learn to internalize the feedback in order to improve their test-time single-turn performance. To do this, we propose two methods: Self Distillation (RLTF-SD), which trains the single-turn policy to match its own feedback-conditioned second-turn generations; and Feedback Modeling (RLTF-FM), which predicts the feedback as an auxiliary objective. We provide theoretical analysis on both methods, and empirically evaluate on reasoning puzzles, competition math, and creative writing tasks. Our results show that both methods consistently outperform strong baselines across benchmarks, highlighting the potential of RL with an additional source of rich supervision at scale.",
    "published": "2026-02-02T18:56:56Z",
    "updated": "2026-02-02T18:56:56Z",
    "authors": [
      "Yuda Song",
      "Lili Chen",
      "Fahim Tajwar",
      "Remi Munos",
      "Deepak Pathak",
      "J. Andrew Bagnell",
      "Aarti Singh",
      "Andrea Zanette"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02482v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02482v1",
    "comment": "43 pages, 6 figures",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 4.8,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02456v1",
    "title": "Relationship-Aware Hierarchical 3D Scene Graph for Task Reasoning",
    "summary": "Representing and understanding 3D environments in a structured manner is crucial for autonomous agents to navigate and reason about their surroundings. While traditional Simultaneous Localization and Mapping (SLAM) methods generate metric reconstructions and can be extended to metric-semantic mapping, they lack a higher level of abstraction and relational reasoning. To address this gap, 3D scene graphs have emerged as a powerful representation for capturing hierarchical structures and object relationships. In this work, we propose an enhanced hierarchical 3D scene graph that integrates open-vocabulary features across multiple abstraction levels and supports object-relational reasoning. Our approach leverages a Vision Language Model (VLM) to infer semantic relationships. Notably, we introduce a task reasoning module that combines Large Language Models (LLM) and a VLM to interpret the scene graph's semantic and relational information, enabling agents to reason about tasks and interact with their environment more intelligently. We validate our method by deploying it on a quadruped robot in multiple environments and tasks, highlighting its ability to reason about them.",
    "published": "2026-02-02T18:47:02Z",
    "updated": "2026-02-02T18:47:02Z",
    "authors": [
      "Albert Gassol Puigjaner",
      "Angelos Zacharia",
      "Kostas Alexis"
    ],
    "primary_category": "cs.RO",
    "categories": [
      "cs.RO"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02456v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02456v1",
    "comment": "ICRA 2026, 8 pages",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 4.8,
    "matched_areas": [
      "ai",
      "agents"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02439v1",
    "title": "Energy-Efficient Neuromorphic Computing for Edge AI: A Framework with Adaptive Spiking Neural Networks and Hardware-Aware Optimization",
    "summary": "Edge AI applications increasingly require ultra-low-power, low-latency inference. Neuromorphic computing based on event-driven spiking neural networks (SNNs) offers an attractive path, but practical deployment on resource-constrained devices is limited by training difficulty, hardware-mapping overheads, and sensitivity to temporal dynamics. We present NeuEdge, a framework that combines adaptive SNN models with hardware-aware optimization for edge deployment. NeuEdge uses a temporal coding scheme that blends rate and spike-timing patterns to reduce spike activity while preserving accuracy, and a hardware-aware training procedure that co-optimizes network structure and on-chip placement to improve utilization on neuromorphic processors. An adaptive threshold mechanism adjusts neuron excitability from input statistics, reducing energy consumption without degrading performance. Across standard vision and audio benchmarks, NeuEdge achieves 91-96% accuracy with up to 2.3 ms inference latency on edge hardware and an estimated 847 GOp/s/W energy efficiency. A case study on an autonomous-drone workload shows up to 312x energy savings relative to conventional deep neural networks while maintaining real-time operation.",
    "published": "2026-02-02T18:34:48Z",
    "updated": "2026-02-02T18:34:48Z",
    "authors": [
      "Olaf Yunus Laitinen Imanov",
      "Derya Umut Kulali",
      "Taner Yilmaz",
      "Duygu Erisken",
      "Rana Irem Turhan"
    ],
    "primary_category": "cs.NE",
    "categories": [
      "cs.NE",
      "cs.ET",
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02439v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02439v1",
    "comment": "8 pages, 4 figures, 4 tables. Submitted to IEEE Transactions on Neural Networks and Learning Systems (TNNLS)",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 4.8,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02385v1",
    "title": "Transformers learn factored representations",
    "summary": "Transformers pretrained via next token prediction learn to factor their world into parts, representing these factors in orthogonal subspaces of the residual stream. We formalize two representational hypotheses: (1) a representation in the product space of all factors, whose dimension grows exponentially with the number of parts, or (2) a factored representation in orthogonal subspaces, whose dimension grows linearly. The factored representation is lossless when factors are conditionally independent, but sacrifices predictive fidelity otherwise, creating a tradeoff between dimensional efficiency and accuracy. We derive precise predictions about the geometric structure of activations for each, including the number of subspaces, their dimensionality, and the arrangement of context embeddings within them. We test between these hypotheses on transformers trained on synthetic processes with known latent structure. Models learn factored representations when factors are conditionally independent, and continue to favor them early in training even when noise or hidden dependencies undermine conditional independence, reflecting an inductive bias toward factoring at the cost of fidelity. This provides a principled explanation for why transformers decompose the world into parts, and suggests that interpretable low dimensional structure may persist even in models trained on complex data.",
    "published": "2026-02-02T17:49:06Z",
    "updated": "2026-02-02T17:49:06Z",
    "authors": [
      "Adam Shai",
      "Loren Amdahl-Culleton",
      "Casper L. Christensen",
      "Henry R. Bigelow",
      "Fernando E. Rosas",
      "Alexander B. Boyd",
      "Eric A. Alt",
      "Kyle J. Ray",
      "Paul M. Riechers"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02385v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02385v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 4.8,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02268v1",
    "title": "HopFormer: Sparse Graph Transformers with Explicit Receptive Field Control",
    "summary": "Graph Transformers typically rely on explicit positional or structural encodings and dense global attention to incorporate graph topology. In this work, we show that neither is essential. We introduce HopFormer, a graph Transformer that injects structure exclusively through head-specific n-hop masked sparse attention, without the use of positional encodings or architectural modifications. This design provides explicit and interpretable control over receptive fields while enabling genuinely sparse attention whose computational cost scales linearly with mask sparsity. Through extensive experiments on both node-level and graph-level benchmarks, we demonstrate that our approach achieves competitive or superior performance across diverse graph structures. Our results further reveal that dense global attention is often unnecessary: on graphs with strong small-world properties, localized attention yields more stable and consistently high performance, while on graphs with weaker small-world effects, global attention offers diminishing returns. Together, these findings challenge prevailing assumptions in graph Transformer design and highlight sparsity-controlled attention as a principled and efficient alternative.",
    "published": "2026-02-02T16:09:58Z",
    "updated": "2026-02-02T16:09:58Z",
    "authors": [
      "Sanggeon Yun",
      "Raheeb Hassan",
      "Ryozo Masukawa",
      "Sungheon Jeong",
      "Mohsen Imani"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02268v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02268v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 4.8,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02259v1",
    "title": "Segment to Focus: Guiding Latent Action Models in the Presence of Distractors",
    "summary": "Latent Action Models (LAMs) learn to extract action-relevant representations solely from raw observations, enabling reinforcement learning from unlabelled videos and significantly scaling available training data. However, LAMs face a critical challenge in disentangling action-relevant features from action-correlated noise (e.g., background motion). Failing to filter these distractors causes LAMs to capture spurious correlations and build sub-optimal latent action spaces. In this paper, we introduce MaskLAM -- a lightweight modification to LAM training to mitigate this issue by incorporating visual agent segmentation. MaskLAM utilises segmentation masks from pretrained foundation models to weight the LAM reconstruction loss, thereby prioritising salient information over background elements while requiring no architectural modifications. We demonstrate the effectiveness of our method on continuous-control MuJoCo tasks, modified with action-correlated background noise. Our approach yields up to a 4x increase in accrued rewards compared to standard baselines and a 3x improvement in the latent action quality, as evidenced by linear probe evaluation.",
    "published": "2026-02-02T16:03:19Z",
    "updated": "2026-02-02T16:03:19Z",
    "authors": [
      "Hamza Adnan",
      "Matthew T. Jackson",
      "Alexey Zakharov"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02259v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02259v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 4.8,
    "matched_areas": [
      "ai",
      "vision"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02227v1",
    "title": "Show, Don't Tell: Morphing Latent Reasoning into Image Generation",
    "summary": "Text-to-image (T2I) generation has achieved remarkable progress, yet existing methods often lack the ability to dynamically reason and refine during generation--a hallmark of human creativity. Current reasoning-augmented paradigms most rely on explicit thought processes, where intermediate reasoning is decoded into discrete text at fixed steps with frequent image decoding and re-encoding, leading to inefficiencies, information loss, and cognitive mismatches. To bridge this gap, we introduce LatentMorph, a novel framework that seamlessly integrates implicit latent reasoning into the T2I generation process. At its core, LatentMorph introduces four lightweight components: (i) a condenser for summarizing intermediate generation states into compact visual memory, (ii) a translator for converting latent thoughts into actionable guidance, (iii) a shaper for dynamically steering next image token predictions, and (iv) an RL-trained invoker for adaptively determining when to invoke reasoning. By performing reasoning entirely in continuous latent spaces, LatentMorph avoids the bottlenecks of explicit reasoning and enables more adaptive self-refinement. Extensive experiments demonstrate that LatentMorph (I) enhances the base model Janus-Pro by $16\\%$ on GenEval and $25\\%$ on T2I-CompBench; (II) outperforms explicit paradigms (e.g., TwiG) by $15\\%$ and $11\\%$ on abstract reasoning tasks like WISE and IPV-Txt, (III) while reducing inference time by $44\\%$ and token consumption by $51\\%$; and (IV) exhibits $71\\%$ cognitive alignment with human intuition on reasoning invocation.",
    "published": "2026-02-02T15:29:48Z",
    "updated": "2026-02-02T15:29:48Z",
    "authors": [
      "Harold Haodong Chen",
      "Xinxiang Yin",
      "Wen-Jie Shu",
      "Hongfei Zhang",
      "Zixin Zhang",
      "Chenfei Liao",
      "Litao Guo",
      "Qifeng Chen",
      "Ying-Cong Chen"
    ],
    "primary_category": "cs.CV",
    "categories": [
      "cs.CV"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02227v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02227v1",
    "comment": "Code: https://github.com/EnVision-Research/LatentMorph",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 4.8,
    "matched_areas": [
      "ai",
      "vision"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02201v1",
    "title": "Cardinality-Preserving Structured Sparse Graph Transformers for Molecular Property Prediction",
    "summary": "Drug discovery motivates efficient molecular property prediction under limited labeled data. Chemical space is vast, often estimated at approximately 10^60 drug-like molecules, while only thousands of drugs have been approved. As a result, self-supervised pretraining on large unlabeled molecular corpora has become essential for data-efficient molecular representation learning. We introduce **CardinalGraphFormer**, a graph transformer that incorporates Graphormer-inspired structural biases, including shortest-path distance and centrality, as well as direct-bond edge bias, within a structured sparse attention regime limited to shortest-path distance <= 3. The model further augments this design with a cardinality-preserving unnormalized aggregation channel over the same support set. Pretraining combines contrastive graph-level alignment with masked attribute reconstruction. Under a fully matched evaluation protocol, CardinalGraphFormer improves mean performance across all 11 evaluated tasks and achieves statistically significant gains on 10 of 11 public benchmarks spanning MoleculeNet, OGB, and TDC ADMET tasks when compared to strong reproduced baselines.",
    "published": "2026-02-02T15:05:46Z",
    "updated": "2026-02-02T15:05:46Z",
    "authors": [
      "Abhijit Gupta"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02201v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02201v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 4.8,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02193v1",
    "title": "SSI-DM: Singularity Skipping Inversion of Diffusion Models",
    "summary": "Inverting real images into the noise space is essential for editing tasks using diffusion models, yet existing methods produce non-Gaussian noise with poor editability due to the inaccuracy in early noising steps. We identify the root cause: a mathematical singularity that renders inversion fundamentally ill-posed. We propose Singularity Skipping Inversion of Diffusion Models (SSI-DM), which bypasses this singular region by adding small noise before standard inversion. This simple approach produces inverted noise with natural Gaussian properties while maintaining reconstruction fidelity. As a plug-and-play technique compatible with general diffusion models, our method achieves superior performance on public image datasets for reconstruction and interpolation tasks, providing a principled and efficient solution to diffusion model inversion.",
    "published": "2026-02-02T14:59:58Z",
    "updated": "2026-02-02T14:59:58Z",
    "authors": [
      "Chen Min",
      "Enze Jiang",
      "Jishen Peng",
      "Zheng Ma"
    ],
    "primary_category": "cs.CV",
    "categories": [
      "cs.CV"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02193v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02193v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 4.8,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02167v1",
    "title": "Real-Time 2D LiDAR Object Detection Using Three-Frame RGB Scan Encoding",
    "summary": "Indoor service robots need perception that is robust, more privacy-friendly than RGB video, and feasible on embedded hardware. We present a camera-free 2D LiDAR object detection pipeline that encodes short-term temporal context by stacking three consecutive scans as RGB channels, yielding a compact YOLOv8n input without occupancy-grid construction while preserving angular structure and motion cues. Evaluated in Webots across 160 randomized indoor scenarios with strict scenario-level holdout, the method achieves 98.4% mAP@0.5 (0.778 mAP@0.5:0.95) with 94.9% precision and 94.7% recall on four object classes. On a Raspberry Pi 5, it runs in real time with a mean post-warm-up end-to-end latency of 47.8ms per frame, including scan encoding and postprocessing. Relative to a closely related occupancy-grid LiDAR-YOLO pipeline reported on the same platform, the proposed representation is associated with substantially lower reported end-to-end latency. Although results are simulation-based, they suggest that lightweight temporal encoding can enable accurate and real-time LiDAR-only detection for embedded indoor robotics without capturing RGB appearance.",
    "published": "2026-02-02T14:44:27Z",
    "updated": "2026-02-02T14:44:27Z",
    "authors": [
      "Soheil Behnam Roudsari",
      "Alexandre S. Brando",
      "Felipe N. Martins"
    ],
    "primary_category": "eess.SP",
    "categories": [
      "eess.SP",
      "cs.CV",
      "cs.LG",
      "cs.RO"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02167v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02167v1",
    "comment": "6 pages, 6 figures, submitted to IEEE SAS 2026",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 4.8,
    "matched_areas": [
      "vision"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02162v1",
    "title": "Interpretable Tabular Foundation Models via In-Context Kernel Regression",
    "summary": "Tabular foundation models like TabPFN and TabICL achieve state-of-the-art performance through in-context learning, yet their architectures remain fundamentally opaque. We introduce KernelICL, a framework to enhance tabular foundation models with quantifiable sample-based interpretability. Building on the insight that in-context learning is akin to kernel regression, we make this mechanism explicit by replacing the final prediction layer with kernel functions (Gaussian, dot-product, kNN) so that every prediction is a transparent weighted average of training labels. We introduce a two-dimensional taxonomy that formally unifies standard kernel methods, modern neighbor-based approaches, and attention mechanisms under a single framework, and quantify inspectability via the perplexity of the weight distribution over training samples. On 55 TALENT benchmark datasets, KernelICL achieves performance on par with existing tabular foundation models, demonstrating that explicit kernel constraints on the final layer enable inspectable predictions without sacrificing performance.",
    "published": "2026-02-02T14:37:10Z",
    "updated": "2026-02-02T14:37:10Z",
    "authors": [
      "Ratmir Miftachov",
      "Bruno Charron",
      "Simon Valentin"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02162v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02162v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 4.8,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02156v1",
    "title": "LoopViT: Scaling Visual ARC with Looped Transformers",
    "summary": "Recent advances in visual reasoning have leveraged vision transformers to tackle the ARC-AGI benchmark. However, we argue that the feed-forward architecture, where computational depth is strictly bound to parameter size, falls short of capturing the iterative, algorithmic nature of human induction. In this work, we propose a recursive architecture called Loop-ViT, which decouples reasoning depth from model capacity through weight-tied recurrence. Loop-ViT iterates a weight-tied Hybrid Block, combining local convolutions and global attention, to form a latent chain of thought. Crucially, we introduce a parameter-free Dynamic Exit mechanism based on predictive entropy: the model halts inference when its internal state ``crystallizes\" into a low-uncertainty attractor. Empirical results on the ARC-AGI-1 benchmark validate this perspective: our 18M model achieves 65.8% accuracy, outperforming massive 73M-parameter ensembles. These findings demonstrate that adaptive iterative computation offers a far more efficient scaling axis for visual reasoning than simply increasing network width. The code is available at https://github.com/WenjieShu/LoopViT.",
    "published": "2026-02-02T14:32:57Z",
    "updated": "2026-02-02T14:32:57Z",
    "authors": [
      "Wen-Jie Shu",
      "Xuerui Qiu",
      "Rui-Jie Zhu",
      "Harold Haodong Chen",
      "Yexin Liu",
      "Harry Yang"
    ],
    "primary_category": "cs.CV",
    "categories": [
      "cs.CV"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02156v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02156v1",
    "comment": "8 pages, 11 figures",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 4.8,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02150v1",
    "title": "ECHO: Entropy-Confidence Hybrid Optimization for Test-Time Reinforcement Learning",
    "summary": "Test-time reinforcement learning generates multiple candidate answers via repeated rollouts and performs online updates using pseudo-labels constructed by majority voting. To reduce overhead and improve exploration, prior work introduces tree structured rollouts, which share reasoning prefixes and branch at key nodes to improve sampling efficiency. However, this paradigm still faces two challenges: (1) high entropy branching can trigger rollout collapse, where the branching budget concentrates on a few trajectories with consecutive high-entropy segments, rapidly reducing the number of effective branches; (2) early pseudo-labels are noisy and biased, which can induce self-reinforcing overfitting, causing the policy to sharpen prematurely and suppress exploration. To address these issues, we propose Entropy Confidence Hybrid Group Relative Policy Optimization (ECHO). During rollout, ECHO jointly leverages local entropy and group level confidence to adaptively control branch width, and further introduces online confidence-based pruning to terminate persistently low confidence branches, avoiding high entropy traps and mitigating collapse. During policy updates, ECHO employs confidence adaptive clipping and an entropy confidence hybrid advantage shaping approach to enhance training robustness and mitigate early stage bias. Experiments demonstrate that ECHO achieves consistent gains on multiple mathematical and visual reasoning benchmarks, and generalizes more effectively under a limited rollout budget.",
    "published": "2026-02-02T14:27:02Z",
    "updated": "2026-02-02T14:27:02Z",
    "authors": [
      "Chu Zhao",
      "Enneng Yang",
      "Yuting Liu",
      "Jianzhe Zhao",
      "Guibing Guo"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02150v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02150v1",
    "comment": "19 ppages",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 4.8,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02133v1",
    "title": "Understanding the Reversal Curse Mitigation in Masked Diffusion Models through Attention and Training Dynamics",
    "summary": "Autoregressive language models (ARMs) suffer from the reversal curse: after learning that \"$A$ is $B$\", they often fail on the reverse query \"$B$ is $A$\". Masked diffusion-based language models (MDMs) exhibit this failure in a much weaker form, but the underlying reason has remained unclear. A common explanation attributes this mitigation to the any-order training objective. However, observing \"[MASK] is $B$\" during training does not necessarily teach the model to handle the reverse prompt \"$B$ is [MASK]\". We show that the mitigation arises from architectural structure and its interaction with training. In a one-layer Transformer encoder, weight sharing couples the two directions by making forward and reverse attention scores positively correlated. In the same setting, we further show that the corresponding gradients are aligned, so minimizing the forward loss also reduces the reverse loss. Experiments on both controlled toy tasks and large-scale diffusion language models support these mechanisms, explaining why MDMs partially overcome a failure mode that persists in strong ARMs.",
    "published": "2026-02-02T14:17:08Z",
    "updated": "2026-02-02T14:17:08Z",
    "authors": [
      "Sangwoo Shin",
      "BumJun Kim",
      "Kyelim Lee",
      "Moongyu Jeon",
      "Albert No"
    ],
    "primary_category": "cs.AI",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02133v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02133v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 4.8,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02117v1",
    "title": "The Maximum von Neumann Entropy Principle: Theory and Applications in Machine Learning",
    "summary": "Von Neumann entropy (VNE) is a fundamental quantity in quantum information theory and has recently been adopted in machine learning as a spectral measure of diversity for kernel matrices and kernel covariance operators. While maximizing VNE under constraints is well known in quantum settings, a principled analogue of the classical maximum entropy framework, particularly its decision theoretic and game theoretic interpretation, has not been explicitly developed for VNE in data driven contexts. In this paper, we extend the minimax formulation of the maximum entropy principle due to Grnwald and Dawid to the setting of von Neumann entropy, providing a game-theoretic justification for VNE maximization over density matrices and trace-normalized positive semidefinite operators. This perspective yields a robust interpretation of maximum VNE solutions under partial information and clarifies their role as least committed inferences in spectral domains. We then illustrate how the resulting Maximum VNE principle applies to modern machine learning problems by considering two representative applications, selecting a kernel representation from multiple normalized embeddings via kernel-based VNE maximization, and completing kernel matrices from partially observed entries. These examples demonstrate how the proposed framework offers a unifying information-theoretic foundation for VNE-based methods in kernel learning.",
    "published": "2026-02-02T13:59:32Z",
    "updated": "2026-02-02T13:59:32Z",
    "authors": [
      "Youqi Wu",
      "Farzan Farnia"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "cs.IT"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02117v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02117v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 4.8,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02114v1",
    "title": "Enhancing Diffusion-Based Quantitatively Controllable Image Generation via Matrix-Form EDM and Adaptive Vicinal Training",
    "summary": "Continuous Conditional Diffusion Model (CCDM) is a diffusion-based framework designed to generate high-quality images conditioned on continuous regression labels. Although CCDM has demonstrated clear advantages over prior approaches across a range of datasets, it still exhibits notable limitations and has recently been surpassed by a GAN-based method, namely CcGAN-AVAR. These limitations mainly arise from its reliance on an outdated diffusion framework and its low sampling efficiency due to long sampling trajectories. To address these issues, we propose an improved CCDM framework, termed iCCDM, which incorporates the more advanced \\textit{Elucidated Diffusion Model} (EDM) framework with substantial modifications to improve both generation quality and sampling efficiency. Specifically, iCCDM introduces a novel matrix-form EDM formulation together with an adaptive vicinal training strategy. Extensive experiments on four benchmark datasets, spanning image resolutions from $64\\times64$ to $256\\times256$, demonstrate that iCCDM consistently outperforms existing methods, including state-of-the-art large-scale text-to-image diffusion models (e.g., Stable Diffusion 3, FLUX.1, and Qwen-Image), achieving higher generation quality while significantly reducing sampling cost.",
    "published": "2026-02-02T13:55:49Z",
    "updated": "2026-02-02T13:55:49Z",
    "authors": [
      "Xin Ding",
      "Yun Chen",
      "Sen Zhang",
      "Kao Zhang",
      "Nenglun Chen",
      "Peibei Cao",
      "Yongwei Wang",
      "Fei Wu"
    ],
    "primary_category": "cs.CV",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02114v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02114v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 4.8,
    "matched_areas": [
      "ai",
      "vision"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02112v1",
    "title": "Unifying Masked Diffusion Models with Various Generation Orders and Beyond",
    "summary": "Masked diffusion models (MDMs) are a potential alternative to autoregressive models (ARMs) for language generation, but generation quality depends critically on the generation order. Prior work either hard-codes an ordering (e.g., blockwise left-to-right) or learns an ordering policy for a pretrained MDM, which incurs extra cost and can yield suboptimal solutions due to the two-stage optimization. Motivated by this, we propose order-expressive masked diffusion model (OeMDM) for a broad class of diffusion generative processes with various generation orders, enabling the interpretation of MDM, ARM, and block diffusion in a single framework. Furthermore, building on OeMDM, we introduce learnable-order masked diffusion model (LoMDM), which jointly learns the generation ordering and diffusion backbone through a single objective from scratch, enabling the diffusion model to generate text in context-dependent ordering. Empirically, we confirm that LoMDM outperforms various discrete diffusion models across multiple language modeling benchmarks.",
    "published": "2026-02-02T13:54:32Z",
    "updated": "2026-02-02T13:54:32Z",
    "authors": [
      "Chunsan Hong",
      "Sanghyun Lee",
      "Jong Chul Ye"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02112v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02112v1",
    "comment": "Preprint",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 4.8,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02107v1",
    "title": "Teacher-Guided Student Self-Knowledge Distillation Using Diffusion Model",
    "summary": "Existing Knowledge Distillation (KD) methods often align feature information between teacher and student by exploring meaningful feature processing and loss functions. However, due to the difference in feature distributions between the teacher and student, the student model may learn incompatible information from the teacher. To address this problem, we propose teacher-guided student Diffusion Self-KD, dubbed as DSKD. Instead of the direct teacher-student alignment, we leverage the teacher classifier to guide the sampling process of denoising student features through a light-weight diffusion model. We then propose a novel locality-sensitive hashing (LSH)-guided feature distillation method between the original and denoised student features. The denoised student features encapsulate teacher knowledge and could be regarded as a teacher role. In this way, our DSKD method could eliminate discrepancies in mapping manners and feature distributions between the teacher and student, while learning meaningful knowledge from the teacher. Experiments on visual recognition tasks demonstrate that DSKD significantly outperforms existing KD methods across various models and datasets. Our code is attached in supplementary material.",
    "published": "2026-02-02T13:52:15Z",
    "updated": "2026-02-02T13:52:15Z",
    "authors": [
      "Yu Wang",
      "Chuanguang Yang",
      "Zhulin An",
      "Weilun Feng",
      "Jiarui Zhao",
      "Chengqing Yu",
      "Libo Huang",
      "Boyu Diao",
      "Yongjun Xu"
    ],
    "primary_category": "cs.CV",
    "categories": [
      "cs.CV"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02107v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02107v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 4.8,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02098v1",
    "title": "Probabilistic Performance Guarantees for Multi-Task Reinforcement Learning",
    "summary": "Multi-task reinforcement learning trains generalist policies that can execute multiple tasks. While recent years have seen significant progress, existing approaches rarely provide formal performance guarantees, which are indispensable when deploying policies in safety-critical settings. We present an approach for computing high-confidence guarantees on the performance of a multi-task policy on tasks not seen during training. Concretely, we introduce a new generalisation bound that composes (i) per-task lower confidence bounds from finitely many rollouts with (ii) task-level generalisation from finitely many sampled tasks, yielding a high-confidence guarantee for new tasks drawn from the same arbitrary and unknown distribution. Across state-of-the-art multi-task RL methods, we show that the guarantees are theoretically sound and informative at realistic sample sizes.",
    "published": "2026-02-02T13:41:47Z",
    "updated": "2026-02-02T13:41:47Z",
    "authors": [
      "Yannik Schnitzer",
      "Mathias Jackermeier",
      "Alessandro Abate",
      "David Parker"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02098v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02098v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 4.8,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02092v1",
    "title": "FSVideo: Fast Speed Video Diffusion Model in a Highly-Compressed Latent Space",
    "summary": "We introduce FSVideo, a fast speed transformer-based image-to-video (I2V) diffusion framework. We build our framework on the following key components: 1.) a new video autoencoder with highly-compressed latent space ($64\\times64\\times4$ spatial-temporal downsampling ratio), achieving competitive reconstruction quality; 2.) a diffusion transformer (DIT) architecture with a new layer memory design to enhance inter-layer information flow and context reuse within DIT, and 3.) a multi-resolution generation strategy via a few-step DIT upsampler to increase video fidelity. Our final model, which contains a 14B DIT base model and a 14B DIT upsampler, achieves competitive performance against other popular open-source models, while being an order of magnitude faster. We discuss our model design as well as training strategies in this report.",
    "published": "2026-02-02T13:37:38Z",
    "updated": "2026-02-02T13:37:38Z",
    "authors": [
      "FSVideo Team",
      "Qingyu Chen",
      "Zhiyuan Fang",
      "Haibin Huang",
      "Xinwei Huang",
      "Tong Jin",
      "Minxuan Lin",
      "Bo Liu",
      "Celong Liu",
      "Chongyang Ma",
      "Xing Mei",
      "Xiaohui Shen",
      "Yaojie Shen",
      "Fuwen Tan",
      "Angtian Wang",
      "Xiao Yang",
      "Yiding Yang",
      "Jiamin Yuan",
      "Lingxi Zhang",
      "Yuxin Zhang"
    ],
    "primary_category": "cs.CV",
    "categories": [
      "cs.CV"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02092v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02092v1",
    "comment": "Project Page: https://kingofprank.github.io/fsvideo/",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 4.8,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02067v1",
    "title": "Multi-View Stenosis Classification Leveraging Transformer-Based Multiple-Instance Learning Using Real-World Clinical Data",
    "summary": "Coronary artery stenosis is a leading cause of cardiovascular disease, diagnosed by analyzing the coronary arteries from multiple angiography views. Although numerous deep-learning models have been proposed for stenosis detection from a single angiography view, their performance heavily relies on expensive view-level annotations, which are often not readily available in hospital systems. Moreover, these models fail to capture the temporal dynamics and dependencies among multiple views, which are crucial for clinical diagnosis. To address this, we propose SegmentMIL, a transformer-based multi-view multiple-instance learning framework for patient-level stenosis classification. Trained on a real-world clinical dataset, using patient-level supervision and without any view-level annotations, SegmentMIL jointly predicts the presence of stenosis and localizes the affected anatomical region, distinguishing between the right and left coronary arteries and their respective segments. SegmentMIL obtains high performance on internal and external evaluations and outperforms both view-level models and classical MIL baselines, underscoring its potential as a clinically viable and scalable solution for coronary stenosis diagnosis. Our code is available at https://github.com/NikolaCenic/mil-stenosis.",
    "published": "2026-02-02T13:07:52Z",
    "updated": "2026-02-02T13:07:52Z",
    "authors": [
      "Nikola Cenikj",
      "zgn Turgut",
      "Alexander Mller",
      "Alexander Steger",
      "Jan Kehrer",
      "Marcus Brugger",
      "Daniel Rueckert",
      "Eimo Martens",
      "Philip Mller"
    ],
    "primary_category": "cs.CV",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02067v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02067v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 4.8,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02061v1",
    "title": "Learning to Route and Schedule LLMs from User Retrials via Contextual Queueing Bandits",
    "summary": "Explosive demands for LLMs often cause user queries to accumulate in server queues, requiring efficient routing (query-LLM matching) and scheduling (query prioritization) mechanisms. Several online algorithms are being deployed, but they overlook the following two key challenges inherent to conversational LLM services: (1) unsatisfied users may retry queries, increasing the server backlog, and (2) requests for ``explicit\" feedback, such as ratings, degrade user experiences. In this paper, we develop a joint routing and scheduling algorithm that leverages ``implicit\" feedback inferred from user retrial behaviors. The key idea is to propose and study the framework of contextual queueing bandits with multinomial logit feedback (CQB-MNL). CQB-MNL models query retrials, as well as context-based learning for user preferences over LLMs. Our algorithm, anytime CQB (ACQB), achieves efficient learning while maintaining queue stability by combining Thompson sampling with forced exploration at a decaying rate. We show that ACQB simultaneously achieves a cumulative regret of $\\widetilde{\\mathcal{O}}(\\sqrt{t})$ for routing and a queue length regret of $\\widetilde{\\mathcal{O}}(t^{-1/4})$ for any large $t$. For experiments, we refine query embeddings via contrastive learning while adopting a disjoint parameter model to learn LLM-specific parameters. Experiments on SPROUT, EmbedLLM, and RouterBench datasets confirm that both algorithms consistently outperform baselines.",
    "published": "2026-02-02T13:01:41Z",
    "updated": "2026-02-02T13:01:41Z",
    "authors": [
      "Seoungbin Bae",
      "Junyoung Son",
      "Dabeen Lee"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02061v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02061v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 4.8,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02055v1",
    "title": "FORLER: Federated Offline Reinforcement Learning with Q-Ensemble and Actor Rectification",
    "summary": "In Internet-of-Things systems, federated learning has advanced online reinforcement learning (RL) by enabling parallel policy training without sharing raw data. However, interacting with real environments online can be risky and costly, motivating offline federated RL (FRL), where local devices learn from fixed datasets. Despite its promise, offline FRL may break down under low-quality, heterogeneous data. Offline RL tends to get stuck in local optima, and in FRL, one device's suboptimal policy can degrade the aggregated model, i.e., policy pollution. We present FORLER, combining Q-ensemble aggregation on the server with actor rectification on devices. The server robustly merges device Q-functions to curb policy pollution and shift heavy computation off resource-constrained hardware without compromising privacy. Locally, actor rectification enriches policy gradients via a zeroth-order search for high-Q actions plus a bespoke regularizer that nudges the policy toward them. A $$-periodic strategy further reduces local computation. We theoretically provide safe policy improvement performance guarantees. Extensive experiments show FORLER consistently outperforms strong baselines under varying data quality and heterogeneity.",
    "published": "2026-02-02T12:57:09Z",
    "updated": "2026-02-02T12:57:09Z",
    "authors": [
      "Nan Qiao",
      "Sheng Yue"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02055v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02055v1",
    "comment": "accetped by IEEE International Conference on Communications (ICC 2026)",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 4.8,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02047v1",
    "title": "Dissecting Outlier Dynamics in LLM NVFP4 Pretraining",
    "summary": "Training large language models using 4-bit arithmetic enhances throughput and memory efficiency. Yet, the limited dynamic range of FP4 increases sensitivity to outliers. While NVFP4 mitigates quantization error via hierarchical microscaling, a persistent loss gap remains compared to BF16. This study conducts a longitudinal analysis of outlier dynamics across architecture during NVFP4 pretraining, focusing on where they localize, why they occur, and how they evolve temporally. We find that, compared with Softmax Attention (SA), Linear Attention (LA) reduces per-tensor heavy tails but still exhibits persistent block-level spikes under block quantization. Our analysis attributes outliers to specific architectural components: Softmax in SA, gating in LA, and SwiGLU in FFN, with \"post-QK\" operations exhibiting higher sensitivity to quantization. Notably, outliers evolve from transient spikes early in training to a small set of persistent hot channels (i.e., channels with persistently large magnitudes) in later stages. Based on these findings, we introduce Hot-Channel Patch (HCP), an online compensation mechanism that identifies hot channels and reinjects residuals using hardware-efficient kernels. We then develop CHON, an NVFP4 training recipe integrating HCP with post-QK operation protection. On GLA-1.3B model trained for 60B tokens, CHON reduces the loss gap to BF16 from 0.94% to 0.58% while maintaining downstream accuracy.",
    "published": "2026-02-02T12:50:27Z",
    "updated": "2026-02-02T12:50:27Z",
    "authors": [
      "Peijie Dong",
      "Ruibo Fan",
      "Yuechen Tao",
      "Di Mou",
      "Wenhu Hu",
      "Zhenheng Tang",
      "Yinghao Yu",
      "Jiamang Wang",
      "Wenbo Su",
      "Guodong Yang",
      "Liping Zhang",
      "Xiaowen Chu",
      "Baochun Li",
      "Bo Li"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02047v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02047v1",
    "comment": "39 pages, 32 figures",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 4.8,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01978v1",
    "title": "SpikingGamma: Surrogate-Gradient Free and Temporally Precise Online Training of Spiking Neural Networks with Smoothed Delays",
    "summary": "Neuromorphic hardware implementations of Spiking Neural Networks (SNNs) promise energy-efficient, low-latency AI through sparse, event-driven computation. Yet, training SNNs under fine temporal discretization remains a major challenge, hindering both low-latency responsiveness and the mapping of software-trained SNNs to efficient hardware. In current approaches, spiking neurons are modeled as self-recurrent units, embedded into recurrent networks to maintain state over time, and trained with BPTT or RTRL variants based on surrogate gradients. These methods scale poorly with temporal resolution, while online approximations often exhibit instability for long sequences and tend to fail at capturing temporal patterns precisely. To address these limitations, we develop spiking neurons with internal recursive memory structures that we combine with sigma-delta spike-coding. We show that this SpikingGamma model supports direct error backpropagation without surrogate gradients, can learn fine temporal patterns with minimal spiking in an online manner, and scale feedforward SNNs to complex tasks and benchmarks with competitive accuracy, all while being insensitive to the temporal resolution of the model. Our approach offers both an alternative to current recurrent SNNs trained with surrogate gradients, and a direct route for mapping SNNs to neuromorphic hardware.",
    "published": "2026-02-02T11:35:16Z",
    "updated": "2026-02-02T11:35:16Z",
    "authors": [
      "Roel Koopman",
      "Sebastian Otte",
      "Sander Boht"
    ],
    "primary_category": "cs.NE",
    "categories": [
      "cs.NE",
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01978v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01978v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 4.8,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01954v1",
    "title": "Beyond Open Vocabulary: Multimodal Prompting for Object Detection in Remote Sensing Images",
    "summary": "Open-vocabulary object detection in remote sensing commonly relies on text-only prompting to specify target categories, implicitly assuming that inference-time category queries can be reliably grounded through pretraining-induced text-visual alignment. In practice, this assumption often breaks down in remote sensing scenarios due to task- and application-specific category semantics, resulting in unstable category specification under open-vocabulary settings. To address this limitation, we propose RS-MPOD, a multimodal open-vocabulary detection framework that reformulates category specification beyond text-only prompting by incorporating instance-grounded visual prompts, textual prompts, and their multimodal integration. RS-MPOD introduces a visual prompt encoder to extract appearance-based category cues from exemplar instances, enabling text-free category specification, and a multimodal fusion module to integrate visual and textual information when both modalities are available. Extensive experiments on standard, cross-dataset, and fine-grained remote sensing benchmarks show that visual prompting yields more reliable category specification under semantic ambiguity and distribution shifts, while multimodal prompting provides a flexible alternative that remains competitive when textual semantics are well aligned.",
    "published": "2026-02-02T11:03:01Z",
    "updated": "2026-02-02T11:03:01Z",
    "authors": [
      "Shuai Yang",
      "Ziyue Huang",
      "Jiaxin Chen",
      "Qingjie Liu",
      "Yunhong Wang"
    ],
    "primary_category": "cs.CV",
    "categories": [
      "cs.CV"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01954v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01954v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 4.8,
    "matched_areas": [
      "vision"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01949v1",
    "title": "Boundary-Constrained Diffusion Models for Floorplan Generation: Balancing Realism and Diversity",
    "summary": "Diffusion models have become widely popular for automated floorplan generation, producing highly realistic layouts conditioned on user-defined constraints. However, optimizing for perceptual metrics such as the Frchet Inception Distance (FID) causes limited design diversity. To address this, we propose the Diversity Score (DS), a metric that quantifies layout diversity under fixed constraints. Moreover, to improve geometric consistency, we introduce a Boundary Cross-Attention (BCA) module that enables conditioning on building boundaries. Our experiments show that BCA significantly improves boundary adherence, while prolonged training drives diversity collapse undiagnosed by FID, revealing a critical trade-off between realism and diversity. Out-Of-Distribution evaluations further demonstrate the models' reliance on dataset priors, emphasizing the need for generative systems that explicitly balance fidelity, diversity, and generalization in architectural design tasks.",
    "published": "2026-02-02T10:59:20Z",
    "updated": "2026-02-02T10:59:20Z",
    "authors": [
      "Leonardo Stoppani",
      "Davide Bacciu",
      "Shahab Mokarizadeh"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01949v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01949v1",
    "comment": "Accepted at ESANN 2026",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 4.8,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01920v1",
    "title": "PIMPC-GNN: Physics-Informed Multi-Phase Consensus Learning for Enhancing Imbalanced Node Classification in Graph Neural Networks",
    "summary": "Graph neural networks (GNNs) often struggle in class-imbalanced settings, where minority classes are under-represented and predictions are biased toward majorities. We propose \\textbf{PIMPC-GNN}, a physics-informed multi-phase consensus framework for imbalanced node classification. Our method integrates three complementary dynamics: (i) thermodynamic diffusion, which spreads minority labels to capture long-range dependencies, (ii) Kuramoto synchronisation, which aligns minority nodes through oscillatory consensus, and (iii) spectral embedding, which separates classes via structural regularisation. These perspectives are combined through class-adaptive ensemble weighting and trained with an imbalance-aware loss that couples balanced cross-entropy with physics-based constraints. Across five benchmark datasets and imbalance ratios from 5-100, PIMPC-GNN outperforms 16 state-of-the-art baselines, achieving notable gains in minority-class recall (up to +12.7\\%) and balanced accuracy (up to +8.3\\%). Beyond empirical improvements, the framework also provides interpretable insights into consensus dynamics in graph learning. The code is available at \\texttt{https://github.com/afofanah/PIMPC-GNN}.",
    "published": "2026-02-02T10:21:58Z",
    "updated": "2026-02-02T10:21:58Z",
    "authors": [
      "Abdul Joseph Fofanah",
      "Lian Wen",
      "David Chen"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01920v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01920v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 4.8,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01915v1",
    "title": "VLM-Guided Experience Replay",
    "summary": "Recent advances in Large Language Models (LLMs) and Vision-Language Models (VLMs) have enabled powerful semantic and multimodal reasoning capabilities, creating new opportunities to enhance sample efficiency, high-level planning, and interpretability in reinforcement learning (RL). While prior work has integrated LLMs and VLMs into various components of RL, the replay buffer, a core component for storing and reusing experiences, remains unexplored. We propose addressing this gap by leveraging VLMs to guide the prioritization of experiences in the replay buffer. Our key idea is to use a frozen, pre-trained VLM (requiring no fine-tuning) as an automated evaluator to identify and prioritize promising sub-trajectories from the agent's experiences. Across scenarios, including game-playing and robotics, spanning both discrete and continuous domains, agents trained with our proposed prioritization method achieve 11-52% higher average success rates and improve sample efficiency by 19-45% compared to previous approaches. https://esharony.me/projects/vlm-rb/",
    "published": "2026-02-02T10:19:59Z",
    "updated": "2026-02-02T10:19:59Z",
    "authors": [
      "Elad Sharony",
      "Tom Jurgenson",
      "Orr Krupnik",
      "Dotan Di Castro",
      "Shie Mannor"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01915v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01915v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 4.8,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01914v1",
    "title": "Towards Long-Horizon Interpretability: Efficient and Faithful Multi-Token Attribution for Reasoning LLMs",
    "summary": "Token attribution methods provide intuitive explanations for language model outputs by identifying causally important input tokens. However, as modern LLMs increasingly rely on extended reasoning chains, existing schemes face two critical challenges: (1) efficiency bottleneck, where attributing a target span of M tokens within a context of length N requires O(M*N) operations, making long-context attribution prohibitively slow; and (2) faithfulness drop, where intermediate reasoning tokens absorb attribution mass, preventing importance from propagating back to the original input. To address these, we introduce FlashTrace, an efficient multi-token attribution method that employs span-wise aggregation to compute attribution over multi-token targets in a single pass, while maintaining faithfulness. Moreover, we design a recursive attribution mechanism that traces importance through intermediate reasoning chains back to source inputs. Extensive experiments on long-context retrieval (RULER) and multi-step reasoning (MATH, MorehopQA) tasks demonstrate that FlashTrace achieves over 130x speedup over existing baselines while maintaining superior faithfulness. We further analyze the dynamics of recursive attribution, showing that even a single recursive hop improves faithfulness by tracing importance through the reasoning chain.",
    "published": "2026-02-02T10:19:52Z",
    "updated": "2026-02-02T10:19:52Z",
    "authors": [
      "Wenbo Pan",
      "Zhichao Liu",
      "Xianlong Wang",
      "Haining Yu",
      "Xiaohua Jia"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01914v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01914v1",
    "comment": "ICML 2025 submission",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 4.8,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01906v1",
    "title": "DSXFormer: Dual-Pooling Spectral Squeeze-Expansion and Dynamic Context Attention Transformer for Hyperspectral Image Classification",
    "summary": "Hyperspectral image classification (HSIC) is a challenging task due to high spectral dimensionality, complex spectral-spatial correlations, and limited labeled training samples. Although transformer-based models have shown strong potential for HSIC, existing approaches often struggle to achieve sufficient spectral discriminability while maintaining computational efficiency. To address these limitations, we propose a novel DSXFormer, a novel dual-pooling spectral squeeze-expansion transformer with Dynamic Context Attention for HSIC. The proposed DSXFormer introduces a Dual-Pooling Spectral Squeeze-Expansion (DSX) block, which exploits complementary global average and max pooling to adaptively recalibrate spectral feature channels, thereby enhancing spectral discriminability and inter-band dependency modeling. In addition, DSXFormer incorporates a Dynamic Context Attention (DCA) mechanism within a window-based transformer architecture to dynamically capture local spectral-spatial relationships while significantly reducing computational overhead. The joint integration of spectral dual-pooling squeeze-expansion and DCA enables DSXFormer to achieve an effective balance between spectral emphasis and spatial contextual representation. Furthermore, patch extraction, embedding, and patch merging strategies are employed to facilitate efficient multi-scale feature learning. Extensive experiments conducted on four widely used hyperspectral benchmark datasets, including Salinas (SA), Indian Pines (IP), Pavia University (PU), and Kennedy Space Center (KSC), demonstrate that DSXFormer consistently outperforms state-of-the-art methods, achieving classification accuracies of 99.95%, 98.91%, 99.85%, and 98.52%, respectively.",
    "published": "2026-02-02T10:12:18Z",
    "updated": "2026-02-02T10:12:18Z",
    "authors": [
      "Farhan Ullah",
      "Irfan Ullah",
      "Khalil Khan",
      "Giovanni Pau",
      "JaKeoung Koo"
    ],
    "primary_category": "cs.CV",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01906v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01906v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 4.8,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01880v1",
    "title": "Multimodal Large Language Models for Real-Time Situated Reasoning",
    "summary": "In this work, we explore how multimodal large language models can support real-time context- and value-aware decision-making. To do so, we combine the GPT-4o language model with a TurtleBot 4 platform simulating a smart vacuum cleaning robot in a home. The model evaluates the environment through vision input and determines whether it is appropriate to initiate cleaning. The system highlights the ability of these models to reason about domestic activities, social norms, and user preferences and take nuanced decisions aligned with the values of the people involved, such as cleanliness, comfort, and safety. We demonstrate the system in a realistic home environment, showing its ability to infer context and values from limited visual input. Our results highlight the promise of multimodal large language models in enhancing robotic autonomy and situational awareness, while also underscoring challenges related to consistency, bias, and real-time performance.",
    "published": "2026-02-02T09:52:11Z",
    "updated": "2026-02-02T09:52:11Z",
    "authors": [
      "Giulio Antonio Abbo",
      "Senne Lenaerts",
      "Tony Belpaeme"
    ],
    "primary_category": "cs.RO",
    "categories": [
      "cs.RO"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01880v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01880v1",
    "comment": "Submitted to the interactivity track of the 21st ACM/IEEE International Conference on Human-Robot Interaction on December 2025, accepted January 2026",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 4.8,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01863v1",
    "title": "Transformers as Measure-Theoretic Associative Memory: A Statistical Perspective and Minimax Optimality",
    "summary": "Transformers excel through content-addressable retrieval and the ability to exploit contexts of, in principle, unbounded length. We recast associative memory at the level of probability measures, treating a context as a distribution over tokens and viewing attention as an integral operator on measures. Concretely, for mixture contexts $= I^{-1} \\sum_{i=1}^I ^{(i^*)}$ and a query $x_{\\mathrm{q}}(i^*)$, the task decomposes into (i) recall of the relevant component $^{(i^*)}$ and (ii) prediction from $(_{i^*},x_\\mathrm{q})$. We study learned softmax attention (not a frozen kernel) trained by empirical risk minimization and show that a shallow measure-theoretic Transformer composed with an MLP learns the recall-and-predict map under a spectral assumption on the input densities. We further establish a matching minimax lower bound with the same rate exponent (up to multiplicative constants), proving sharpness of the convergence order. The framework offers a principled recipe for designing and analyzing Transformers that recall from arbitrarily long, distributional contexts with provable generalization guarantees.",
    "published": "2026-02-02T09:34:17Z",
    "updated": "2026-02-02T09:34:17Z",
    "authors": [
      "Ryotaro Kawata",
      "Taiji Suzuki"
    ],
    "primary_category": "stat.ML",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01863v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01863v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 4.8,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01861v1",
    "title": "RIR-Former: Coordinate-Guided Transformer for Continuous Reconstruction of Room Impulse Responses",
    "summary": "Room impulse responses (RIRs) are essential for many acoustic signal processing tasks, yet measuring them densely across space is often impractical. In this work, we propose RIR-Former, a grid-free, one-step feed-forward model for RIR reconstruction. By introducing a sinusoidal encoding module into a transformer backbone, our method effectively incorporates microphone position information, enabling interpolation at arbitrary array locations. Furthermore, a segmented multi-branch decoder is designed to separately handle early reflections and late reverberation, improving reconstruction across the entire RIR. Experiments on diverse simulated acoustic environments demonstrate that RIR-Former consistently outperforms state-of-the-art baselines in terms of normalized mean square error (NMSE) and cosine distance (CD), under varying missing rates and array configurations. These results highlight the potential of our approach for practical deployment and motivate future work on scaling from randomly spaced linear arrays to complex array geometries, dynamic acoustic scenes, and real-world environments.",
    "published": "2026-02-02T09:33:54Z",
    "updated": "2026-02-02T09:33:54Z",
    "authors": [
      "Shaoheng Xu",
      "Chunyi Sun",
      "Jihui",
      "Zhang",
      "Prasanga N. Samarasinghe",
      "Thushara D. Abhayapala"
    ],
    "primary_category": "eess.AS",
    "categories": [
      "eess.AS",
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01861v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01861v1",
    "comment": "Accepted to International Conference on Acoustics, Speech and Signal Processing (ICASSP) 2026. Equal contribution: Shaoheng Xu and Chunyi Sun",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 4.8,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01843v1",
    "title": "SPIRIT: Adapting Vision Foundation Models for Unified Single- and Multi-Frame Infrared Small Target Detection",
    "summary": "Infrared small target detection (IRSTD) is crucial for surveillance and early-warning, with deployments spanning both single-frame analysis and video-mode tracking. A practical solution should leverage vision foundation models (VFMs) to mitigate infrared data scarcity, while adopting a memory-attention-based temporal propagation framework that unifies single- and multi-frame inference. However, infrared small targets exhibit weak radiometric signals and limited semantic cues, which differ markedly from visible-spectrum imagery. This modality gap makes direct use of semantics-oriented VFMs and appearance-driven cross-frame association unreliable for IRSTD: hierarchical feature aggregation can submerge localized target peaks, and appearance-only memory attention becomes ambiguous, leading to spurious clutter associations. To address these challenges, we propose SPIRIT, a unified and VFM-compatible framework that adapts VFMs to IRSTD via lightweight physics-informed plug-ins. Spatially, PIFR refines features by approximating rank-sparsity decomposition to suppress structured background components and enhance sparse target-like signals. Temporally, PGMA injects history-derived soft spatial priors into memory cross-attention to constrain cross-frame association, enabling robust video detection while naturally reverting to single-frame inference when temporal context is absent. Experiments on multiple IRSTD benchmarks show consistent gains over VFM-based baselines and SOTA performance.",
    "published": "2026-02-02T09:15:29Z",
    "updated": "2026-02-02T09:15:29Z",
    "authors": [
      "Qian Xu",
      "Xi Li",
      "Fei Gao",
      "Jie Guo",
      "Haojuan Yuan",
      "Shuaipeng Fan",
      "Mingjin Zhang"
    ],
    "primary_category": "cs.CV",
    "categories": [
      "cs.CV"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01843v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01843v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 4.8,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01828v1",
    "title": "Hyperbolic Graph Neural Networks Under the Microscope: The Role of Geometry-Task Alignment",
    "summary": "Many complex networks exhibit hyperbolic structural properties, making hyperbolic space a natural candidate for representing hierarchical and tree-like graphs with low distortion. Based on this observation, Hyperbolic Graph Neural Networks (HGNNs) have been widely adopted as a principled choice for representation learning on tree-like graphs. In this work, we question this paradigm by proposing an additional condition of geometry-task alignment, i.e., whether the metric structure of the target follows that of the input graph. We theoretically and empirically demonstrate the capability of HGNNs to recover low-distortion representations on two synthetic regression problems, and show that their geometric inductive bias becomes helpful when the problem requires preserving metric structure. Additionally, we evaluate HGNNs on the tasks of link prediction and node classification by jointly analyzing predictive performance and embedding distortion, revealing that only link prediction is geometry-aligned. Overall, our findings shift the focus from only asking \"Is the graph hyperbolic?\" to also questioning \"Is the task aligned with hyperbolic geometry?\", showing that HGNNs consistently outperform Euclidean models under such alignment, while their advantage vanishes otherwise.",
    "published": "2026-02-02T09:01:58Z",
    "updated": "2026-02-02T09:01:58Z",
    "authors": [
      "Dionisia Naddeo",
      "Jonas Linkerhgner",
      "Nicola Toschi",
      "Geri Skenderi",
      "Veronica Lachi"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01828v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01828v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 4.8,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01799v1",
    "title": "Spatio-Temporal Transformers for Long-Term NDVI Forecasting",
    "summary": "Long-term satellite image time series (SITS) analysis in heterogeneous landscapes faces significant challenges, particularly in Mediterranean regions where complex spatial patterns, seasonal variations, and multi-decade environmental changes interact across different scales. This paper presents the Spatio-Temporal Transformer for Long Term Forecasting (STT-LTF ), an extended framework that advances beyond purely temporal analysis to integrate spatial context modeling with temporal sequence prediction. STT-LTF processes multi-scale spatial patches alongside temporal sequences (up to 20 years) through a unified transformer architecture, capturing both local neighborhood relationships and regional climate influences. The framework employs comprehensive self-supervised learning with spatial masking, temporal masking, and horizon sampling strategies, enabling robust model training from 40 years of unlabeled Landsat imagery. Unlike autoregressive approaches, STT-LTF directly predicts arbitrary future time points without error accumulation, incorporating spatial patch embeddings, cyclical temporal encoding, and geographic coordinates to learn complex dependencies across heterogeneous Mediterranean ecosystems. Experimental evaluation on Landsat data (1984-2024) demonstrates that STT-LTF achieves a Mean Absolute Error (MAE) of 0.0328 and R^2 of 0.8412 for next-year predictions, outperforming traditional statistical methods, CNN-based approaches, LSTM networks, and standard transformers. The framework's ability to handle irregular temporal sampling and variable prediction horizons makes it particularly suitable for analysis of heterogeneous landscapes experiencing rapid ecological transitions.",
    "published": "2026-02-02T08:29:45Z",
    "updated": "2026-02-02T08:29:45Z",
    "authors": [
      "Ido Faran",
      "Nathan S. Netanyahu",
      "Maxim Shoshany"
    ],
    "primary_category": "cs.CV",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01799v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01799v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 4.8,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01765v1",
    "title": "Backdoor Sentinel: Detecting and Detoxifying Backdoors in Diffusion Models via Temporal Noise Consistency",
    "summary": "Diffusion models have been widely deployed in AIGC services; however, their reliance on opaque training data and procedures exposes a broad attack surface for backdoor injection. In practical auditing scenarios, due to the protection of intellectual property and commercial confidentiality, auditors are typically unable to access model parameters, rendering existing white-box or query-intensive detection methods impractical. More importantly, even after the backdoor is detected, existing detoxification approaches are often trapped in a dilemma between detoxification effectiveness and generation quality. In this work, we identify a previously unreported phenomenon called temporal noise unconsistency, where the noise predictions between adjacent diffusion timesteps is disrupted in specific temporal segments when the input is triggered, while remaining stable under clean inputs. Leveraging this finding, we propose Temporal Noise Consistency Defense (TNC-Defense), a unified framework for backdoor detection and detoxification. The framework first uses the adjacent timestep noise consistency to design a gray-box detection module, for identifying and locating anomalous diffusion timesteps. Furthermore, the framework uses the identified anomalous timesteps to construct a trigger-agnostic, timestep-aware detoxification module, which directly corrects the backdoor generation path. This effectively suppresses backdoor behavior while significantly reducing detoxification costs. We evaluate the proposed method under five representative backdoor attack scenarios and compare it with state-of-the-art defenses. The results show that TNC-Defense improves the average detection accuracy by $11\\%$ with negligible additional overhead, and invalidates an average of $98.5\\%$ of triggered samples with only a mild degradation in generation quality.",
    "published": "2026-02-02T07:48:44Z",
    "updated": "2026-02-02T07:48:44Z",
    "authors": [
      "Bingzheng Wang",
      "Xiaoyan Gu",
      "Hongbo Xu",
      "Hongcheng Li",
      "Zimo Yu",
      "Jiang Zhou",
      "Weiping Wang"
    ],
    "primary_category": "cs.CR",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01765v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01765v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 4.8,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01754v1",
    "title": "Spot-Wise Smart Parking: An Edge-Enabled Architecture with YOLOv11 and Digital Twin Integration",
    "summary": "Smart parking systems help reduce congestion and minimize users' search time, thereby contributing to smart city adoption and enhancing urban mobility. In previous works, we presented a system developed on a university campus to monitor parking availability by estimating the number of free spaces from vehicle counts within a region of interest. Although this approach achieved good accuracy, it restricted the system's ability to provide spot-level insights and support more advanced applications. To overcome this limitation, we extend the system with a spot-wise monitoring strategy based on a distance-aware matching method with spatial tolerance, enhanced through an Adaptive Bounding Box Partitioning method for challenging spaces. The proposed approach achieves a balanced accuracy of 98.80% while maintaining an inference time of 8 seconds on a resource-constrained edge device, enhancing the capabilities of YOLOv11m, a model that has a size of 40.5 MB. In addition, two new components were introduced: (i) a Digital Shadow that visually represents parking lot entities as a base to evolve to a full Digital Twin, and (ii) an application support server based on a repurposed TV box. The latter not only enables scalable communication among cloud services, the parking totem, and a bot that provides detailed spot occupancy statistics, but also promotes hardware reuse as a step towards greater sustainability.",
    "published": "2026-02-02T07:39:37Z",
    "updated": "2026-02-02T07:39:37Z",
    "authors": [
      "Gustavo P. C. P. da Luz",
      "Alvaro M. Aspilcueta Narvaez",
      "Tiago Godoi Bannwart",
      "Gabriel Massuyoshi Sato",
      "Luis Fernando Gomez Gonzalez",
      "Juliana Freitag Borin"
    ],
    "primary_category": "cs.CV",
    "categories": [
      "cs.CV"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01754v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01754v1",
    "comment": "Submitted to Journal of Internet Services and Applications, 27 pages, 20 figures, 3 tables",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 4.8,
    "matched_areas": [
      "manufacturing"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01738v1",
    "title": "Simplicity Prevails: The Emergence of Generalizable AIGI Detection in Visual Foundation Models",
    "summary": "While specialized detectors for AI-Generated Images (AIGI) achieve near-perfect accuracy on curated benchmarks, they suffer from a dramatic performance collapse in realistic, in-the-wild scenarios. In this work, we demonstrate that simplicity prevails over complex architectural designs. A simple linear classifier trained on the frozen features of modern Vision Foundation Models , including Perception Encoder, MetaCLIP 2, and DINOv3, establishes a new state-of-the-art. Through a comprehensive evaluation spanning traditional benchmarks, unseen generators, and challenging in-the-wild distributions, we show that this baseline not only matches specialized detectors on standard benchmarks but also decisively outperforms them on in-the-wild datasets, boosting accuracy by striking margins of over 30\\%. We posit that this superior capability is an emergent property driven by the massive scale of pre-training data containing synthetic content. We trace the source of this capability to two distinct manifestations of data exposure: Vision-Language Models internalize an explicit semantic concept of forgery, while Self-Supervised Learning models implicitly acquire discriminative forensic features from the pretraining data. However, we also reveal persistent limitations: these models suffer from performance degradation under recapture and transmission, remain blind to VAE reconstruction and localized editing. We conclude by advocating for a paradigm shift in AI forensics, moving from overfitting on static benchmarks to harnessing the evolving world knowledge of foundation models for real-world reliability.",
    "published": "2026-02-02T07:20:02Z",
    "updated": "2026-02-02T07:20:02Z",
    "authors": [
      "Yue Zhou",
      "Xinan He",
      "Kaiqing Lin",
      "Bing Fan",
      "Feng Ding",
      "Bin Li"
    ],
    "primary_category": "cs.CV",
    "categories": [
      "cs.CV"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01738v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01738v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 4.8,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01725v1",
    "title": "SafePred: A Predictive Guardrail for Computer-Using Agents via World Models",
    "summary": "With the widespread deployment of Computer-using Agents (CUAs) in complex real-world environments, prevalent long-term risks often lead to severe and irreversible consequences. Most existing guardrails for CUAs adopt a reactive approach, constraining agent behavior only within the current observation space. While these guardrails can prevent immediate short-term risks (e.g., clicking on a phishing link), they cannot proactively avoid long-term risks: seemingly reasonable actions can lead to high-risk consequences that emerge with a delay (e.g., cleaning logs leads to future audits being untraceable), which reactive guardrails cannot identify within the current observation space. To address these limitations, we propose a predictive guardrail approach, with the core idea of aligning predicted future risks with current decisions. Based on this approach, we present SafePred, a predictive guardrail framework for CUAs that establishes a risk-to-decision loop to ensure safe agent behavior. SafePred supports two key abilities: (1) Short- and long-term risk prediction: by using safety policies as the basis for risk prediction, SafePred leverages the prediction capability of the world model to generate semantic representations of both short-term and long-term risks, thereby identifying and pruning actions that lead to high-risk states; (2) Decision optimization: translating predicted risks into actionable safe decision guidances through step-level interventions and task-level re-planning. Extensive experiments show that SafePred significantly reduces high-risk behaviors, achieving over 97.6% safety performance and improving task utility by up to 21.4% compared with reactive baselines.",
    "published": "2026-02-02T07:04:06Z",
    "updated": "2026-02-02T07:04:06Z",
    "authors": [
      "Yurun Chen",
      "Zeyi Liao",
      "Ping Yin",
      "Taotao Xie",
      "Keting Yin",
      "Shengyu Zhang"
    ],
    "primary_category": "cs.CL",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01725v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01725v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 4.8,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01662v1",
    "title": "AgenticLab: A Real-World Robot Agent Platform that Can See, Think, and Act",
    "summary": "Recent advances in large vision-language models (VLMs) have demonstrated generalizable open-vocabulary perception and reasoning, yet their real-robot manipulation capability remains unclear for long-horizon, closed-loop execution in unstructured, in-the-wild environments. Prior VLM-based manipulation pipelines are difficult to compare across different research groups' setups, and many evaluations rely on simulation, privileged state, or specially designed setups. We present AgenticLab, a model-agnostic robot agent platform and benchmark for open-world manipulation. AgenticLab provides a closed-loop agent pipeline for perception, task decomposition, online verification, and replanning. Using AgenticLab, we benchmark state-of-the-art VLM-based agents on real-robot tasks in unstructured environments. Our benchmark reveals several failure modes that offline vision-language tests (e.g., VQA and static image understanding) fail to capture, including breakdowns in multi-step grounding consistency, object grounding under occlusion and scene changes, and insufficient spatial reasoning for reliable manipulation. We will release the full hardware and software stack to support reproducible evaluation and accelerate research on general-purpose robot agents.",
    "published": "2026-02-02T05:30:14Z",
    "updated": "2026-02-02T05:30:14Z",
    "authors": [
      "Pengyuan Guo",
      "Zhonghao Mai",
      "Zhengtong Xu",
      "Kaidi Zhang",
      "Heng Zhang",
      "Zichen Miao",
      "Arash Ajoudani",
      "Zachary Kingston",
      "Qiang Qiu",
      "Yu She"
    ],
    "primary_category": "cs.RO",
    "categories": [
      "cs.RO"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01662v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01662v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 4.8,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01651v1",
    "title": "On the Spatiotemporal Dynamics of Generalization in Neural Networks",
    "summary": "Why do neural networks fail to generalize addition from 16-digit to 32-digit numbers, while a child who learns the rule can apply it to arbitrarily long sequences? We argue that this failure is not an engineering problem but a violation of physical postulates. Drawing inspiration from physics, we identify three constraints that any generalizing system must satisfy: (1) Locality -- information propagates at finite speed; (2) Symmetry -- the laws of computation are invariant across space and time; (3) Stability -- the system converges to discrete attractors that resist noise accumulation. From these postulates, we derive -- rather than design -- the Spatiotemporal Evolution with Attractor Dynamics (SEAD) architecture: a neural cellular automaton where local convolutional rules are iterated until convergence. Experiments on three tasks validate our theory: (1) Parity -- demonstrating perfect length generalization via light-cone propagation; (2) Addition -- achieving scale-invariant inference from L=16 to L=1 million with 100% accuracy, exhibiting input-adaptive computation; (3) Rule 110 -- learning a Turing-complete cellular automaton without trajectory divergence. Our results suggest that the gap between statistical learning and logical reasoning can be bridged -- not by scaling parameters, but by respecting the physics of computation.",
    "published": "2026-02-02T05:11:48Z",
    "updated": "2026-02-02T05:11:48Z",
    "authors": [
      "Zichao Wei"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01651v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01651v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 4.8,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01637v1",
    "title": "Chance-Constrained Inference for Hallucination Risk Control in Large Language Models",
    "summary": "Large language models generate outputs stochastically and may produce fluent but invalid responses, including factual hallucinations. Existing mitigation strategies reduce average error rates but do not provide explicit control over the \\emph{frequency} of such failures under repeated use. We formulate inference as a deployment-time risk control problem and introduce \\emph{chance-constrained inference}, which directly bounds the probability of hallucinations among accepted generations. Hallucinations are modeled as stochastic constraint violations, and we show that confidence-based selective prediction does not, in general, imply probabilistic risk guarantees. To enforce chance constraints efficiently, we propose a sequential, anytime-valid inference procedure that adaptively certifies feasibility or infeasibility using finite samples, avoiding conservative fixed-sample bounds. Experiments on questions inspired by NaturalQuestions and controlled multi-hop question answering demonstrate reliable risk control, early detection of intrinsically infeasible inputs, and safe composition under repeated use, while confidence-based baselines fail to provide consistent guarantees.",
    "published": "2026-02-02T04:51:47Z",
    "updated": "2026-02-02T04:51:47Z",
    "authors": [
      "Sreenivasan Mohandas"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01637v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01637v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 4.8,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01606v1",
    "title": "Boosting Maximum Entropy Reinforcement Learning via One-Step Flow Matching",
    "summary": "Diffusion policies are expressive yet incur high inference latency. Flow Matching (FM) enables one-step generation, but integrating it into Maximum Entropy Reinforcement Learning (MaxEnt RL) is challenging: the optimal policy is an intractable energy-based distribution, and the efficient log-likelihood estimation required to balance exploration and exploitation suffers from severe discretization bias. We propose \\textbf{F}low-based \\textbf{L}og-likelihood-\\textbf{A}ware \\textbf{M}aximum \\textbf{E}ntropy RL (\\textbf{FLAME}), a principled framework that addresses these challenges. First, we derive a Q-Reweighted FM objective that bypasses partition function estimation via importance reweighting. Second, we design a decoupled entropy estimator that rigorously corrects bias, which enables efficient exploration and brings the policy closer to the optimal MaxEnt policy. Third, we integrate the MeanFlow formulation to achieve expressive and efficient one-step control. Empirical results on MuJoCo show that FLAME outperforms Gaussian baselines and matches multi-step diffusion policies with significantly lower inference cost. Code is available at https://github.com/lzqw/FLAME.",
    "published": "2026-02-02T03:54:11Z",
    "updated": "2026-02-02T03:54:11Z",
    "authors": [
      "Zeqiao Li",
      "Yijing Wang",
      "Haoyu Wang",
      "Zheng Li",
      "Zhiqiang Zuo"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01606v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01606v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 4.8,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01607v1",
    "title": "Minimax optimal differentially private synthetic data for smooth queries",
    "summary": "Differentially private synthetic data enables the sharing and analysis of sensitive datasets while providing rigorous privacy guarantees for individual contributors. A central challenge is to achieve strong utility guarantees for meaningful downstream analysis. Many existing methods ensure uniform accuracy over broad query classes, such as all Lipschitz functions, but this level of generality often leads to suboptimal rates for statistics of practical interest. Since many common data analysis queries exhibit smoothness beyond what worst-case Lipschitz bounds capture, we ask whether exploiting this additional structure can yield improved utility. We study the problem of generating $(\\varepsilon,)$-differentially private synthetic data from a dataset of size $n$ supported on the hypercube $[-1,1]^d$, with utility guarantees uniformly for all smooth queries having bounded derivatives up to order $k$. We propose a polynomial-time algorithm that achieves a minimax error rate of $n^{-\\min \\{1, \\frac{k}{d}\\}}$, up to a $\\log(n)$ factor. This characterization uncovers a phase transition at $k=d$. Our results generalize the Chebyshev moment matching framework of (Musco et al., 2025; Wang et al., 2016) and strictly improve the error rates for $k$-smooth queries established in (Wang et al., 2016). Moreover, we establish the first minimax lower bound for the utility of $(\\varepsilon,)$-differentially private synthetic data with respect to $k$-smooth queries, extending the Wasserstein lower bound for $\\varepsilon$-differential privacy in (Boedihardjo et al., 2024).",
    "published": "2026-02-02T03:54:11Z",
    "updated": "2026-02-02T03:54:11Z",
    "authors": [
      "Rundong Ding",
      "Yiyun He",
      "Yizhe Zhu"
    ],
    "primary_category": "math.ST",
    "categories": [
      "math.ST",
      "cs.IT",
      "cs.LG",
      "stat.ML"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01607v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01607v1",
    "comment": "27 pages",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 4.8,
    "matched_areas": [
      "vision"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01601v1",
    "title": "Adaptive Rollout Allocation for Online Reinforcement Learning with Verifiable Rewards",
    "summary": "Sampling efficiency is a key bottleneck in reinforcement learning with verifiable rewards. Existing group-based policy optimization methods, such as GRPO, allocate a fixed number of rollouts for all training prompts. This uniform allocation implicitly treats all prompts as equally informative, and could lead to inefficient computational budget usage and impede training progress. We introduce \\Ours, a Variance-Informed Predictive allocation strategy that allocates a given rollout budget to the prompts in the incumbent batch to minimize the expected gradient variance of the policy update. At each iteration, \\Ours~uses a lightweight Gaussian process model to predict per-prompt success probabilities based on recent rollouts. These probability predictions are translated into variance estimates, which are then fed into a convex optimization problem to determine the optimal rollout allocations under a hard compute budget constraint. Empirical results show that \\Ours~consistently improves sampling efficiency and achieves higher performance than uniform or heuristic allocation strategies in multiple benchmarks. Our code will be available at https://github.com/HieuNT91/VIP.",
    "published": "2026-02-02T03:50:01Z",
    "updated": "2026-02-02T03:50:01Z",
    "authors": [
      "Hieu Trung Nguyen",
      "Bao Nguyen",
      "Wenao Ma",
      "Yuzhi Zhao",
      "Ruifeng She",
      "Viet Anh Nguyen"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01601v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01601v1",
    "comment": "Accepted at ICLR 2026",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 4.8,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01600v1",
    "title": "Expected Harm: Rethinking Safety Evaluation of (Mis)Aligned LLMs",
    "summary": "Current evaluations of LLM safety predominantly rely on severity-based taxonomies to assess the harmfulness of malicious queries. We argue that this formulation requires re-examination as it assumes uniform risk across all malicious queries, neglecting Execution Likelihood--the conditional probability of a threat being realized given the model's response. In this work, we introduce Expected Harm, a metric that weights the severity of a jailbreak by its execution likelihood, modeled as a function of execution cost. Through empirical analysis of state-of-the-art models, we reveal a systematic Inverse Risk Calibration: models disproportionately exhibit stronger refusal behaviors for low-likelihood (high-cost) threats while remaining vulnerable to high-likelihood (low-cost) queries. We demonstrate that this miscalibration creates a structural vulnerability: by exploiting this property, we increase the attack success rate of existing jailbreaks by up to $2\\times$. Finally, we trace the root cause of this failure using linear probing, which reveals that while models encode severity in their latent space to drive refusal decisions, they possess no distinguishable internal representation of execution cost, making them \"blind\" to this critical dimension of risk.",
    "published": "2026-02-02T03:48:04Z",
    "updated": "2026-02-02T03:48:04Z",
    "authors": [
      "Yen-Shan Chen",
      "Zhi Rui Tam",
      "Cheng-Kuang Wu",
      "Yun-Nung Chen"
    ],
    "primary_category": "cs.CR",
    "categories": [
      "cs.CR",
      "cs.CL",
      "cs.CY",
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01600v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01600v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 4.8,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01586v1",
    "title": "HandMCM: Multi-modal Point Cloud-based Correspondence State Space Model for 3D Hand Pose Estimation",
    "summary": "3D hand pose estimation that involves accurate estimation of 3D human hand keypoint locations is crucial for many human-computer interaction applications such as augmented reality. However, this task poses significant challenges due to self-occlusion of the hands and occlusions caused by interactions with objects. In this paper, we propose HandMCM to address these challenges. Our HandMCM is a novel method based on the powerful state space model (Mamba). By incorporating modules for local information injection/filtering and correspondence modeling, the proposed correspondence Mamba effectively learns the highly dynamic kinematic topology of keypoints across various occlusion scenarios. Moreover, by integrating multi-modal image features, we enhance the robustness and representational capacity of the input, leading to more accurate hand pose estimation. Empirical evaluations on three benchmark datasets demonstrate that our model significantly outperforms current state-of-the-art methods, particularly in challenging scenarios involving severe occlusions. These results highlight the potential of our approach to advance the accuracy and reliability of 3D hand pose estimation in practical applications.",
    "published": "2026-02-02T03:25:43Z",
    "updated": "2026-02-02T03:25:43Z",
    "authors": [
      "Wencan Cheng",
      "Gim Hee Lee"
    ],
    "primary_category": "cs.CV",
    "categories": [
      "cs.CV"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01586v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01586v1",
    "comment": "AAAI accepted",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 4.8,
    "matched_areas": [
      "vision"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01577v1",
    "title": "Visible Light Positioning With Lam Curve LEDs: A Generic Approach for Camera Pose Estimation",
    "summary": "Camera-based visible light positioning (VLP) is a promising technique for accurate and low-cost indoor camera pose estimation (CPE). To reduce the number of required light-emitting diodes (LEDs), advanced methods commonly exploit LED shape features for positioning. Although interesting, they are typically restricted to a single LED geometry, leading to failure in heterogeneous LED-shape scenarios. To address this challenge, this paper investigates Lam curves as a unified representation of common LED shapes and proposes a generic VLP algorithm using Lam curve-shaped LEDs, termed LC-VLP. In the considered system, multiple ceiling-mounted Lam curve-shaped LEDs periodically broadcast their curve parameters via visible light communication, which are captured by a camera-equipped receiver. Based on the received LED images and curve parameters, the receiver can estimate the camera pose using LC-VLP. Specifically, an LED database is constructed offline to store the curve parameters, while online positioning is formulated as a nonlinear least-squares problem and solved iteratively. To provide a reliable initialization, a correspondence-free perspective-\\textit{n}-points (FreeP\\textit{n}P) algorithm is further developed, enabling approximate CPE without any pre-calibrated reference points. The performance of LC-VLP is verified by both simulations and experiments. Simulations show that LC-VLP outperforms state-of-the-art methods in both circular- and rectangular-LED scenarios, achieving reductions of over 40% in position error and 25% in rotation error. Experiments further show that LC-VLP can achieve an average position accuracy of less than 4 cm.",
    "published": "2026-02-02T03:14:05Z",
    "updated": "2026-02-02T03:14:05Z",
    "authors": [
      "Wenxuan Pan",
      "Yang Yang",
      "Dong Wei",
      "Zhiyu Zhu",
      "Jintao Wang",
      "Huan Wu",
      "Yao Nie"
    ],
    "primary_category": "eess.SP",
    "categories": [
      "eess.SP",
      "cs.CV"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01577v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01577v1",
    "comment": "Submitted to an IEEE journal for possible publication",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 4.8,
    "matched_areas": [
      "vision"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01532v1",
    "title": "PRISM: Festina Lente Proactivity -- Risk-Sensitive, Uncertainty-Aware Deliberation for Proactive Agents",
    "summary": "Proactive agents must decide not only what to say but also whether and when to intervene. Many current systems rely on brittle heuristics or indiscriminate long reasoning, which offers little control over the benefit-burden tradeoff. We formulate the problem as cost-sensitive selective intervention and present PRISM, a novel framework that couples a decision-theoretic gate with a dual-process reasoning architecture. At inference time, the agent intervenes only when a calibrated probability of user acceptance exceeds a threshold derived from asymmetric costs of missed help and false alarms. Inspired by festina lente (Latin: \"make haste slowly\"), we gate by an acceptance-calibrated, cost-derived threshold and invoke a resource-intensive Slow mode with counterfactual checks only near the decision boundary, concentrating computation on ambiguous and high-stakes cases. Training uses gate-aligned, schema-locked distillation: a teacher running the full PRISM pipeline provides dense, executable supervision on unlabeled interaction traces, while the student learns a response policy that is explicitly decoupled from the intervention gate to enable tunable and auditable control. On ProactiveBench, PRISM reduces false alarms by 22.78% and improves F1 by 20.14% over strong baselines. These results show that principled decision-theoretic gating, paired with selective slow reasoning and aligned distillation, yields proactive agents that are precise, computationally efficient, and controllable. To facilitate reproducibility, we release our code, models, and resources at https://prism-festinalente.github.io/; all experiments use the open-source ProactiveBench benchmark.",
    "published": "2026-02-02T01:56:29Z",
    "updated": "2026-02-02T01:56:29Z",
    "authors": [
      "Yuxuan Fu",
      "Xiaoyu Tan",
      "Teqi Hao",
      "Chen Zhan",
      "Xihe Qiu"
    ],
    "primary_category": "cs.AI",
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01532v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01532v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 4.8,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02488v1",
    "title": "RLAnything: Forge Environment, Policy, and Reward Model in Completely Dynamic RL System",
    "summary": "We propose RLAnything, a reinforcement learning framework that dynamically forges environment, policy, and reward models through closed-loop optimization, amplifying learning signals and strengthening the overall RL system for any LLM or agentic scenarios. Specifically, the policy is trained with integrated feedback from step-wise and outcome signals, while the reward model is jointly optimized via consistency feedback, which in turn further improves policy training. Moreover, our theory-motivated automatic environment adaptation improves training for both the reward and policy models by leveraging critic feedback from each, enabling learning from experience. Empirically, each added component consistently improves the overall system, and RLAnything yields substantial gains across various representative LLM and agentic tasks, boosting Qwen3-VL-8B-Thinking by 9.1% on OSWorld and Qwen2.5-7B-Instruct by 18.7% and 11.9% on AlfWorld and LiveBench, respectively. We also that optimized reward-model signals outperform outcomes that rely on human labels. Code: https://github.com/Gen-Verse/Open-AgentRL",
    "published": "2026-02-02T18:59:04Z",
    "updated": "2026-02-02T18:59:04Z",
    "authors": [
      "Yinjie Wang",
      "Tianbao Xie",
      "Ke Shen",
      "Mengdi Wang",
      "Ling Yang"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02488v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02488v1",
    "comment": "Code: https://github.com/Gen-Verse/Open-AgentRL",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 3.6,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02470v1",
    "title": "Breaking the Reversal Curse in Autoregressive Language Models via Identity Bridge",
    "summary": "Autoregressive large language models (LLMs) have achieved remarkable success in many complex tasks, yet they can still fail in very simple logical reasoning such as the \"reversal curse\" -- when trained on forward knowledge data of the form \"$A \\rightarrow B$\" (e.g., Alice's husband is Bob), the model is unable to deduce the reversal knowledge \"$B \\leftarrow A$\" (e.g., Bob's wife is Alice) during test. Extensive prior research suggests that this failure is an inherent, fundamental limit of autoregressive causal LLMs, indicating that these models tend to memorize factual-level knowledge rather than capture higher-level rules. In this paper, we challenge this view by showing that this seemingly fundamental limit can be mitigated by slightly tweaking the training data with a simple regularization data recipe called the Identity Bridge of the form \"$A \\to A$\" (e.g., The name of Alice is Alice). Theoretically, we prove that under this recipe, even a one-layer transformer can break the reversal curse by analyzing the implicit bias of gradient descent. Empirically, we show that a 1B pretrained language model finetuned with the proposed data recipe achieves a 40% success rate on reversal tasks, in stark contrast to a near-zero success rate when trained solely on forward-knowledge data. Our work provides a novel theoretical foundation for the reversal curse and offers a principled, low-cost path to encouraging LLMs to learn higher-level rules from data.",
    "published": "2026-02-02T18:50:57Z",
    "updated": "2026-02-02T18:50:57Z",
    "authors": [
      "Xutao Ma",
      "Yixiao Huang",
      "Hanlin Zhu",
      "Somayeh Sojoudi"
    ],
    "primary_category": "cs.AI",
    "categories": [
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02470v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02470v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 3.6,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02426v1",
    "title": "SelvaMask: Segmenting Trees in Tropical Forests and Beyond",
    "summary": "Tropical forests harbor most of the planet's tree biodiversity and are critical to global ecological balance. Canopy trees in particular play a disproportionate role in carbon storage and functioning of these ecosystems. Studying canopy trees at scale requires accurate delineation of individual tree crowns, typically performed using high-resolution aerial imagery. Despite advances in transformer-based models for individual tree crown segmentation, performance remains low in most forests, especially tropical ones. To this end, we introduce SelvaMask, a new tropical dataset containing over 8,800 manually delineated tree crowns across three Neotropical forest sites in Panama, Brazil, and Ecuador. SelvaMask features comprehensive annotations, including an inter-annotator agreement evaluation, capturing the dense structure of tropical forests and highlighting the difficulty of the task. Leveraging this benchmark, we propose a modular detection-segmentation pipeline that adapts vision foundation models (VFMs), using domain-specific detection-prompter. Our approach reaches state-of-the-art performance, outperforming both zero-shot generalist models and fully supervised end-to-end methods in dense tropical forests. We validate these gains on external tropical and temperate datasets, demonstrating that SelvaMask serves as both a challenging benchmark and a key enabler for generalized forest monitoring. Our code and dataset will be released publicly.",
    "published": "2026-02-02T18:26:56Z",
    "updated": "2026-02-02T18:26:56Z",
    "authors": [
      "Simon-Olivier Duguay",
      "Hugo Baudchon",
      "Etienne Lalibert",
      "Helene Muller-Landau",
      "Gonzalo Rivas-Torres",
      "Arthur Ouaknine"
    ],
    "primary_category": "cs.CV",
    "categories": [
      "cs.CV"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02426v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02426v1",
    "comment": "22 pages, 8 figures",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 3.6,
    "matched_areas": [
      "ai",
      "vision"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02416v1",
    "title": "Structure Enables Effective Self-Localization of Errors in LLMs",
    "summary": "Self-correction in language models remains elusive. In this work, we explore whether language models can explicitly localize errors in incorrect reasoning, as a path toward building AI systems that can effectively correct themselves. We introduce a prompting method that structures reasoning as discrete, semantically coherent thought steps, and show that models are able to reliably localize errors within this structure, while failing to do so in conventional, unstructured chain-of-thought reasoning. Motivated by how the human brain monitors errors at discrete decision points and resamples alternatives, we introduce Iterative Correction Sampling of Thoughts (Thought-ICS), a self-correction framework. Thought-ICS iteratively prompts the model to generate reasoning one discrete and complete thought at a time--where each thought represents a deliberate decision by the model--creating natural boundaries for precise error localization. Upon verification, the model localizes the first erroneous step, and the system backtracks to generate alternative reasoning from the last correct point. When asked to correct reasoning verified as incorrect by an oracle, Thought-ICS achieves 20-40% self-correction lift. In a completely autonomous setting without external verification, it outperforms contemporary self-correction baselines.",
    "published": "2026-02-02T18:15:59Z",
    "updated": "2026-02-02T18:15:59Z",
    "authors": [
      "Ankur Samanta",
      "Akshayaa Magesh",
      "Ayush Jain",
      "Kavosh Asadi",
      "Youliang Yu",
      "Daniel Jiang",
      "Boris Vidolov",
      "Kaveh Hassani",
      "Paul Sajda",
      "Jalaj Bhandari",
      "Yonathan Efroni"
    ],
    "primary_category": "cs.AI",
    "categories": [
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02416v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02416v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 3.6,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02401v1",
    "title": "Superman: Unifying Skeleton and Vision for Human Motion Perception and Generation",
    "summary": "Human motion analysis tasks, such as temporal 3D pose estimation, motion prediction, and motion in-betweening, play an essential role in computer vision. However, current paradigms suffer from severe fragmentation. First, the field is split between ``perception'' models that understand motion from video but only output text, and ``generation'' models that cannot perceive from raw visual input. Second, generative MLLMs are often limited to single-frame, static poses using dense, parametric SMPL models, failing to handle temporal motion. Third, existing motion vocabularies are built from skeleton data alone, severing the link to the visual domain. To address these challenges, we introduce Superman, a unified framework that bridges visual perception with temporal, skeleton-based motion generation. Our solution is twofold. First, to overcome the modality disconnect, we propose a Vision-Guided Motion Tokenizer. Leveraging the natural geometric alignment between 3D skeletons and visual data, this module pioneers robust joint learning from both modalities, creating a unified, cross-modal motion vocabulary. Second, grounded in this motion language, a single, unified MLLM architecture is trained to handle all tasks. This module flexibly processes diverse, temporal inputs, unifying 3D skeleton pose estimation from video (perception) with skeleton-based motion prediction and in-betweening (generation). Extensive experiments on standard benchmarks, including Human3.6M, demonstrate that our unified method achieves state-of-the-art or competitive performance across all motion tasks. This showcases a more efficient and scalable path for generative motion analysis using skeletons.",
    "published": "2026-02-02T17:59:01Z",
    "updated": "2026-02-02T17:59:01Z",
    "authors": [
      "Xinshun Wang",
      "Peiming Li",
      "Ziyi Wang",
      "Zhongbin Fang",
      "Zhichao Deng",
      "Songtao Wu",
      "Jason Li",
      "Mengyuan Liu"
    ],
    "primary_category": "cs.CV",
    "categories": [
      "cs.CV"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02401v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02401v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 3.6,
    "matched_areas": [
      "ai",
      "vision"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02383v1",
    "title": "SLIME: Stabilized Likelihood Implicit Margin Enforcement for Preference Optimization",
    "summary": "Direct preference optimization methods have emerged as a computationally efficient alternative to Reinforcement Learning from Human Feedback (RLHF) for aligning Large Language Models (LLMs). Latest approaches have streamlined the alignment process by deriving implicit reward functions, yet they often suffer from a critical objective mismatch: optimizing the relative margin between chosen and rejected responses does not guarantee the preservation of the chosen response's absolute likelihood. This can lead to ``unlearning'', where the model degrades the probability of high-quality outputs to satisfy margin constraints, and ``formatting collapse'' caused by the over-penalization of rejected sequences. In this work, we introduce SLIME (Stabilized Likelihood Implicit Margin Enforcement), a reference-free alignment objective designed to decouple preference learning from generation quality. SLIME incorporates a three-pronged objective: (1) an anchoring term to maximize the likelihood of preferred responses; (2) a stabilizing penalty that prevents the probabilities of rejected tokens from collapsing to zero; and (3) a dual-margin mechanism that combines hard and soft constraints for precise boundary shaping. Our results demonstrate that SLIME achieves superior performance compared to state-of-the-art baselines while maintaining higher generation stability.",
    "published": "2026-02-02T17:46:06Z",
    "updated": "2026-02-02T17:46:06Z",
    "authors": [
      "Maksim Afanasyev",
      "Illarion Iov"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02383v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02383v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 3.6,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02335v1",
    "title": "Building a Correct-by-Design Lakehouse. Data Contracts, Versioning, and Transactional Pipelines for Humans and Agents",
    "summary": "Lakehouses are the default cloud platform for analytics and AI, but they become unsafe when untrusted actors concurrently operate on production data: upstream-downstream mismatches surface only at runtime, and multi-table pipelines can leak partial effects. Inspired by software engineering, we design Bauplan, a code-first lakehouse that aims to make (most) illegal states unrepresentable using familiar abstractions. Bauplan acts along three axes: typed table contracts to make pipeline boundaries checkable, Git-like data versioning for review and reproducibility, and transactional runs that guarantee pipeline-level atomicity. We report early results from a lightweight formal transaction model and discuss future work motivated by counterexamples.",
    "published": "2026-02-02T16:58:38Z",
    "updated": "2026-02-02T16:58:38Z",
    "authors": [
      "Weiming Sheng",
      "Jinlang Wang",
      "Manuel Barros",
      "Aldrin Montana",
      "Jacopo Tagliabue",
      "Luca Bigon"
    ],
    "primary_category": "cs.DC",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.DB"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02335v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02335v1",
    "comment": "Pre-print (PaPoC 2026)",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 3.6,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02288v1",
    "title": "An Optimization Method for Autoregressive Time Series Forecasting",
    "summary": "Current time-series forecasting models are primarily based on transformer-style neural networks. These models achieve long-term forecasting mainly by scaling up the model size rather than through genuinely autoregressive (AR) rollout. From the perspective of large language model training, the traditional training process for time-series forecasting models ignores temporal causality. In this paper, we propose a novel training method for time-series forecasting that enforces two key properties: (1) AR prediction errors should increase with the forecasting horizon. Any violation of this principle is considered random guessing and is explicitly penalized in the loss function, and (2) the method enables models to concatenate short-term AR predictions for forming flexible long-term forecasts. Empirical results demonstrate that our method establishes a new state-of-the-art across multiple benchmarks, achieving an MSE reduction of more than 10% compared to iTransformer and other recent strong baselines. Furthermore, it enables short-horizon forecasting models to perform reliable long-term predictions at horizons over 7.5 times longer. Code is available at https://github.com/LizhengMathAi/AROpt",
    "published": "2026-02-02T16:28:00Z",
    "updated": "2026-02-02T16:28:00Z",
    "authors": [
      "Zheng Li",
      "Jerry Cheng",
      "Huanying Gu"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02288v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02288v1",
    "comment": "10 pages, 2 figures, 2 tables",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 3.6,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02285v1",
    "title": "Statistical Learning Theory in Lean 4: Empirical Processes from Scratch",
    "summary": "We present the first comprehensive Lean 4 formalization of statistical learning theory (SLT) grounded in empirical process theory. Our end-to-end formal infrastructure implement the missing contents in latest Lean 4 Mathlib library, including a complete development of Gaussian Lipschitz concentration, the first formalization of Dudley's entropy integral theorem for sub-Gaussian processes, and an application to least-squares (sparse) regression with a sharp rate. The project was carried out using a human-AI collaborative workflow, in which humans design proof strategies and AI agents execute tactical proof construction, leading to the human-verified Lean 4 toolbox for SLT. Beyond implementation, the formalization process exposes and resolves implicit assumptions and missing details in standard SLT textbooks, enforcing a granular, line-by-line understanding of the theory. This work establishes a reusable formal foundation and opens the door for future developments in machine learning theory. The code is available at https://github.com/YuanheZ/lean-stat-learning-theory",
    "published": "2026-02-02T16:24:53Z",
    "updated": "2026-02-02T16:24:53Z",
    "authors": [
      "Yuanhe Zhang",
      "Jason D. Lee",
      "Fanghui Liu"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "cs.CL",
      "math.ST"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02285v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02285v1",
    "comment": "19 pages, 2 figures. Comments are welcome",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 3.6,
    "matched_areas": [
      "ai",
      "agents"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02236v1",
    "title": "Online Fine-Tuning of Pretrained Controllers for Autonomous Driving via Real-Time Recurrent RL",
    "summary": "Deploying pretrained policies in real-world applications presents substantial challenges that fundamentally limit the practical applicability of learning-based control systems. When autonomous systems encounter environmental changes in system dynamics, sensor drift, or task objectives, fixed policies rapidly degrade in performance. We show that employing Real-Time Recurrent Reinforcement Learning (RTRRL), a biologically plausible algorithm for online adaptation, can effectively fine-tune a pretrained policy to improve autonomous agents' performance on driving tasks. We further show that RTRRL synergizes with a recent biologically inspired recurrent network model, the Liquid-Resistance Liquid-Capacitance RNN. We demonstrate the effectiveness of this closed-loop approach in a simulated CarRacing environment and in a real-world line-following task with a RoboRacer car equipped with an event camera.",
    "published": "2026-02-02T15:41:53Z",
    "updated": "2026-02-02T15:41:53Z",
    "authors": [
      "Julian Lemmel",
      "Felix Resch",
      "Mnika Farsang",
      "Ramin Hasani",
      "Daniela Rus",
      "Radu Grosu"
    ],
    "primary_category": "cs.RO",
    "categories": [
      "cs.RO",
      "cs.LG",
      "cs.NE",
      "eess.SY"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02236v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02236v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 3.6,
    "matched_areas": [
      "ai",
      "agents"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02197v1",
    "title": "Hierarchical Adaptive Eviction for KV Cache Management in Multimodal Language Models",
    "summary": "The integration of visual information into Large Language Models (LLMs) has enabled Multimodal LLMs (MLLMs), but the quadratic memory and computational costs of Transformer architectures remain a bottleneck. Existing KV cache eviction strategies fail to address the heterogeneous attention distributions between visual and text tokens, leading to suboptimal efficiency or degraded performance. In this paper, we propose Hierarchical Adaptive Eviction (HAE), a KV cache eviction framework that optimizes text-visual token interaction in MLLMs by implementing Dual-Attention Pruning during pre-filling (leveraging visual token sparsity and attention variance) and a Dynamic Decoding Eviction Strategy (inspired by OS Recycle Bins) during decoding. HAE minimizes KV cache usage across layers, reduces computational overhead via index broadcasting, and theoretically ensures superior information integrity and lower error bounds compared to greedy strategies, enhancing efficiency in both comprehension and generation tasks. Empirically, HAE reduces KV-Cache memory by 41\\% with minimal accuracy loss (0.3\\% drop) in image understanding tasks and accelerates story generation inference by 1.5x while maintaining output quality on Phi3.5-Vision-Instruct model.",
    "published": "2026-02-02T15:01:44Z",
    "updated": "2026-02-02T15:01:44Z",
    "authors": [
      "Xindian Ma",
      "Yidi Lu",
      "Peng Zhang",
      "Jing Zhang"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02197v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02197v1",
    "comment": "10 oages, 3 figures",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 3.6,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02113v1",
    "title": "Training-free score-based diffusion for parameter-dependent stochastic dynamical systems",
    "summary": "Simulating parameter-dependent stochastic differential equations (SDEs) presents significant computational challenges, as separate high-fidelity simulations are typically required for each parameter value of interest. Despite the success of machine learning methods in learning SDE dynamics, existing approaches either require expensive neural network training for score function estimation or lack the ability to handle continuous parameter dependence. We present a training-free conditional diffusion model framework for learning stochastic flow maps of parameter-dependent SDEs, where both drift and diffusion coefficients depend on physical parameters. The key technical innovation is a joint kernel-weighted Monte Carlo estimator that approximates the conditional score function using trajectory data sampled at discrete parameter values, enabling interpolation across both state space and the continuous parameter domain. Once trained, the resulting generative model produces sample trajectories for any parameter value within the training range without retraining, significantly accelerating parameter studies, uncertainty quantification, and real-time filtering applications. The performance of the proposed approach is demonstrated via three numerical examples of increasing complexity, showing accurate approximation of conditional distributions across varying parameter values.",
    "published": "2026-02-02T13:54:36Z",
    "updated": "2026-02-02T13:54:36Z",
    "authors": [
      "Minglei Yang",
      "Sicheng He"
    ],
    "primary_category": "stat.ML",
    "categories": [
      "stat.ML",
      "cs.LG",
      "math.NA"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02113v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02113v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 3.6,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02001v1",
    "title": "Preserve-Then-Quantize: Balancing Rank Budgets for Quantization Error Reconstruction in LLMs",
    "summary": "Quantization Error Reconstruction (QER) reduces accuracy loss in Post-Training Quantization (PTQ) by approximating weights as $\\mathbf{W} \\approx \\mathbf{Q} + \\mathbf{L}\\mathbf{R}$, using a rank-$r$ correction to reconstruct quantization error. Prior methods devote the full rank budget to error reconstruction, which is suboptimal when $\\mathbf{W}$ has intrinsic low-rank structure and quantization corrupts dominant directions. We propose Structured Residual Reconstruction (SRR), a rank-allocation framework that preserves the top-$k$ singular subspace of the activation-scaled weight before quantization, quantizes only the residual, and uses the remaining rank $r-k$ for error reconstruction. We derive a theory-guided criterion for selecting $k$ by balancing quantization-exposed energy and unrecoverable error under rank constraints. We further show that resulting $\\mathbf{Q} + \\mathbf{L}\\mathbf{R}$ parameterization naturally supports Quantized Parameter-Efficient Fine-Tuning (QPEFT), and stabilizes fine-tuning via gradient scaling along preserved directions. Experiments demonstrate consistent perplexity reductions across diverse models and quantization settings in PTQ, along with a 5.9 percentage-point average gain on GLUE under 2-bit QPEFT.",
    "published": "2026-02-02T12:02:21Z",
    "updated": "2026-02-02T12:02:21Z",
    "authors": [
      "Yoonjun Cho",
      "Dongjae Jeon",
      "Soeun Kim",
      "Moongyu Jeon",
      "Albert No"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02001v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02001v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 3.6,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01930v1",
    "title": "LIEREx: Language-Image Embeddings for Robotic Exploration",
    "summary": "Semantic maps allow a robot to reason about its surroundings to fulfill tasks such as navigating known environments, finding specific objects, and exploring unmapped areas. Traditional mapping approaches provide accurate geometric representations but are often constrained by pre-designed symbolic vocabularies. The reliance on fixed object classes makes it impractical to handle out-of-distribution knowledge not defined at design time. Recent advances in Vision-Language Foundation Models, such as CLIP, enable open-set mapping, where objects are encoded as high-dimensional embeddings rather than fixed labels. In LIEREx, we integrate these VLFMs with established 3D Semantic Scene Graphs to enable target-directed exploration by an autonomous agent in partially unknown environments.",
    "published": "2026-02-02T10:30:50Z",
    "updated": "2026-02-02T10:30:50Z",
    "authors": [
      "Felix Igelbrink",
      "Lennart Niecksch",
      "Marian Renz",
      "Martin Gnther",
      "Martin Atzmueller"
    ],
    "primary_category": "cs.RO",
    "categories": [
      "cs.RO",
      "cs.CV"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01930v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01930v1",
    "comment": "This preprint has not undergone peer review or any post-submission improvements or corrections. The Version of Record of this article is published in KI - Knstliche Intelligenz, and is available online at https://doi.org/10.1007/s13218-026-00902-6",
    "journal_ref": "Knstliche Intelligenz (2026)",
    "doi": "10.1007/s13218-026-00902-6",
    "relevance_score": 3.6,
    "matched_areas": [
      "ai",
      "agents"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01872v1",
    "title": "Grappa: Gradient-Only Communication for Scalable Graph Neural Network Training",
    "summary": "Cross-partition edges dominate the cost of distributed GNN training: fetching remote features and activations per iteration overwhelms the network as graphs deepen and partition counts grow. Grappa is a distributed GNN training framework that enforces gradient-only communication: during each iteration, partitions train in isolation and exchange only gradients for the global update. To recover accuracy lost to isolation, Grappa (i) periodically repartitions to expose new neighborhoods and (ii) applies a lightweight coverage-corrected gradient aggregation inspired by importance sampling. We prove the corrected estimator is asymptotically unbiased under standard support and boundedness assumptions, and we derive a batch-level variant for compatibility with common deep-learning packages that minimizes mean-squared deviation from the ideal node-level correction. We also introduce a shrinkage version that improves stability in practice. Empirical results on real and synthetic graphs show that Grappa trains GNNs 4 times faster on average (up to 13 times) than state-of-the-art systems, achieves better accuracy especially for deeper models, and sustains training at the trillion-edge scale on commodity hardware. Grappa is model-agnostic, supports full-graph and mini-batch training, and does not rely on high-bandwidth interconnects or caching.",
    "published": "2026-02-02T09:44:12Z",
    "updated": "2026-02-02T09:44:12Z",
    "authors": [
      "Chongyang Xu",
      "Christoph Siebenbrunner",
      "Laurent Bindschaedler"
    ],
    "primary_category": "cs.DC",
    "categories": [
      "cs.DC",
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01872v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01872v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 3.6,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01870v1",
    "title": "BTGenBot-2: Efficient Behavior Tree Generation with Small Language Models",
    "summary": "Recent advances in robot learning increasingly rely on LLM-based task planning, leveraging their ability to bridge natural language with executable actions. While prior works showcased great performances, the widespread adoption of these models in robotics has been challenging as 1) existing methods are often closed-source or computationally intensive, neglecting the actual deployment on real-world physical systems, and 2) there is no universally accepted, plug-and-play representation for robotic task generation. Addressing these challenges, we propose BTGenBot-2, a 1B-parameter open-source small language model that directly converts natural language task descriptions and a list of robot action primitives into executable behavior trees in XML. Unlike prior approaches, BTGenBot-2 enables zero-shot BT generation, error recovery at inference and runtime, while remaining lightweight enough for resource-constrained robots. We further introduce the first standardized benchmark for LLM-based BT generation, covering 52 navigation and manipulation tasks in NVIDIA Isaac Sim. Extensive evaluations demonstrate that BTGenBot-2 consistently outperforms GPT-5, Claude Opus 4.1, and larger open-source models across both functional and non-functional metrics, achieving average success rates of 90.38% in zero-shot and 98.07% in one-shot, while delivering up to 16x faster inference compared to the previous BTGenBot.",
    "published": "2026-02-02T09:43:17Z",
    "updated": "2026-02-02T09:43:17Z",
    "authors": [
      "Riccardo Andrea Izzo",
      "Gianluca Bardaro",
      "Matteo Matteucci"
    ],
    "primary_category": "cs.RO",
    "categories": [
      "cs.RO"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01870v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01870v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 3.6,
    "matched_areas": [
      "ai",
      "agents"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01858v1",
    "title": "SOPRAG: Multi-view Graph Experts Retrieval for Industrial Standard Operating Procedures",
    "summary": "Standard Operating Procedures (SOPs) are essential for ensuring operational safety and consistency in industrial environments. However, retrieving and following these procedures presents unique challenges, such as rigid proprietary structures, condition-dependent relevance, and actionable execution requirement, which standard semantic-driven Retrieval-Augmented Generation (RAG) paradigms fail to address. Inspired by the Mixture-of-Experts (MoE) paradigm, we propose SOPRAG, a novel framework specifically designed to address the above pain points in SOP retrieval. SOPRAG replaces flat chunking with specialized Entity, Causal, and Flow graph experts to resolve industrial structural and logical complexities. To optimize and coordinate these experts, we propose a Procedure Card layer that prunes the search space to eliminate computational noise, and an LLM-Guided gating mechanism that dynamically weights these experts to align retrieval with operator intent. To address the scarcity of domain-specific data, we also introduce an automated, multi-agent workflow for benchmark construction. Extensive experiments across four industrial domains demonstrate that SOPRAG significantly outperforms strong lexical, dense, and graph-based RAG baselines in both retrieval accuracy and response utility, achieving perfect execution scores in real-world critical tasks.",
    "published": "2026-02-02T09:30:43Z",
    "updated": "2026-02-02T09:30:43Z",
    "authors": [
      "Liangtao Lin",
      "Zhaomeng Zhu",
      "Tianwei Zhang",
      "Yonggang Wen"
    ],
    "primary_category": "cs.AI",
    "categories": [
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01858v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01858v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 3.6,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01658v1",
    "title": "Efficient Adversarial Attacks on High-dimensional Offline Bandits",
    "summary": "Bandit algorithms have recently emerged as a powerful tool for evaluating machine learning models, including generative image models and large language models, by efficiently identifying top-performing candidates without exhaustive comparisons. These methods typically rely on a reward model, often distributed with public weights on platforms such as Hugging Face, to provide feedback to the bandit. While online evaluation is expensive and requires repeated trials, offline evaluation with logged data has become an attractive alternative. However, the adversarial robustness of offline bandit evaluation remains largely unexplored, particularly when an attacker perturbs the reward model (rather than the training data) prior to bandit training. In this work, we fill this gap by investigating, both theoretically and empirically, the vulnerability of offline bandit training to adversarial manipulations of the reward model. We introduce a novel threat model in which an attacker exploits offline data in high-dimensional settings to hijack the bandit's behavior. Starting with linear reward functions and extending to nonlinear models such as ReLU neural networks, we study attacks on two Hugging Face evaluators used for generative model assessment: one measuring aesthetic quality and the other assessing compositional alignment. Our results show that even small, imperceptible perturbations to the reward model's weights can drastically alter the bandit's behavior. From a theoretical perspective, we prove a striking high-dimensional effect: as input dimensionality increases, the perturbation norm required for a successful attack decreases, making modern applications such as image evaluation especially vulnerable. Extensive experiments confirm that naive random perturbations are ineffective, whereas carefully targeted perturbations achieve near-perfect attack success rates ...",
    "published": "2026-02-02T05:24:31Z",
    "updated": "2026-02-02T05:24:31Z",
    "authors": [
      "Seyed Mohammad Hadi Hosseini",
      "Amir Najafi",
      "Mahdieh Soleymani Baghshah"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01658v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01658v1",
    "comment": "Accepted at ICLR 2026 Conference",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 3.6,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01621v1",
    "title": "Efficient Softmax Reformulation for Homomorphic Encryption via Moment Generating Function",
    "summary": "Homomorphic encryption (HE) is a prominent framework for privacy-preserving machine learning, enabling inference directly on encrypted data. However, evaluating softmax, a core component of transformer architectures, remains particularly challenging in HE due to its multivariate structure, the large dynamic range induced by exponential functions, and the need for accurate division during normalization. In this paper, we propose MGF-softmax, a novel softmax reformulation based on the moment generating function (MGF) that replaces the softmax denominator with its moment-based counterpart. This reformulation substantially reduces multiplicative depth while preserving key properties of softmax and asymptotically converging to the exact softmax as the number of input tokens increases. Extensive experiments on Vision Transformers and large language models show that MGF-softmax provides an efficient and accurate approximation of softmax in encrypted inference. In particular, it achieves inference accuracy close to that of high-depth exact methods, while requiring substantially lower computational cost through reduced multiplicative depth.",
    "published": "2026-02-02T04:33:12Z",
    "updated": "2026-02-02T04:33:12Z",
    "authors": [
      "Hanjun Park",
      "Byeong-Seo Min",
      "Jiheon Woo",
      "Min-Wook Jeong",
      "Jongho Shin",
      "Yongwoo Lee",
      "Young-Sik Kim",
      "Yongjune Kim"
    ],
    "primary_category": "cs.CR",
    "categories": [
      "cs.CR",
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01621v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01621v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 3.6,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01614v1",
    "title": "AgroFlux: A Spatial-Temporal Benchmark for Carbon and Nitrogen Flux Prediction in Agricultural Ecosystems",
    "summary": "Agroecosystem, which heavily influenced by human actions and accounts for a quarter of global greenhouse gas emissions (GHGs), plays a crucial role in mitigating global climate change and securing environmental sustainability. However, we can't manage what we can't measure. Accurately quantifying the pools and fluxes in the carbon, nutrient, and water nexus of the agroecosystem is therefore essential for understanding the underlying drivers of GHG and developing effective mitigation strategies. Conventional approaches like soil sampling, process-based models, and black-box machine learning models are facing challenges such as data sparsity, high spatiotemporal heterogeneity, and complex subsurface biogeochemical and physical processes. Developing new trustworthy approaches such as AI-empowered models, will require the AI-ready benchmark dataset and outlined protocols, which unfortunately do not exist. In this work, we introduce a first-of-its-kind spatial-temporal agroecosystem GHG benchmark dataset that integrates physics-based model simulations from Ecosys and DayCent with real-world observations from eddy covariance flux towers and controlled-environment facilities. We evaluate the performance of various sequential deep learning models on carbon and nitrogen flux prediction, including LSTM-based models, temporal CNN-based model, and Transformer-based models. Furthermore, we explored transfer learning to leverage simulated data to improve the generalization of deep learning models on real-world observations. Our benchmark dataset and evaluation framework contribute to the development of more accurate and scalable AI-driven agroecosystem models, advancing our understanding of ecosystem-climate interactions.",
    "published": "2026-02-02T04:04:07Z",
    "updated": "2026-02-02T04:04:07Z",
    "authors": [
      "Qi Cheng",
      "Licheng Liu",
      "Yao Zhang",
      "Mu Hong",
      "Yiqun Xie",
      "Xiaowei Jia"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01614v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01614v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 3.6,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01518v1",
    "title": "Qrita: High-performance Top-k and Top-p Algorithm for GPUs using Pivot-based Truncation and Selection",
    "summary": "Top-k and Top-p are the dominant truncation operators in the sampling of large language models. Despite their widespread use, implementing them efficiently over large vocabularies remains a significant challenge. Existing approaches often rely on sorting, which incur significant computation and memory overhead on GPUs, or stochastic approaches, which alter the algorithm output. In this work, we propose Qrita, an efficient Top-k and Top-p algorithm based on a pivot-based selection strategy. Based on RTop-k, which uses a pivot-based search for node selection in graph neural networks, Qrita extends the concept of pivot-based search to both Top-k and Top-p with two key techniques: 1. Gaussian-based sigma-truncation, which greatly reduces the search space of the target elements, and 2. Quaternary pivot search with duplication handling, which halves the pivot search iteration and guarantees deterministic output. We provide the full implementation of Qrita using Triton, a popular GPU programming language. Our evaluation of Qrita against the Top-k and Top-p kernels of high performance LLM execution engines such as vLLM, SGLang, and Flashinfer show that Qrita achieves up to 2 times throughput and half memory use while providing the same output to the the sorting-based algorithms.",
    "published": "2026-02-02T01:19:28Z",
    "updated": "2026-02-02T01:19:28Z",
    "authors": [
      "Jongseok Park",
      "Sunga Kim",
      "Alvin Cheung",
      "Ion Stoica"
    ],
    "primary_category": "cs.AI",
    "categories": [
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01518v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01518v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 3.6,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02495v1",
    "title": "Reward-free Alignment for Conflicting Objectives",
    "summary": "Direct alignment methods are increasingly used to align large language models (LLMs) with human preferences. However, many real-world alignment problems involve multiple conflicting objectives, where naive aggregation of preferences can lead to unstable training and poor trade-offs. In particular, weighted loss methods may fail to identify update directions that simultaneously improve all objectives, and existing multi-objective approaches often rely on explicit reward models, introducing additional complexity and distorting user-specified preferences. The contributions of this paper are two-fold. First, we propose a Reward-free Alignment framework for Conflicted Objectives (RACO) that directly leverages pairwise preference data and resolves gradient conflicts via a novel clipped variant of conflict-averse gradient descent. We provide convergence guarantees to Pareto-critical points that respect user-specified objective weights, and further show that clipping can strictly improve convergence rate in the two-objective setting. Second, we improve our method using some heuristics and conduct experiments to demonstrate the compatibility of the proposed framework for LLM alignment. Both qualitative and quantitative evaluations on multi-objective summarization and safety alignment tasks across multiple LLM families (Qwen 3, Llama 3, Gemma 3) show that our method consistently achieves better Pareto trade-offs compared to existing multi-objective alignment baselines.",
    "published": "2026-02-02T18:59:52Z",
    "updated": "2026-02-02T18:59:52Z",
    "authors": [
      "Peter Chen",
      "Xiaopeng Li",
      "Xi Chen",
      "Tianyi Lin"
    ],
    "primary_category": "cs.CL",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02495v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02495v1",
    "comment": "27 pages",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 2.4,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02493v1",
    "title": "PixelGen: Pixel Diffusion Beats Latent Diffusion with Perceptual Loss",
    "summary": "Pixel diffusion generates images directly in pixel space in an end-to-end manner, avoiding the artifacts and bottlenecks introduced by VAEs in two-stage latent diffusion. However, it is challenging to optimize high-dimensional pixel manifolds that contain many perceptually irrelevant signals, leaving existing pixel diffusion methods lagging behind latent diffusion models. We propose PixelGen, a simple pixel diffusion framework with perceptual supervision. Instead of modeling the full image manifold, PixelGen introduces two complementary perceptual losses to guide diffusion model towards learning a more meaningful perceptual manifold. An LPIPS loss facilitates learning better local patterns, while a DINO-based perceptual loss strengthens global semantics. With perceptual supervision, PixelGen surpasses strong latent diffusion baselines. It achieves an FID of 5.11 on ImageNet-256 without classifier-free guidance using only 80 training epochs, and demonstrates favorable scaling performance on large-scale text-to-image generation with a GenEval score of 0.79. PixelGen requires no VAEs, no latent representations, and no auxiliary stages, providing a simpler yet more powerful generative paradigm. Codes are publicly available at https://github.com/Zehong-Ma/PixelGen.",
    "published": "2026-02-02T18:59:42Z",
    "updated": "2026-02-02T18:59:42Z",
    "authors": [
      "Zehong Ma",
      "Ruihan Xu",
      "Shiliang Zhang"
    ],
    "primary_category": "cs.CV",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02493v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02493v1",
    "comment": "Project Pages: https://zehong-ma.github.io/PixelGen/",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 2.4,
    "matched_areas": [
      "ai",
      "vision"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02465v1",
    "title": "MentisOculi: Revealing the Limits of Reasoning with Mental Imagery",
    "summary": "Frontier models are transitioning from multimodal large language models (MLLMs) that merely ingest visual information to unified multimodal models (UMMs) capable of native interleaved generation. This shift has sparked interest in using intermediate visualizations as a reasoning aid, akin to human mental imagery. Central to this idea is the ability to form, maintain, and manipulate visual representations in a goal-oriented manner. To evaluate and probe this capability, we develop MentisOculi, a procedural, stratified suite of multi-step reasoning problems amenable to visual solution, tuned to challenge frontier models. Evaluating visual strategies ranging from latent tokens to explicit generated imagery, we find they generally fail to improve performance. Analysis of UMMs specifically exposes a critical limitation: While they possess the textual reasoning capacity to solve a task and can sometimes generate correct visuals, they suffer from compounding generation errors and fail to leverage even ground-truth visualizations. Our findings suggest that despite their inherent appeal, visual thoughts do not yet benefit model reasoning. MentisOculi establishes the necessary foundation to analyze and close this gap across diverse model families.",
    "published": "2026-02-02T18:49:06Z",
    "updated": "2026-02-02T18:49:06Z",
    "authors": [
      "Jana Zeller",
      "Thaddus Wiedemer",
      "Fanfei Li",
      "Thomas Klein",
      "Prasanna Mayilvahanan",
      "Matthias Bethge",
      "Felix Wichmann",
      "Ryan Cotterell",
      "Wieland Brendel"
    ],
    "primary_category": "cs.AI",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02465v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02465v1",
    "comment": "9 pages, 8 figures",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 2.4,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02458v1",
    "title": "Conflict-Aware Client Selection for Multi-Server Federated Learning",
    "summary": "Federated learning (FL) has emerged as a promising distributed machine learning (ML) that enables collaborative model training across clients without exposing raw data, thereby preserving user privacy and reducing communication costs. Despite these benefits, traditional single-server FL suffers from high communication latency due to the aggregation of models from a large number of clients. While multi-server FL distributes workloads across edge servers, overlapping client coverage and uncoordinated selection often lead to resource contention, causing bandwidth conflicts and training failures. To address these limitations, we propose a decentralized reinforcement learning with conflict risk prediction, named RL CRP, to optimize client selection in multi-server FL systems. Specifically, each server estimates the likelihood of client selection conflicts using a categorical hidden Markov model based on its sparse historical client selection sequence. Then, a fairness-aware reward mechanism is incorporated to promote long-term client participation for minimizing training latency and resource contention. Extensive experiments demonstrate that the proposed RL-CRP framework effectively reduces inter-server conflicts and significantly improves training efficiency in terms of convergence speed and communication cost.",
    "published": "2026-02-02T18:47:16Z",
    "updated": "2026-02-02T18:47:16Z",
    "authors": [
      "Mingwei Hong",
      "Zheng Lin",
      "Zehang Lin",
      "Lin Li",
      "Miao Yang",
      "Xia Du",
      "Zihan Fang",
      "Zhaolu Kang",
      "Dianxin Luan",
      "Shunzhi Zhu"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "cs.NI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02458v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02458v1",
    "comment": "6 pages, 4 figures",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 2.4,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02414v1",
    "title": "Misconception Diagnosis From Student-Tutor Dialogue: Generate, Retrieve, Rerank",
    "summary": "Timely and accurate identification of student misconceptions is key to improving learning outcomes and pre-empting the compounding of student errors. However, this task is highly dependent on the effort and intuition of the teacher. In this work, we present a novel approach for detecting misconceptions from student-tutor dialogues using large language models (LLMs). First, we use a fine-tuned LLM to generate plausible misconceptions, and then retrieve the most promising candidates among these using embedding similarity with the input dialogue. These candidates are then assessed and re-ranked by another fine-tuned LLM to improve misconception relevance. Empirically, we evaluate our system on real dialogues from an educational tutoring platform. We consider multiple base LLM models including LLaMA, Qwen and Claude on zero-shot and fine-tuned settings. We find that our approach improves predictive performance over baseline models and that fine-tuning improves both generated misconception quality and can outperform larger closed-source models. Finally, we conduct ablation studies to both validate the importance of our generation and reranking steps on misconception generation quality.",
    "published": "2026-02-02T18:14:35Z",
    "updated": "2026-02-02T18:14:35Z",
    "authors": [
      "Joshua Mitton",
      "Prarthana Bhattacharyya",
      "Digory Smith",
      "Thomas Christie",
      "Ralph Abboud",
      "Simon Woodhead"
    ],
    "primary_category": "cs.CL",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02414v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02414v1",
    "comment": "21 pages, 8 figures, 8 tables. Joshua Mitton and Prarthana Bhattacharyya contributed equally to this paper",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 2.4,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02405v1",
    "title": "Didactic to Constructive: Turning Expert Solutions into Learnable Reasoning",
    "summary": "Improving the reasoning capabilities of large language models (LLMs) typically relies either on the model's ability to sample a correct solution to be reinforced or on the existence of a stronger model able to solve the problem. However, many difficult problems remain intractable for even current frontier models, preventing the extraction of valid training signals. A promising alternative is to leverage high-quality expert human solutions, yet naive imitation of this data fails because it is fundamentally out of distribution: expert solutions are typically didactic, containing implicit reasoning gaps intended for human readers rather than computational models. Furthermore, high-quality expert solutions are expensive, necessitating generalizable sample-efficient training methods. We propose Distribution Aligned Imitation Learning (DAIL), a two-step method that bridges the distributional gap by first transforming expert solutions into detailed, in-distribution reasoning traces and then applying a contrastive objective to focus learning on expert insights and methodologies. We find that DAIL can leverage fewer than 1000 high-quality expert solutions to achieve 10-25% pass@k gains on Qwen2.5-Instruct and Qwen3 models, improve reasoning efficiency by 2x to 4x, and enable out-of-domain generalization.",
    "published": "2026-02-02T18:03:43Z",
    "updated": "2026-02-02T18:03:43Z",
    "authors": [
      "Ethan Mendes",
      "Jungsoo Park",
      "Alan Ritter"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02405v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02405v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 2.4,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02393v1",
    "title": "Infinite-World: Scaling Interactive World Models to 1000-Frame Horizons via Pose-Free Hierarchical Memory",
    "summary": "We propose Infinite-World, a robust interactive world model capable of maintaining coherent visual memory over 1000+ frames in complex real-world environments. While existing world models can be efficiently optimized on synthetic data with perfect ground-truth, they lack an effective training paradigm for real-world videos due to noisy pose estimations and the scarcity of viewpoint revisits. To bridge this gap, we first introduce a Hierarchical Pose-free Memory Compressor (HPMC) that recursively distills historical latents into a fixed-budget representation. By jointly optimizing the compressor with the generative backbone, HPMC enables the model to autonomously anchor generations in the distant past with bounded computational cost, eliminating the need for explicit geometric priors. Second, we propose an Uncertainty-aware Action Labeling module that discretizes continuous motion into a tri-state logic. This strategy maximizes the utilization of raw video data while shielding the deterministic action space from being corrupted by noisy trajectories, ensuring robust action-response learning. Furthermore, guided by insights from a pilot toy study, we employ a Revisit-Dense Finetuning Strategy using a compact, 30-minute dataset to efficiently activate the model's long-range loop-closure capabilities. Extensive experiments, including objective metrics and user studies, demonstrate that Infinite-World achieves superior performance in visual quality, action controllability, and spatial consistency.",
    "published": "2026-02-02T17:52:56Z",
    "updated": "2026-02-02T17:52:56Z",
    "authors": [
      "Ruiqi Wu",
      "Xuanhua He",
      "Meng Cheng",
      "Tianyu Yang",
      "Yong Zhang",
      "Zhuoliang Kang",
      "Xunliang Cai",
      "Xiaoming Wei",
      "Chunle Guo",
      "Chongyi Li",
      "Ming-Ming Cheng"
    ],
    "primary_category": "cs.CV",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02393v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02393v1",
    "comment": "14 pages, 8 figures",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 2.4,
    "matched_areas": [
      "vision"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02361v1",
    "title": "SWE-Universe: Scale Real-World Verifiable Environments to Millions",
    "summary": "We propose SWE-Universe, a scalable and efficient framework for automatically constructing real-world software engineering (SWE) verifiable environments from GitHub pull requests (PRs). To overcome the prevalent challenges of automatic building, such as low production yield, weak verifiers, and prohibitive cost, our framework utilizes a building agent powered by an efficient custom-trained model. This agent employs iterative self-verification and in-loop hacking detection to ensure the reliable generation of high-fidelity, verifiable tasks. Using this method, we scale the number of real-world multilingual SWE environments to a million scale (807,693). We demonstrate the profound value of our environments through large-scale agentic mid-training and reinforcement learning. Finally, we applied this technique to Qwen3-Max-Thinking and achieved a score of 75.3% on SWE-Bench Verified. Our work provides both a critical resource and a robust methodology to advance the next generation of coding agents.",
    "published": "2026-02-02T17:20:30Z",
    "updated": "2026-02-02T17:20:30Z",
    "authors": [
      "Mouxiang Chen",
      "Lei Zhang",
      "Yunlong Feng",
      "Xuwu Wang",
      "Wenting Zhao",
      "Ruisheng Cao",
      "Jiaxi Yang",
      "Jiawei Chen",
      "Mingze Li",
      "Zeyao Ma",
      "Hao Ge",
      "Zongmeng Zhang",
      "Zeyu Cui",
      "Dayiheng Liu",
      "Jingren Zhou",
      "Jianling Sun",
      "Junyang Lin",
      "Binyuan Hui"
    ],
    "primary_category": "cs.SE",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02361v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02361v1",
    "comment": "13 pages",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 2.4,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02343v1",
    "title": "Why Steering Works: Toward a Unified View of Language Model Parameter Dynamics",
    "summary": "Methods for controlling large language models (LLMs), including local weight fine-tuning, LoRA-based adaptation, and activation-based interventions, are often studied in isolation, obscuring their connections and making comparison difficult. In this work, we present a unified view that frames these interventions as dynamic weight updates induced by a control signal, placing them within a single conceptual framework. Building on this view, we propose a unified preference-utility analysis that separates control effects into preference, defined as the tendency toward a target concept, and utility, defined as coherent and task-valid generation, and measures both on a shared log-odds scale using polarity-paired contrastive examples. Across methods, we observe a consistent trade-off between preference and utility: stronger control increases preference while predictably reducing utility. We further explain this behavior through an activation manifold perspective, in which control shifts representations along target-concept directions to enhance preference, while utility declines primarily when interventions push representations off the model's valid-generation manifold. Finally, we introduce a new steering approach SPLIT guided by this analysis that improves preference while better preserving utility. Code is available at https://github.com/zjunlp/EasyEdit/blob/main/examples/SPLIT.md.",
    "published": "2026-02-02T17:04:36Z",
    "updated": "2026-02-02T17:04:36Z",
    "authors": [
      "Ziwen Xu",
      "Chenyan Wu",
      "Hengyu Sun",
      "Haiwen Hong",
      "Mengru Wang",
      "Yunzhi Yao",
      "Longtao Huang",
      "Hui Xue",
      "Shumin Deng",
      "Zhixuan Chu",
      "Huajun Chen",
      "Ningyu Zhang"
    ],
    "primary_category": "cs.CL",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.IR",
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02343v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02343v1",
    "comment": "Work in progress",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 2.4,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02320v1",
    "title": "A Large-Scale Dataset for Molecular Structure-Language Description via a Rule-Regularized Method",
    "summary": "Molecular function is largely determined by structure. Accurately aligning molecular structure with natural language is therefore essential for enabling large language models (LLMs) to reason about downstream chemical tasks. However, the substantial cost of human annotation makes it infeasible to construct large-scale, high-quality datasets of structure-grounded descriptions. In this work, we propose a fully automated annotation framework for generating precise molecular structure descriptions at scale. Our approach builds upon and extends a rule-based chemical nomenclature parser to interpret IUPAC names and construct enriched, structured XML metadata that explicitly encodes molecular structure. This metadata is then used to guide LLMs in producing accurate natural-language descriptions. Using this framework, we curate a large-scale dataset of approximately $163$k molecule-description pairs. A rigorous validation protocol combining LLM-based and expert human evaluation on a subset of $2,000$ molecules demonstrates a high description precision of $98.6\\%$. The resulting dataset provides a reliable foundation for future molecule-language alignment, and the proposed annotation method is readily extensible to larger datasets and broader chemical tasks that rely on structural descriptions.",
    "published": "2026-02-02T16:49:19Z",
    "updated": "2026-02-02T16:49:19Z",
    "authors": [
      "Feiyang Cai",
      "Guijuan He",
      "Yi Hu",
      "Jingjing Wang",
      "Joshua Luo",
      "Tianyu Zhu",
      "Srikanth Pilla",
      "Gang Li",
      "Ling Liu",
      "Feng Luo"
    ],
    "primary_category": "cs.CL",
    "categories": [
      "cs.CL",
      "cs.AI",
      "q-bio.BM"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02320v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02320v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 2.4,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02301v1",
    "title": "Advancing General-Purpose Reasoning Models with Modular Gradient Surgery",
    "summary": "Reinforcement learning (RL) has played a central role in recent advances in large reasoning models (LRMs), yielding strong gains in verifiable and open-ended reasoning. However, training a single general-purpose LRM across diverse domains remains challenging due to pronounced domain heterogeneity. Through a systematic study of two widely used strategies, Sequential RL and Mixed RL, we find that both incur substantial cross-domain interference at the behavioral and gradient levels, resulting in limited overall gains. To address these challenges, we introduce **M**odular **G**radient **S**urgery (**MGS**), which resolves gradient conflicts at the module level within the transformer. When applied to Llama and Qwen models, MGS achieves average improvements of 4.3 (16.6\\%) and 4.5 (11.1\\%) points, respectively, over standard multi-task RL across three representative domains (math, general chat, and instruction following). Further analysis demonstrates that MGS remains effective under prolonged training. Overall, our study clarifies the sources of interference in multi-domain RL and presents an effective solution for training general-purpose LRMs.",
    "published": "2026-02-02T16:34:39Z",
    "updated": "2026-02-02T16:34:39Z",
    "authors": [
      "Min Cai",
      "Yu Liang",
      "Longzheng Wang",
      "Yan Wang",
      "Yueyang Zhang",
      "Long Xia",
      "Zhiyuan Sun",
      "Xi Ye",
      "Daiting Shi"
    ],
    "primary_category": "cs.CL",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02301v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02301v1",
    "comment": "Preprint; Code: https://github.com/StringNLPLAB/MGS; Website: https://modular-gradient-surgery.github.io",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 2.4,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02264v1",
    "title": "Unsupervised Physics-Informed Operator Learning through Multi-Stage Curriculum Training",
    "summary": "Solving partial differential equations remains a central challenge in scientific machine learning. Neural operators offer a promising route by learning mappings between function spaces and enabling resolution-independent inference, yet they typically require supervised data. Physics-informed neural networks address this limitation through unsupervised training with physical constraints but often suffer from unstable convergence and limited generalization capability. To overcome these issues, we introduce a multi-stage physics-informed training strategy that achieves convergence by progressively enforcing boundary conditions in the loss landscape and subsequently incorporating interior residuals. At each stage the optimizer is re-initialized, acting as a continuation mechanism that restores stability and prevents gradient stagnation. We further propose the Physics-Informed Spline Fourier Neural Operator (PhIS-FNO), combining Fourier layers with Hermite spline kernels for smooth residual evaluation. Across canonical benchmarks, PhIS-FNO attains a level of accuracy comparable to that of supervised learning, using labeled information only along a narrow boundary region, establishing staged, spline-based optimization as a robust paradigm for physics-informed operator learning.",
    "published": "2026-02-02T16:06:57Z",
    "updated": "2026-02-02T16:06:57Z",
    "authors": [
      "Paolo Marcandelli",
      "Natansh Mathur",
      "Stefano Markidis",
      "Martina Siena",
      "Stefano Mariani"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02264v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02264v1",
    "comment": "51 pages, 15 figures, 6 tables",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 2.4,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02260v1",
    "title": "Learning Markov Decision Processes under Fully Bandit Feedback",
    "summary": "A standard assumption in Reinforcement Learning is that the agent observes every visited state-action pair in the associated Markov Decision Process (MDP), along with the per-step rewards. Strong theoretical results are known in this setting, achieving nearly-tight $(\\sqrt{T})$-regret bounds. However, such detailed feedback can be unrealistic, and recent research has investigated more restricted settings such as trajectory feedback, where the agent observes all the visited state-action pairs, but only a single \\emph{aggregate} reward. In this paper, we consider a far more restrictive ``fully bandit'' feedback model for episodic MDPs, where the agent does not even observe the visited state-action pairs -- it only learns the aggregate reward. We provide the first efficient bandit learning algorithm for episodic MDPs with $\\widetilde{O}(\\sqrt{T})$ regret. Our regret has an exponential dependence on the horizon length $\\H$, which we show is necessary. We also obtain improved nearly-tight regret bounds for ``ordered'' MDPs; these can be used to model classical stochastic optimization problems such as $k$-item prophet inequality and sequential posted pricing. Finally, we evaluate the empirical performance of our algorithm for the setting of $k$-item prophet inequalities; despite the highly restricted feedback, our algorithm's performance is comparable to that of a state-of-art learning algorithm (UCB-VI) with detailed state-action feedback.",
    "published": "2026-02-02T16:03:24Z",
    "updated": "2026-02-02T16:03:24Z",
    "authors": [
      "Zhengjia Zhuo",
      "Anupam Gupta",
      "Viswanath Nagarajan"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02260v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02260v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 2.4,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02229v1",
    "title": "Prediction-Powered Risk Monitoring of Deployed Models for Detecting Harmful Distribution Shifts",
    "summary": "We study the problem of monitoring model performance in dynamic environments where labeled data are limited. To this end, we propose prediction-powered risk monitoring (PPRM), a semi-supervised risk-monitoring approach based on prediction-powered inference (PPI). PPRM constructs anytime-valid lower bounds on the running risk by combining synthetic labels with a small set of true labels. Harmful shifts are detected via a threshold-based comparison with an upper bound on the nominal risk, satisfying assumption-free finite-sample guarantees in the probability of false alarm. We demonstrate the effectiveness of PPRM through extensive experiments on image classification, large language model (LLM), and telecommunications monitoring tasks.",
    "published": "2026-02-02T15:32:14Z",
    "updated": "2026-02-02T15:32:14Z",
    "authors": [
      "Guangyi Zhang",
      "Yunlong Cai",
      "Guanding Yu",
      "Osvaldo Simeone"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "eess.SP"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02229v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02229v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 2.4,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02199v1",
    "title": "More Than a Quick Glance: Overcoming the Greedy Bias in KV-Cache Compression",
    "summary": "While Large Language Models (LLMs) can theoretically support extensive context windows, their actual deployment is constrained by the linear growth of Key-Value (KV) cache memory. Prevailing compression strategies mitigate this through various pruning mechanisms, yet trade-off semantic recall for memory efficiency. In this work, we present LASER-KV (Layer Accumulated Selection with Exact-LSH Recall), a framework designed to test the limits of KV compression under a strict accumulative budgeting policy. We deviate from the standard fixed summary size approach by implementing a block-wise accumulation strategy governed by a protection divisor (n). This allows us to isolate the effects of compression from sliding window artifacts. Our experiments on the Babilong benchmark reveal performance degradation in previous compression methods by 15-30% on various long context tasks. LASER-KV maintains stable performance, achieving superior accuracies by a margin of upto 10% at 128k. These findings challenge the prevailing assumption that attention scores alone are a sufficient proxy for token utility.",
    "published": "2026-02-02T15:05:03Z",
    "updated": "2026-02-02T15:05:03Z",
    "authors": [
      "Aryan Sood",
      "Tanvi Sharma",
      "Vansh Agrawal"
    ],
    "primary_category": "cs.AI",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02199v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02199v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 2.4,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02163v1",
    "title": "Reg4Pru: Regularisation Through Random Token Routing for Token Pruning",
    "summary": "Transformers are widely adopted in modern vision models due to their strong ability to scale with dataset size and generalisability. However, this comes with a major drawback: computation scales quadratically to the total number of tokens. Numerous methods have been proposed to mitigate this. For example, we consider token pruning with reactivating tokens from preserved representations, but the increased computational efficiency of this method results in decreased stability from the preserved representations, leading to poorer dense prediction performance at deeper layers. In this work, we introduce Reg4Pru, a training regularisation technique that mitigates token-pruning performance loss for segmentation. We compare our models on the FIVES blood vessel segmentation dataset and find that Reg4Pru improves average precision by an absolute 46% compared to the same model trained without routing. This increase is observed using a configuration that achieves a 29% relative speedup in wall-clock time compared to the non-pruned baseline. These findings indicate that Reg4Pru is a valuable regulariser for token reduction strategies.",
    "published": "2026-02-02T14:38:19Z",
    "updated": "2026-02-02T14:38:19Z",
    "authors": [
      "Julian Wyatt",
      "Ronald Clark",
      "Irina Voiculescu"
    ],
    "primary_category": "cs.CV",
    "categories": [
      "cs.CV"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02163v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02163v1",
    "comment": "11 pages, 7 figures",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 2.4,
    "matched_areas": [
      "ai",
      "vision"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02143v1",
    "title": "Learning Generative Selection for Best-of-N",
    "summary": "Scaling test-time compute via parallel sampling can substantially improve LLM reasoning, but is often limited by Best-of-N selection quality. Generative selection methods, such as GenSelect, address this bottleneck, yet strong selection performance remains largely limited to large models. We show that small reasoning models can acquire strong GenSelect capabilities through targeted reinforcement learning. To this end, we synthesize selection tasks from large-scale math and code instruction datasets by filtering to instances with both correct and incorrect candidate solutions, and train 1.7B-parameter models with DAPO to reward correct selections. Across math (AIME24, AIME25, HMMT25) and code (LiveCodeBench) reasoning benchmarks, our models consistently outperform prompting and majority-voting baselines, often approaching or exceeding much larger models. Moreover, these gains generalize to selecting outputs from stronger models despite training only on outputs from weaker models. Overall, our results establish reinforcement learning as a scalable way to unlock strong generative selection in small models, enabling efficient test-time scaling.",
    "published": "2026-02-02T14:21:15Z",
    "updated": "2026-02-02T14:21:15Z",
    "authors": [
      "Shubham Toshniwal",
      "Aleksander Ficek",
      "Siddhartha Jain",
      "Wei Du",
      "Vahid Noroozi",
      "Sadegh Mahdavi",
      "Somshubra Majumdar",
      "Igor Gitman"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02143v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02143v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 2.4,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02128v1",
    "title": "Scalable Spatio-Temporal SE(3) Diffusion for Long-Horizon Protein Dynamics",
    "summary": "Molecular dynamics (MD) simulations remain the gold standard for studying protein dynamics, but their computational cost limits access to biologically relevant timescales. Recent generative models have shown promise in accelerating simulations, yet they struggle with long-horizon generation due to architectural constraints, error accumulation, and inadequate modeling of spatio-temporal dynamics. We present STAR-MD (Spatio-Temporal Autoregressive Rollout for Molecular Dynamics), a scalable SE(3)-equivariant diffusion model that generates physically plausible protein trajectories over microsecond timescales. Our key innovation is a causal diffusion transformer with joint spatio-temporal attention that efficiently captures complex space-time dependencies while avoiding the memory bottlenecks of existing methods. On the standard ATLAS benchmark, STAR-MD achieves state-of-the-art performance across all metrics--substantially improving conformational coverage, structural validity, and dynamic fidelity compared to previous methods. STAR-MD successfully extrapolates to generate stable microsecond-scale trajectories where baseline methods fail catastrophically, maintaining high structural quality throughout the extended rollout. Our comprehensive evaluation reveals severe limitations in current models for long-horizon generation, while demonstrating that STAR-MD's joint spatio-temporal modeling enables robust dynamics simulation at biologically relevant timescales, paving the way for accelerated exploration of protein function.",
    "published": "2026-02-02T14:13:28Z",
    "updated": "2026-02-02T14:13:28Z",
    "authors": [
      "Nima Shoghi",
      "Yuxuan Liu",
      "Yuning Shen",
      "Rob Brekelmans",
      "Pan Li",
      "Quanquan Gu"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.bio-ph",
      "q-bio.BM",
      "q-bio.QM"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02128v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02128v1",
    "comment": "For associated project page, see https://bytedance-seed.github.io/ConfRover/starmd",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 2.4,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02124v1",
    "title": "Toxicity Assessment in Preclinical Histopathology via Class-Aware Mahalanobis Distance for Known and Novel Anomalies",
    "summary": "Drug-induced toxicity remains a leading cause of failure in preclinical development and early clinical trials. Detecting adverse effects at an early stage is critical to reduce attrition and accelerate the development of safe medicines. Histopathological evaluation remains the gold standard for toxicity assessment, but it relies heavily on expert pathologists, creating a bottleneck for large-scale screening. To address this challenge, we introduce an AI-based anomaly detection framework for histopathological whole-slide images (WSIs) in rodent livers from toxicology studies. The system identifies healthy tissue and known pathologies (anomalies) for which training data is available. In addition, it can detect rare pathologies without training data as out-of-distribution (OOD) findings. We generate a novel dataset of pixelwise annotations of healthy tissue and known pathologies and use this data to fine-tune a pre-trained Vision Transformer (DINOv2) via Low-Rank Adaptation (LoRA) in order to do tissue segmentation. Finally, we extract features for OOD detection using the Mahalanobis distance. To better account for class-dependent variability in histological data, we propose the use of class-specific thresholds. We optimize the thresholds using the mean of the false negative and false positive rates, resulting in only 0.16\\% of pathological tissue classified as healthy and 0.35\\% of healthy tissue classified as pathological. Applied to mouse liver WSIs with known toxicological findings, the framework accurately detects anomalies, including rare OOD morphologies. This work demonstrates the potential of AI-driven histopathology to support preclinical workflows, reduce late-stage failures, and improve efficiency in drug development.",
    "published": "2026-02-02T14:07:33Z",
    "updated": "2026-02-02T14:07:33Z",
    "authors": [
      "Olga Graf",
      "Dhrupal Patel",
      "Peter Gro",
      "Charlotte Lempp",
      "Matthias Hein",
      "Fabian Heinemann"
    ],
    "primary_category": "cs.CV",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02124v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02124v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 2.4,
    "matched_areas": [
      "ai",
      "vision"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02079v1",
    "title": "AICD Bench: A Challenging Benchmark for AI-Generated Code Detection",
    "summary": "Large language models (LLMs) are increasingly capable of generating functional source code, raising concerns about authorship, accountability, and security. While detecting AI-generated code is critical, existing datasets and benchmarks are narrow, typically limited to binary human-machine classification under in-distribution settings. To bridge this gap, we introduce $\\emph{AICD Bench}$, the most comprehensive benchmark for AI-generated code detection. It spans $\\emph{2M examples}$, $\\emph{77 models}$ across $\\emph{11 families}$, and $\\emph{9 programming languages}$, including recent reasoning models. Beyond scale, AICD Bench introduces three realistic detection tasks: ($\\emph{i}$)~$\\emph{Robust Binary Classification}$ under distribution shifts in language and domain, ($\\emph{ii}$)~$\\emph{Model Family Attribution}$, grouping generators by architectural lineage, and ($\\emph{iii}$)~$\\emph{Fine-Grained Human-Machine Classification}$ across human, machine, hybrid, and adversarial code. Extensive evaluation on neural and classical detectors shows that performance remains far below practical usability, particularly under distribution shift and for hybrid or adversarial code. We release AICD Bench as a $\\emph{unified, challenging evaluation suite}$ to drive the next generation of robust approaches for AI-generated code detection. The data and the code are available at https://huggingface.co/AICD-bench}.",
    "published": "2026-02-02T13:24:14Z",
    "updated": "2026-02-02T13:24:14Z",
    "authors": [
      "Daniil Orel",
      "Dilshod Azizov",
      "Indraneil Paul",
      "Yuxia Wang",
      "Iryna Gurevych",
      "Preslav Nakov"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "cs.SE"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02079v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02079v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 2.4,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02028v1",
    "title": "Edit Knowledge, Not Just Facts via Multi-Step Reasoning over Background Stories",
    "summary": "Enabling artificial intelligence systems, particularly large language models, to integrate new knowledge and flexibly apply it during reasoning remains a central challenge. Existing knowledge editing approaches emphasize atomic facts, improving factual recall but often failing to integrate new information into a coherent framework usable across contexts. In this work, we argue that knowledge internalization is fundamentally a reasoning problem rather than a memorization problem. Consequently, a model should be trained in situations where the new information is instrumental to solving a task, combined with pre-existing knowledge, and exercised through multi-step reasoning. Based on this insight, we propose a training strategy based on three principles. First, new knowledge is introduced as a coherent background story that contextualizes novel facts and explains their relation to existing knowledge. Second, models are trained using self-generated multi-hop questions that require multi-step reasoning involving the new information. Third, training is done using knowledge distillation, forcing a student model to internalize the teacher's reasoning behavior without access to the novel information. Experiments show that models trained with this strategy effectively leverage newly acquired knowledge during reasoning and achieve remarkable performance on challenging questions that require combining multiple new facts.",
    "published": "2026-02-02T12:22:51Z",
    "updated": "2026-02-02T12:22:51Z",
    "authors": [
      "Ya Gao",
      "Kalle Kujanp",
      "Pekka Marttinen",
      "Harri Valpola",
      "Alexander Ilin"
    ],
    "primary_category": "cs.AI",
    "categories": [
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02028v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02028v1",
    "comment": "under review",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 2.4,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02018v1",
    "title": "Do I Really Know? Learning Factual Self-Verification for Hallucination Reduction",
    "summary": "Factual hallucination remains a central challenge for large language models (LLMs). Existing mitigation approaches primarily rely on either external post-hoc verification or mapping uncertainty directly to abstention during fine-tuning, often resulting in overly conservative behavior. We propose VeriFY, a training-time framework that teaches LLMs to reason about factual uncertainty through consistency-based self-verification. VeriFY augments training with structured verification traces that guide the model to produce an initial answer, generate and answer a probing verification query, issue a consistency judgment, and then decide whether to answer or abstain. To address the risk of reinforcing hallucinated content when training on augmented traces, we introduce a stage-level loss masking approach that excludes hallucinated answer stages from the training objective while preserving supervision over verification behavior. Across multiple model families and scales, VeriFY reduces factual hallucination rates by 9.7 to 53.3 percent, with only modest reductions in recall (0.4 to 5.7 percent), and generalizes across datasets when trained on a single source. The source code, training data, and trained model checkpoints will be released upon acceptance.",
    "published": "2026-02-02T12:15:50Z",
    "updated": "2026-02-02T12:15:50Z",
    "authors": [
      "Enes Altinisik",
      "Masoomali Fatehkia",
      "Fatih Deniz",
      "Nadir Durrani",
      "Majd Hawasly",
      "Mohammad Raza",
      "Husrev Taha Sencar"
    ],
    "primary_category": "cs.AI",
    "categories": [
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02018v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02018v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 2.4,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02014v1",
    "title": "Rethinking Genomic Modeling Through Optical Character Recognition",
    "summary": "Recent genomic foundation models largely adopt large language model architectures that treat DNA as a one-dimensional token sequence. However, exhaustive sequential reading is structurally misaligned with sparse and discontinuous genomic semantics, leading to wasted computation on low-information background and preventing understanding-driven compression for long contexts. Here, we present OpticalDNA, a vision-based framework that reframes genomic modeling as Optical Character Recognition (OCR)-style document understanding. OpticalDNA renders DNA into structured visual layouts and trains an OCR-capable vision--language model with a \\emph{visual DNA encoder} and a \\emph{document decoder}, where the encoder produces compact, reconstructible visual tokens for high-fidelity compression. Building on this representation, OpticalDNA defines prompt-conditioned objectives over core genomic primitives-reading, region grounding, subsequence retrieval, and masked span completion-thereby learning layout-aware DNA representations that retain fine-grained genomic information under a reduced effective token budget. Across diverse genomic benchmarks, OpticalDNA consistently outperforms recent baselines; on sequences up to 450k bases, it achieves the best overall performance with nearly $20\\times$ fewer effective tokens, and surpasses models with up to $985\\times$ more activated parameters while tuning only 256k \\emph{trainable} parameters.",
    "published": "2026-02-02T12:12:00Z",
    "updated": "2026-02-02T12:12:00Z",
    "authors": [
      "Hongxin Xiang",
      "Pengsen Ma",
      "Yunkang Cao",
      "Di Yu",
      "Haowen Chen",
      "Xinyu Yang",
      "Xiangxiang Zeng"
    ],
    "primary_category": "cs.CV",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02014v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02014v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 2.4,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02006v1",
    "title": "Reformulating AI-based Multi-Object Relative State Estimation for Aleatoric Uncertainty-based Outlier Rejection of Partial Measurements",
    "summary": "Precise localization with respect to a set of objects of interest enables mobile robots to perform various tasks. With the rise of edge devices capable of deploying deep neural networks (DNNs) for real-time inference, it stands to reason to use artificial intelligence (AI) for the extraction of object-specific, semantic information from raw image data, such as the object class and the relative six degrees of freedom (6-DoF) pose. However, fusing such AI-based measurements in an Extended Kalman Filter (EKF) requires quantifying the DNNs' uncertainty and outlier rejection capabilities. This paper presents the benefits of reformulating the measurement equation in AI-based, object-relative state estimation. By deriving an EKF using the direct object-relative pose measurement, we can decouple the position and rotation measurements, thus limiting the influence of erroneous rotation measurements and allowing partial measurement rejection. Furthermore, we investigate the performance and consistency improvements for state estimators provided by replacing the fixed measurement covariance matrix of the 6-DoF object-relative pose measurements with the predicted aleatoric uncertainty of the DNN.",
    "published": "2026-02-02T12:04:34Z",
    "updated": "2026-02-02T12:04:34Z",
    "authors": [
      "Thomas Jantos",
      "Giulio Delama",
      "Stephan Weiss",
      "Jan Steinbrener"
    ],
    "primary_category": "cs.RO",
    "categories": [
      "cs.RO"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02006v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02006v1",
    "comment": "Accepted for publication at ICRA 2026, Vienna, Austria",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 2.4,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01990v1",
    "title": "SAME: Stabilized Mixture-of-Experts for Multimodal Continual Instruction Tuning",
    "summary": "Multimodal Large Language Models (MLLMs) achieve strong performance through instruction tuning, but real-world deployment requires them to continually expand their capabilities, making Multimodal Continual Instruction Tuning (MCIT) essential. Recent methods leverage sparse expert routing to promote task specialization, but we find that the expert routing process suffers from drift as the data distribution evolves. For example, a grounding query that previously activated localization experts may instead be routed to irrelevant experts after learning OCR tasks. Meanwhile, the grounding-related experts can be overwritten by new tasks and lose their original functionality. Such failure reflects two problems: router drift, where expert selection becomes inconsistent over time, and expert drift, where shared experts are overwritten across tasks. Therefore, we propose StAbilized Mixture-of-Experts (SAME) for MCIT. To address router drift, SAME stabilizes expert selection by decomposing routing dynamics into orthogonal subspaces and updating only task-relevant directions. To mitigate expert drift, we regulate expert updates via curvature-aware scaling using historical input covariance in a rehearsal-free manner. SAME also introduces adaptive expert activation to freeze selected experts during training, reducing redundant computation and cross-task interference. Extensive experiments demonstrate its SOTA performance.",
    "published": "2026-02-02T11:47:06Z",
    "updated": "2026-02-02T11:47:06Z",
    "authors": [
      "Zhen-Hao Xie",
      "Jun-Tao Tang",
      "Yu-Cheng Shi",
      "Han-Jia Ye",
      "De-Chuan Zhan",
      "Da-Wei Zhou"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01990v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01990v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 2.4,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01970v1",
    "title": "Small Generalizable Prompt Predictive Models Can Steer Efficient RL Post-Training of Large Reasoning Models",
    "summary": "Reinforcement learning enhances the reasoning capabilities of large language models but often involves high computational costs due to rollout-intensive optimization. Online prompt selection presents a plausible solution by prioritizing informative prompts to improve training efficiency. However, current methods either depend on costly, exact evaluations or construct prompt-specific predictive models lacking generalization across prompts. This study introduces Generalizable Predictive Prompt Selection (GPS), which performs Bayesian inference towards prompt difficulty using a lightweight generative model trained on the shared optimization history. Intermediate-difficulty prioritization and history-anchored diversity are incorporated into the batch acquisition principle to select informative prompt batches. The small predictive model also generalizes at test-time for efficient computational allocation. Experiments across varied reasoning benchmarks indicate GPS's substantial improvements in training efficiency, final performance, and test-time efficiency over superior baseline methods.",
    "published": "2026-02-02T11:24:36Z",
    "updated": "2026-02-02T11:24:36Z",
    "authors": [
      "Yun Qu",
      "Qi Wang",
      "Yixiu Mao",
      "Heming Zou",
      "Yuhang Jiang",
      "Weijie Liu",
      "Clive Bai",
      "Kai Yang",
      "Yangkun Chen",
      "Saiyong Yang",
      "Xiangyang Ji"
    ],
    "primary_category": "cs.AI",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01970v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01970v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 2.4,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01962v1",
    "title": "Zero-Shot Off-Policy Learning",
    "summary": "Off-policy learning methods seek to derive an optimal policy directly from a fixed dataset of prior interactions. This objective presents significant challenges, primarily due to the inherent distributional shift and value function overestimation bias. These issues become even more noticeable in zero-shot reinforcement learning, where an agent trained on reward-free data must adapt to new tasks at test time without additional training. In this work, we address the off-policy problem in a zero-shot setting by discovering a theoretical connection of successor measures to stationary density ratios. Using this insight, our algorithm can infer optimal importance sampling ratios, effectively performing a stationary distribution correction with an optimal policy for any task on the fly. We benchmark our method in motion tracking tasks on SMPL Humanoid, continuous control on ExoRL, and for the long-horizon OGBench tasks. Our technique seamlessly integrates into forward-backward representation frameworks and enables fast-adaptation to new tasks in a training-free regime. More broadly, this work bridges off-policy learning and zero-shot adaptation, offering benefits to both research areas.",
    "published": "2026-02-02T11:06:31Z",
    "updated": "2026-02-02T11:06:31Z",
    "authors": [
      "Arip Asadulaev",
      "Maksim Bobrin",
      "Salem Lahlou",
      "Dmitry Dylov",
      "Fakhri Karray",
      "Martin Takac"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01962v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01962v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 2.4,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01953v1",
    "title": "Deep Multivariate Models with Parametric Conditionals",
    "summary": "We consider deep multivariate models for heterogeneous collections of random variables. In the context of computer vision, such collections may e.g. consist of images, segmentations, image attributes, and latent variables. When developing such models, most existing works start from an application task and design the model components and their dependencies to meet the needs of the chosen task. This has the disadvantage of limiting the applicability of the resulting model for other downstream tasks. Here, instead, we propose to represent the joint probability distribution by means of conditional probability distributions for each group of variables conditioned on the rest. Such models can then be used for practically any possible downstream task. Their learning can be approached as training a parametrised Markov chain kernel by maximising the data likelihood of its limiting distribution. This has the additional advantage of allowing a wide range of semi-supervised learning scenarios.",
    "published": "2026-02-02T11:01:48Z",
    "updated": "2026-02-02T11:01:48Z",
    "authors": [
      "Dmitrij Schlesinger",
      "Boris Flach",
      "Alexander Shekhovtsov"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01953v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01953v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 2.4,
    "matched_areas": [
      "vision"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01909v1",
    "title": "Propagating the prior from far to near offset: A self-supervised diffusion framework for progressively recovering near-offsets of towed-streamer data",
    "summary": "In marine towed-streamer seismic acquisition, the nearest hydrophone is often two hundred meter away from the source resulting in missing near-offset traces, which degrades critical processing workflows such as surface-related multiple elimination, velocity analysis, and full-waveform inversion. Existing reconstruction methods, like transform-domain interpolation, often produce kinematic inconsistencies and amplitude distortions, while supervised deep learning approaches require complete ground-truth near-offset data that are unavailable in realistic acquisition scenarios. To address these limitations, we propose a self-supervised diffusion-based framework that reconstructs missing near-offset traces without requiring near-offset reference data. Our method leverages overlapping patch extraction with single-trace shifts from the available far-offset section to train a conditional diffusion model, which learns offset-dependent statistical patterns governing event curvature, amplitude variation, and wavelet characteristics. At inference, we perform trace-by-trace recursive extrapolation from the nearest recorded offset toward zero offset, progressively propagating learned prior information from far to near offsets. The generative formulation further provides uncertainty estimates via ensemble sampling, quantifying prediction confidence where validation data are absent. Controlled validation experiments on synthetic and field datasets show substantial performance gains over conventional parabolic Radon transform baselines. Operational deployment on actual near-offset gaps demonstrates practical viability where ground-truth validation is impossible. Notably, the reconstructed waveforms preserve realistic amplitude-versus-offset trends despite training exclusively on far-offset observations, and uncertainty maps accurately identify challenging extrapolation regions.",
    "published": "2026-02-02T10:13:18Z",
    "updated": "2026-02-02T10:13:18Z",
    "authors": [
      "Shijun Cheng",
      "Tariq Alkhalifah"
    ],
    "primary_category": "physics.geo-ph",
    "categories": [
      "physics.geo-ph",
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01909v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01909v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 2.4,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01893v1",
    "title": "Geometric Analysis of Token Selection in Multi-Head Attention",
    "summary": "We present a geometric framework for analysing multi-head attention in large language models (LLMs). Without altering the mechanism, we view standard attention through a top-N selection lens and study its behaviour directly in value-state space. We define geometric metrics - Precision, Recall, and F-score - to quantify separability between selected and non-selected tokens, and derive non-asymptotic bounds with explicit dependence on dimension and margin under empirically motivated assumptions (stable value norms with a compressed sink token, exponential similarity decay, and piecewise attention weight profiles). The theory predicts a small-N operating regime of strongest non-trivial separability and clarifies how sequence length and sink similarity shape the metrics. Empirically, across LLaMA-2-7B, Gemma-7B, and Mistral-7B, measurements closely track the theoretical envelopes: top-N selection sharpens separability, sink similarity correlates with Recall. We also found that in LLaMA-2-7B heads specialize into three regimes - Retriever, Mixer, Reset - with distinct geometric signatures. Overall, attention behaves as a structured geometric classifier with measurable criteria for token selection, offering head level interpretability and informing geometry-aware sparsification and design of attention in LLMs.",
    "published": "2026-02-02T10:04:40Z",
    "updated": "2026-02-02T10:04:40Z",
    "authors": [
      "Timur Mudarisov",
      "Mikhal Burtsev",
      "Tatiana Petrova",
      "Radu State"
    ],
    "primary_category": "cs.AI",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01893v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01893v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 2.4,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01854v1",
    "title": "Fact or Fake? Assessing the Role of Deepfake Detectors in Multimodal Misinformation Detection",
    "summary": "In multimodal misinformation, deception usually arises not just from pixel-level manipulations in an image, but from the semantic and contextual claim jointly expressed by the image-text pair. Yet most deepfake detectors, engineered to detect pixel-level forgeries, do not account for claim-level meaning, despite their growing integration in automated fact-checking (AFC) pipelines. This raises a central scientific and practical question: Do pixel-level detectors contribute useful signal for verifying image-text claims, or do they instead introduce misleading authenticity priors that undermine evidence-based reasoning? We provide the first systematic analysis of deepfake detectors in the context of multimodal misinformation detection. Using two complementary benchmarks, MMFakeBench and DGM4, we evaluate: (1) state-of-the-art image-only deepfake detectors, (2) an evidence-driven fact-checking system that performs tool-guided retrieval via Monte Carlo Tree Search (MCTS) and engages in deliberative inference through Multi-Agent Debate (MAD), and (3) a hybrid fact-checking system that injects detector outputs as auxiliary evidence. Results across both benchmark datasets show that deepfake detectors offer limited standalone value, achieving F1 scores in the range of 0.26-0.53 on MMFakeBench and 0.33-0.49 on DGM4, and that incorporating their predictions into fact-checking pipelines consistently reduces performance by 0.04-0.08 F1 due to non-causal authenticity assumptions. In contrast, the evidence-centric fact-checking system achieves the highest performance, reaching F1 scores of approximately 0.81 on MMFakeBench and 0.55 on DGM4. Overall, our findings demonstrate that multimodal claim verification is driven primarily by semantic understanding and external evidence, and that pixel-level artifact signals do not reliably enhance reasoning over real-world image-text misinformation.",
    "published": "2026-02-02T09:28:16Z",
    "updated": "2026-02-02T09:28:16Z",
    "authors": [
      "A S M Sharifuzzaman Sagar",
      "Mohammed Bennamoun",
      "Farid Boussaid",
      "Naeha Sharif",
      "Lian Xu",
      "Shaaban Sahmoud",
      "Ali Kishk"
    ],
    "primary_category": "cs.CV",
    "categories": [
      "cs.CV"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01854v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01854v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 2.4,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01826v1",
    "title": "Beyond Precision: Training-Inference Mismatch is an Optimization Problem and Simple LR Scheduling Fixes It",
    "summary": "Reinforcement Learning (RL) for training Large Language Models is notoriously unstable. While recent studies attribute this to \"training inference mismatch stemming\" from inconsistent hybrid engines, standard remedies, such as Importance Sampling, might fail during extended training runs. In this work, we analyze this instability through the lens of optimization, demonstrating that gradient noise and training-inference mismatch escalate in tandem as training progresses. Meanwhile, we find that the mismatch can be effectively suppressed by shrinking the update size. Taken together, we deduce that the mismatch is not merely a static numerical discrepancy, but a dynamic failure coupled with the model's optimization. Based on this insight, we propose a simple yet effective solution: a specialized Learning Rate (LR) scheduler. Instead of pre-defined decay schedule in traditional LR scheduler, our method dynamically triggers LR decay based on response length, which we identify as a reliable early-warning signal for impending instability. Empirical evidence suggests that by reducing the learning rate as gradient noise rises, we can consistently stabilize RL training and keep the training-inference mismatch at a safe level.",
    "published": "2026-02-02T09:00:53Z",
    "updated": "2026-02-02T09:00:53Z",
    "authors": [
      "Yaxiang Zhang",
      "Yingru Li",
      "Jiacai Liu",
      "Jiawei Xu",
      "Ziniu Li",
      "Qian Liu",
      "Haoyuan Li"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01826v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01826v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 2.4,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01795v1",
    "title": "RedVisor: Reasoning-Aware Prompt Injection Defense via Zero-Copy KV Cache Reuse",
    "summary": "Large Language Models (LLMs) are increasingly vulnerable to Prompt Injection (PI) attacks, where adversarial instructions hidden within retrieved contexts hijack the model's execution flow. Current defenses typically face a critical trade-off: prevention-based fine-tuning often degrades general utility via the \"alignment tax\", while detection-based filtering incurs prohibitive latency and memory costs. To bridge this gap, we propose RedVisor, a unified framework that synthesizes the explainability of detection systems with the seamless integration of prevention strategies. To the best of our knowledge, RedVisor is the first approach to leverage fine-grained reasoning paths to simultaneously detect attacks and guide the model's safe response. We implement this via a lightweight, removable adapter positioned atop the frozen backbone. This adapter serves a dual function: it first generates an explainable analysis that precisely localizes the injection and articulates the threat, which then explicitly conditions the model to reject the malicious command. Uniquely, the adapter is active only during this reasoning phase and is effectively muted during the subsequent response generation. This architecture yields two distinct advantages: (1) it mathematically preserves the backbone's original utility on benign inputs; and (2) it enables a novel KV Cache Reuse strategy, eliminating the redundant prefill computation inherent to decoupled pipelines. We further pioneer the integration of this defense into the vLLM serving engine with custom kernels. Experiments demonstrate that RedVisor outperforms state-of-the-art defenses in detection accuracy and throughput while incurring negligible utility loss.",
    "published": "2026-02-02T08:26:51Z",
    "updated": "2026-02-02T08:26:51Z",
    "authors": [
      "Mingrui Liu",
      "Sixiao Zhang",
      "Cheng Long",
      "Kwok-Yan Lam"
    ],
    "primary_category": "cs.CR",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01795v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01795v1",
    "comment": "under review",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 2.4,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01769v1",
    "title": "IRIS: Implicit Reward-Guided Internal Sifting for Mitigating Multimodal Hallucination",
    "summary": "Hallucination remains a fundamental challenge for Multimodal Large Language Models (MLLMs). While Direct Preference Optimization (DPO) is a key alignment framework, existing approaches often rely heavily on costly external evaluators for scoring or rewriting, incurring off-policy learnability gaps and discretization loss. Due to the lack of access to internal states, such feedback overlooks the fine-grained conflicts between different modalities that lead to hallucinations during generation. To address this issue, we propose IRIS (Implicit Reward-Guided Internal Sifting), which leverages continuous implicit rewards in the native log-probability space to preserve full information density and capture internal modal competition. This on-policy paradigm eliminates learnability gaps by utilizing self-generated preference pairs. By sifting these pairs based on multimodal implicit rewards, IRIS ensures that optimization is driven by signals that directly resolve modal conflicts. Extensive experiments demonstrate that IRIS achieves highly competitive performance on key hallucination benchmarks using only 5.7k samples, without requiring any external feedback during preference alignment. These results confirm that IRIS provides an efficient and principled paradigm for mitigating MLLM hallucinations.",
    "published": "2026-02-02T07:51:57Z",
    "updated": "2026-02-02T07:51:57Z",
    "authors": [
      "Yuanshuai Li",
      "Yuping Yan",
      "Jirui Han",
      "Fei Ming",
      "Lingjuan Lv",
      "Yaochu Jin"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01769v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01769v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 2.4,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01763v1",
    "title": "A Provable Expressiveness Hierarchy in Hybrid Linear-Full Attention",
    "summary": "Transformers serve as the foundation of most modern large language models. To mitigate the quadratic complexity of standard full attention, various efficient attention mechanisms, such as linear and hybrid attention, have been developed. A fundamental gap remains: their expressive power relative to full attention lacks a rigorous theoretical characterization. In this work, we theoretically characterize the performance differences among these attention mechanisms. Our theory applies to all linear attention variants that can be formulated as a recurrence, including Mamba, DeltaNet, etc. Specifically, we establish an expressiveness hierarchy: for the sequential function composition-a multi-step reasoning task that must occur within a model's forward pass, an ($L+1$)-layer full attention network is sufficient, whereas any hybrid network interleaving $L-1$ layers of full attention with a substantially larger number ($2^{3L^2}$) of linear attention layers cannot solve it. This result demonstrates a clear separation in expressive power between the two types of attention. Our work provides the first provable separation between hybrid attention and standard full attention, offering a theoretical perspective for understanding the fundamental capabilities and limitations of different attention mechanisms.",
    "published": "2026-02-02T07:47:21Z",
    "updated": "2026-02-02T07:47:21Z",
    "authors": [
      "Xiaowei Ye",
      "Xiaoyu He",
      "Chao Liao",
      "Chen Wu",
      "Pinyan Lu"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CC"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01763v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01763v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 2.4,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01762v1",
    "title": "PRISM: Parametrically Refactoring Inference for Speculative Sampling Draft Models",
    "summary": "Large Language Models (LLMs), constrained by their auto-regressive nature, suffer from slow decoding. Speculative decoding methods have emerged as a promising solution to accelerate LLM decoding, attracting attention from both systems and AI research communities. Recently, the pursuit of better draft quality has driven a trend toward parametrically larger draft models, which inevitably introduces substantial computational overhead. While existing work attempts to balance the trade-off between prediction accuracy and compute latency, we address this fundamental dilemma through architectural innovation. We propose PRISM, which disaggregates the computation of each predictive step across different parameter sets, refactoring the computational pathways of draft models to successfully decouple model capacity from inference cost. Through extensive experiments, we demonstrate that PRISM outperforms all existing draft architectures, achieving exceptional acceptance lengths while maintaining minimal draft latency for superior end-to-end speedup. We also re-examine scaling laws with PRISM, revealing that PRISM scales more effectively with expanding data volumes than other draft architectures. Through rigorous and fair comparison, we show that PRISM boosts the decoding throughput of an already highly optimized inference engine by more than 2.6x.",
    "published": "2026-02-02T07:46:03Z",
    "updated": "2026-02-02T07:46:03Z",
    "authors": [
      "Xuliang Wang",
      "Yuetao Chen",
      "Maochan Zhen",
      "Fang Liu",
      "Xinzhou Zheng",
      "Xingwu Liu",
      "Hong Xu",
      "Ming Li"
    ],
    "primary_category": "cs.AI",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01762v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01762v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 2.4,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01736v1",
    "title": "Position: The Inevitable End of One-Architecture-Fits-All-Domains in Time Series Forecasting",
    "summary": "Recent work has questioned the effectiveness and robustness of neural network architectures for time series forecasting tasks. We summarize these concerns and analyze groundly their inherent limitations: i.e. the irreconcilable conflict between single (or few similar) domains SOTA and generalizability over general domains for time series forecasting neural network architecture designs. Moreover, neural networks architectures for general domain time series forecasting are becoming more and more complicated and their performance has almost saturated in recent years. As a result, network architectures developed aiming at fitting general time series domains are almost not inspiring for real world practices for certain single (or few similar) domains such as Finance, Weather, Traffic, etc: each specific domain develops their own methods that rarely utilize advances in neural network architectures of time series community in recent 2-3 years. As a result, we call for the time series community to shift focus away from research on time series neural network architectures for general domains: these researches have become saturated and away from domain-specific SOTAs over time. We should either (1) focus on deep learning methods for certain specific domain(s), or (2) turn to the development of meta-learning methods for general domains.",
    "published": "2026-02-02T07:19:16Z",
    "updated": "2026-02-02T07:19:16Z",
    "authors": [
      "Qinwei Ma",
      "Jingzhe Shi",
      "Jiahao Qiu",
      "Zaiwen Yang"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01736v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01736v1",
    "comment": "14 pages, 3 figures, 2 tables",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 2.4,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01723v1",
    "title": "FastPhysGS: Accelerating Physics-based Dynamic 3DGS Simulation via Interior Completion and Adaptive Optimization",
    "summary": "Extending 3D Gaussian Splatting (3DGS) to 4D physical simulation remains challenging. Based on the Material Point Method (MPM), existing methods either rely on manual parameter tuning or distill dynamics from video diffusion models, limiting the generalization and optimization efficiency. Recent attempts using LLMs/VLMs suffer from a text/image-to-3D perceptual gap, yielding unstable physics behavior. In addition, they often ignore the surface structure of 3DGS, leading to implausible motion. We propose FastPhysGS, a fast and robust framework for physics-based dynamic 3DGS simulation:(1) Instance-aware Particle Filling (IPF) with Monte Carlo Importance Sampling (MCIS) to efficiently populate interior particles while preserving geometric fidelity; (2) Bidirectional Graph Decoupling Optimization (BGDO), an adaptive strategy that rapidly optimizes material parameters predicted from a VLM. Experiments show FastPhysGS achieves high-fidelity physical simulation in 1 minute using only 7 GB runtime memory, outperforming prior works with broad potential applications.",
    "published": "2026-02-02T07:00:42Z",
    "updated": "2026-02-02T07:00:42Z",
    "authors": [
      "Yikun Ma",
      "Yiqing Li",
      "Jingwen Ye",
      "Zhongkai Wu",
      "Weidong Zhang",
      "Lin Gao",
      "Zhi Jin"
    ],
    "primary_category": "cs.CV",
    "categories": [
      "cs.CV"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01723v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01723v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 2.4,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01699v1",
    "title": "Mitigating loss of control in advanced AI systems through instrumental goal trajectories",
    "summary": "Researchers at artificial intelligence labs and universities are concerned that highly capable artificial intelligence (AI) systems may erode human control by pursuing instrumental goals. Existing mitigations remain largely technical and system-centric: tracking capability in advanced systems, shaping behaviour through methods such as reinforcement learning from human feedback, and designing systems to be corrigible and interruptible. Here we develop instrumental goal trajectories to expand these options beyond the model. Gaining capability typically depends on access to additional technical resources, such as compute, storage, data and adjacent services, which in turn requires access to monetary resources. In organisations, these resources can be obtained through three organisational pathways. We label these pathways the procurement, governance and finance instrumental goal trajectories (IGTs). Each IGT produces a trail of organisational artefacts that can be monitored and used as intervention points when a systems capabilities or behaviour exceed acceptable thresholds. In this way, IGTs offer concrete avenues for defining capability levels and for broadening how corrigibility and interruptibility are implemented, shifting attention from model properties alone to the organisational systems that enable them.",
    "published": "2026-02-02T06:13:21Z",
    "updated": "2026-02-02T06:13:21Z",
    "authors": [
      "Willem Fourie"
    ],
    "primary_category": "cs.AI",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01699v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01699v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 2.4,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01687v1",
    "title": "Counting Hypothesis: Potential Mechanism of In-Context Learning",
    "summary": "In-Context Learning (ICL) indicates that large language models (LLMs) pretrained on a massive amount of data can learn specific tasks from input prompts' examples. ICL is notable for two reasons. First, it does not need modification of LLMs' internal structure. Second, it enables LLMs to perform a wide range of tasks/functions with a few examples demonstrating a desirable task. ICL opens up new ways to utilize LLMs in more domains, but its underlying mechanisms still remain poorly understood, making error correction and diagnosis extremely challenging. Thus, it is imperative that we better understand the limitations of ICL and how exactly LLMs support ICL. Inspired by ICL properties and LLMs' functional modules, we propose 1the counting hypothesis' of ICL, which suggests that LLMs' encoding strategy may underlie ICL, and provide supporting evidence.",
    "published": "2026-02-02T05:57:33Z",
    "updated": "2026-02-02T05:57:33Z",
    "authors": [
      "Jung H. Lee",
      "Sujith Vijayan"
    ],
    "primary_category": "cs.CL",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01687v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01687v1",
    "comment": "19 pages, 7 main Figures, 1 Table and 6 Supp. Figures",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 2.4,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01683v1",
    "title": "FreshMem: Brain-Inspired Frequency-Space Hybrid Memory for Streaming Video Understanding",
    "summary": "Transitioning Multimodal Large Language Models (MLLMs) from offline to online streaming video understanding is essential for continuous perception. However, existing methods lack flexible adaptivity, leading to irreversible detail loss and context fragmentation. To resolve this, we propose FreshMem, a Frequency-Space Hybrid Memory network inspired by the brain's logarithmic perception and memory consolidation. FreshMem reconciles short-term fidelity with long-term coherence through two synergistic modules: Multi-scale Frequency Memory (MFM), which projects overflowing frames into representative frequency coefficients, complemented by residual details to reconstruct a global historical \"gist\"; and Space Thumbnail Memory (STM), which discretizes the continuous stream into episodic clusters by employing an adaptive compression strategy to distill them into high-density space thumbnails. Extensive experiments show that FreshMem significantly boosts the Qwen2-VL baseline, yielding gains of 5.20%, 4.52%, and 2.34% on StreamingBench, OV-Bench, and OVO-Bench, respectively. As a training-free solution, FreshMem outperforms several fully fine-tuned methods, offering a highly efficient paradigm for long-horizon streaming video understanding.",
    "published": "2026-02-02T05:52:11Z",
    "updated": "2026-02-02T05:52:11Z",
    "authors": [
      "Kangcong Li",
      "Peng Ye",
      "Lin Zhang",
      "Chao Wang",
      "Huafeng Qin",
      "Tao Chen"
    ],
    "primary_category": "cs.CV",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01683v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01683v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 2.4,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01681v1",
    "title": "Hyperspectral Image Fusion with Spectral-Band and Fusion-Scale Agnosticism",
    "summary": "Current deep learning models for Multispectral and Hyperspectral Image Fusion (MS/HS fusion) are typically designed for fixed spectral bands and spatial scales, which limits their transferability across diverse sensors. To address this, we propose SSA, a universal framework for MS/HS fusion with spectral-band and fusion-scale agnosticism. Specifically, we introduce Matryoshka Kernel (MK), a novel operator that enables a single model to adapt to arbitrary numbers of spectral channels. Meanwhile, we build SSA upon an Implicit Neural Representation (INR) backbone that models the HS signal as a continuous function, enabling reconstruction at arbitrary spatial resolutions. Together, these two forms of agnosticism enable a single MS/HS fusion model that generalizes effectively to unseen sensors and spatial scales. Extensive experiments demonstrate that our single model achieves state-of-the-art performance while generalizing well to unseen sensors and scales, paving the way toward future HS foundation models.",
    "published": "2026-02-02T05:48:53Z",
    "updated": "2026-02-02T05:48:53Z",
    "authors": [
      "Yu-Jie Liang",
      "Zihan Cao",
      "Liang-Jian Deng",
      "Yang Yang",
      "Malu Zhang"
    ],
    "primary_category": "eess.IV",
    "categories": [
      "eess.IV",
      "cs.CV",
      "cs.MM"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01681v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01681v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 2.4,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01673v1",
    "title": "Real-Time Loop Closure Detection in Visual SLAM via NetVLAD and Faiss",
    "summary": "Loop closure detection (LCD) is a core component of simultaneous localization and mapping (SLAM): it identifies revisited places and enables pose-graph constraints that correct accumulated drift. Classic bag-of-words approaches such as DBoW are efficient but often degrade under appearance change and perceptual aliasing. In parallel, deep learning-based visual place recognition (VPR) descriptors (e.g., NetVLAD and Transformer-based models) offer stronger robustness, but their computational cost is often viewed as a barrier to real-time SLAM. In this paper, we empirically evaluate NetVLAD as an LCD module and compare it against DBoW on the KITTI dataset. We introduce a Fine-Grained Top-K precision-recall curve that better reflects LCD settings where a query may have zero or multiple valid matches. With Faiss-accelerated nearestneighbor search, NetVLAD achieves real-time query speed while improving accuracy and robustness over DBoW, making it a practical drop-in alternative for LCD in SLAM.",
    "published": "2026-02-02T05:41:42Z",
    "updated": "2026-02-02T05:41:42Z",
    "authors": [
      "Enguang Fan"
    ],
    "primary_category": "cs.CV",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01673v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01673v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 2.4,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01629v1",
    "title": "AdaptNC: Adaptive Nonconformity Scores for Uncertainty-Aware Autonomous Systems in Dynamic Environments",
    "summary": "Rigorous uncertainty quantification is essential for the safe deployment of autonomous systems in unconstrained environments. Conformal Prediction (CP) provides a distribution-free framework for this task, yet its standard formulations rely on exchangeability assumptions that are violated by the distribution shifts inherent in real-world robotics. Existing online CP methods maintain target coverage by adaptively scaling the conformal threshold, but typically employ a static nonconformity score function. We show that this fixed geometry leads to highly conservative, volume-inefficient prediction regions when environments undergo structural shifts. To address this, we propose \\textbf{AdaptNC}, a framework for the joint online adaptation of both the nonconformity score parameters and the conformal threshold. AdaptNC leverages an adaptive reweighting scheme to optimize score functions, and introduces a replay buffer mechanism to mitigate the coverage instability that occurs during score transitions. We evaluate AdaptNC on diverse robotic benchmarks involving multi-agent policy changes, environmental changes and sensor degradation. Our results demonstrate that AdaptNC significantly reduces prediction region volume compared to state-of-the-art threshold-only baselines while maintaining target coverage levels.",
    "published": "2026-02-02T04:41:35Z",
    "updated": "2026-02-02T04:41:35Z",
    "authors": [
      "Renukanandan Tumu",
      "Aditya Singh",
      "Rahul Mangharam"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "cs.RO",
      "eess.SY"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01629v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01629v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 2.4,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01624v1",
    "title": "PISCES: Annotation-free Text-to-Video Post-Training via Optimal Transport-Aligned Rewards",
    "summary": "Text-to-video (T2V) generation aims to synthesize videos with high visual quality and temporal consistency that are semantically aligned with input text. Reward-based post-training has emerged as a promising direction to improve the quality and semantic alignment of generated videos. However, recent methods either rely on large-scale human preference annotations or operate on misaligned embeddings from pre-trained vision-language models, leading to limited scalability or suboptimal supervision. We present $\\texttt{PISCES}$, an annotation-free post-training algorithm that addresses these limitations via a novel Dual Optimal Transport (OT)-aligned Rewards module. To align reward signals with human judgment, $\\texttt{PISCES}$ uses OT to bridge text and video embeddings at both distributional and discrete token levels, enabling reward supervision to fulfill two objectives: (i) a Distributional OT-aligned Quality Reward that captures overall visual quality and temporal coherence; and (ii) a Discrete Token-level OT-aligned Semantic Reward that enforces semantic, spatio-temporal correspondence between text and video tokens. To our knowledge, $\\texttt{PISCES}$ is the first to improve annotation-free reward supervision in generative post-training through the lens of OT. Experiments on both short- and long-video generation show that $\\texttt{PISCES}$ outperforms both annotation-based and annotation-free methods on VBench across Quality and Semantic scores, with human preference studies further validating its effectiveness. We show that the Dual OT-aligned Rewards module is compatible with multiple optimization paradigms, including direct backpropagation and reinforcement learning fine-tuning.",
    "published": "2026-02-02T04:37:11Z",
    "updated": "2026-02-02T04:37:11Z",
    "authors": [
      "Minh-Quan Le",
      "Gaurav Mittal",
      "Cheng Zhao",
      "David Gu",
      "Dimitris Samaras",
      "Mei Chen"
    ],
    "primary_category": "cs.CV",
    "categories": [
      "cs.CV"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01624v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01624v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 2.4,
    "matched_areas": [
      "ai",
      "vision"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01619v1",
    "title": "SUSD: Structured Unsupervised Skill Discovery through State Factorization",
    "summary": "Unsupervised Skill Discovery (USD) aims to autonomously learn a diverse set of skills without relying on extrinsic rewards. One of the most common USD approaches is to maximize the Mutual Information (MI) between skill latent variables and states. However, MI-based methods tend to favor simple, static skills due to their invariance properties, limiting the discovery of dynamic, task-relevant behaviors. Distance-Maximizing Skill Discovery (DSD) promotes more dynamic skills by leveraging state-space distances, yet still fall short in encouraging comprehensive skill sets that engage all controllable factors or entities in the environment. In this work, we introduce SUSD, a novel framework that harnesses the compositional structure of environments by factorizing the state space into independent components (e.g., objects or controllable entities). SUSD allocates distinct skill variables to different factors, enabling more fine-grained control on the skill discovery process. A dynamic model also tracks learning across factors, adaptively steering the agent's focus toward underexplored factors. This structured approach not only promotes the discovery of richer and more diverse skills, but also yields a factorized skill representation that enables fine-grained and disentangled control over individual entities which facilitates efficient training of compositional downstream tasks via Hierarchical Reinforcement Learning (HRL). Our experimental results across three environments, with factors ranging from 1 to 10, demonstrate that our method can discover diverse and complex skills without supervision, significantly outperforming existing unsupervised skill discovery methods in factorized and complex environments. Code is publicly available at: https://github.com/hadi-hosseini/SUSD.",
    "published": "2026-02-02T04:21:33Z",
    "updated": "2026-02-02T04:21:33Z",
    "authors": [
      "Seyed Mohammad Hadi Hosseini",
      "Mahdieh Soleymani Baghshah"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01619v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01619v1",
    "comment": "Accepted as a conference paper at ICLR 2026",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 2.4,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01610v1",
    "title": "ToPT: Task-Oriented Prompt Tuning for Urban Region Representation Learning",
    "summary": "Learning effective region embeddings from heterogeneous urban data underpins key urban computing tasks (e.g., crime prediction, resource allocation). However, prevailing two-stage methods yield task-agnostic representations, decoupling them from downstream objectives. Recent prompt-based approaches attempt to fix this but introduce two challenges: they often lack explicit spatial priors, causing spatially incoherent inter-region modeling, and they lack robust mechanisms for explicit task-semantic alignment. We propose ToPT, a two-stage framework that delivers spatially consistent fusion and explicit task alignment. ToPT consists of two modules: spatial-aware region embedding learning (SREL) and task-aware prompting for region embeddings (Prompt4RE). SREL employs a Graphormer-based fusion module that injects spatial priors-distance and regional centrality-as learnable attention biases to capture coherent, interpretable inter-region interactions. Prompt4RE performs task-oriented prompting: a frozen multimodal large language model (MLLM) processes task-specific templates to obtain semantic vectors, which are aligned with region embeddings via multi-head cross-attention for stable task conditioning. Experiments across multiple tasks and cities show state-of-the-art performance, with improvements of up to 64.2\\%, validating the necessity and complementarity of spatial priors and prompt-region alignment. The code is available at https://github.com/townSeven/Prompt4RE.git.",
    "published": "2026-02-02T03:56:05Z",
    "updated": "2026-02-02T03:56:05Z",
    "authors": [
      "Zitao Guo",
      "Changyang Jiang",
      "Tianhong Zhao",
      "Jinzhou Cao",
      "Genan Dai",
      "Bowen Zhang"
    ],
    "primary_category": "cs.AI",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01610v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01610v1",
    "comment": "The paper has been accepted by ICASSP 2026",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 2.4,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01591v1",
    "title": "Know Your Step: Faster and Better Alignment for Flow Matching Models via Step-aware Advantages",
    "summary": "Recent advances in flow matching models, particularly with reinforcement learning (RL), have significantly enhanced human preference alignment in few step text to image generators. However, existing RL based approaches for flow matching models typically rely on numerous denoising steps, while suffering from sparse and imprecise reward signals that often lead to suboptimal alignment. To address these limitations, we propose Temperature Annealed Few step Sampling with Group Relative Policy Optimization (TAFS GRPO), a novel framework for training flow matching text to image models into efficient few step generators well aligned with human preferences. Our method iteratively injects adaptive temporal noise onto the results of one step samples. By repeatedly annealing the model's sampled outputs, it introduces stochasticity into the sampling process while preserving the semantic integrity of each generated image. Moreover, its step aware advantage integration mechanism combines the GRPO to avoid the need for the differentiable of reward function and provide dense and step specific rewards for stable policy optimization. Extensive experiments demonstrate that TAFS GRPO achieves strong performance in few step text to image generation and significantly improves the alignment of generated images with human preferences. The code and models of this work will be available to facilitate further research.",
    "published": "2026-02-02T03:32:00Z",
    "updated": "2026-02-02T03:32:00Z",
    "authors": [
      "Zhixiong Yue",
      "Zixuan Ni",
      "Feiyang Ye",
      "Jinshan Zhang",
      "Sheng Shen",
      "Zhenpeng Mi"
    ],
    "primary_category": "cs.CV",
    "categories": [
      "cs.CV"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01591v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01591v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 2.4,
    "matched_areas": [
      "ai",
      "vision"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01530v1",
    "title": "Preserving Localized Patch Semantics in VLMs",
    "summary": "Logit Lens has been proposed for visualizing tokens that contribute most to LLM answers. Recently, Logit Lens was also shown to be applicable in autoregressive Vision-Language Models (VLMs), where it illustrates the conceptual content of image tokens in the form of heatmaps, e.g., which image tokens are likely to depict the concept of cat in a given image. However, the visual content of image tokens often gets diffused to language tokens, and consequently, the locality of visual information gets mostly destroyed, which renders Logit Lens visualization unusable for explainability. To address this issue, we introduce a complementary loss to next-token prediction (NTP) to prevent the visual tokens from losing the visual representation inherited from corresponding image patches. The proposed Logit Lens Loss (LLL) is designed to make visual token embeddings more semantically aligned with the textual concepts that describe their image regions (e.g., patches containing a cat with the word \"cat\"), without requiring any architectural modification or large-scale training. This way, LLL constrains the mixing of image and text tokens in the self-attention layers in order to prevent image tokens from losing their localized visual information. As our experiments show, LLL not only makes Logit Lens practically relevant by producing meaningful object confidence maps in images, but also improves performance on vision-centric tasks like segmentation without attaching any special heads.",
    "published": "2026-02-02T01:48:11Z",
    "updated": "2026-02-02T01:48:11Z",
    "authors": [
      "Parsa Esmaeilkhani",
      "Longin Jan Latecki"
    ],
    "primary_category": "cs.CV",
    "categories": [
      "cs.CV"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01530v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01530v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 2.4,
    "matched_areas": [
      "ai",
      "vision"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01519v1",
    "title": "You Need an Encoder for Native Position-Independent Caching",
    "summary": "The Key-Value (KV) cache of Large Language Models (LLMs) is prefix-based, making it highly inefficient for processing contexts retrieved in arbitrary order. Position-Independent Caching (PIC) has been proposed to enable KV reuse without positional constraints; however, existing approaches often incur substantial accuracy degradation, limiting their practical adoption. To address this issue, we propose native PIC by reintroducing the encoder to prevalent decoder-only LLMs and explicitly training it to support PIC. We further develop COMB, a PIC-aware caching system that integrates seamlessly with existing inference frameworks. Experimental results show that COMB reduces Time-to-First-Token (TTFT) by 51-94% and increases throughput by 3$\\times$ with comparable accuracy. Furthermore, the quality improvement when using DeepSeek-V2-Lite-Chat demonstrates the applicability of COMB to other types of decoder-only LLMs. Our code is available at https://github.com/shijuzhao/Comb.",
    "published": "2026-02-02T01:23:13Z",
    "updated": "2026-02-02T01:23:13Z",
    "authors": [
      "Shiju Zhao",
      "Junhao Hu",
      "Jiaqi Zheng",
      "Guihai Chen"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01519v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01519v1",
    "comment": "12 pages, 10 figures. Welcome back, Encoder",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 2.4,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02494v1",
    "title": "MEG-XL: Data-Efficient Brain-to-Text via Long-Context Pre-Training",
    "summary": "Clinical brain-to-text interfaces are designed for paralysed patients who cannot provide extensive training recordings. Pre-training improves data-efficient generalisation by learning statistical priors across subjects, but these priors critically depend on context. While natural speech might unfold gradually over minutes, most methods pre-train with only a few seconds of context. Thus, we propose MEG-XL, a model pre-trained with 2.5 minutes of MEG context per sample, 5-300x longer than prior work, and equivalent to 191k tokens, capturing extended neural context. Fine-tuning on the task of word decoding from brain data, MEG-XL matches supervised performance with a fraction of the data (e.g. 1hr vs 50hrs) and outperforms brain foundation models. We find that models pre-trained with longer contexts learn representations that transfer better to word decoding. Our results indicate that long-context pre-training helps exploit extended neural context that other methods unnecessarily discard. Code, model weights, and instructions are available at https://github.com/neural-processing-lab/MEG-XL .",
    "published": "2026-02-02T18:59:50Z",
    "updated": "2026-02-02T18:59:50Z",
    "authors": [
      "Dulhan Jayalath",
      "Oiwi Parker Jones"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "q-bio.NC"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02494v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02494v1",
    "comment": "19 pages, 8 figures, 5 tables",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02459v1",
    "title": "TIC-VLA: A Think-in-Control Vision-Language-Action Model for Robot Navigation in Dynamic Environments",
    "summary": "Robots in dynamic, human-centric environments must follow language instructions while maintaining real-time reactive control. Vision-language-action (VLA) models offer a promising framework, but they assume temporally aligned reasoning and control, despite semantic inference being inherently delayed relative to real-time action. We introduce Think-in-Control (TIC)-VLA, a latency-aware framework that explicitly models delayed semantic reasoning during action generation. TIC-VLA defines a delayed semantic-control interface that conditions action generation on delayed vision-language semantic states and explicit latency metadata, in addition to current observations, enabling policies to compensate for asynchronous reasoning. We further propose a latency-consistent training pipeline that injects reasoning inference delays during imitation learning and online reinforcement learning, aligning training with asynchronous deployment. To support realistic evaluation, we present DynaNav, a physics-accurate, photo-realistic simulation suite for language-guided navigation in dynamic environments. Extensive experiments in simulation and on a real robot show that TIC-VLA consistently outperforms prior VLA models while maintaining robust real-time control under multi-second reasoning latency. Project website: https://ucla-mobility.github.io/TIC-VLA/",
    "published": "2026-02-02T18:47:49Z",
    "updated": "2026-02-02T18:47:49Z",
    "authors": [
      "Zhiyu Huang",
      "Yun Zhang",
      "Johnson Liu",
      "Rui Song",
      "Chen Tang",
      "Jiaqi Ma"
    ],
    "primary_category": "cs.RO",
    "categories": [
      "cs.RO"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02459v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02459v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02453v1",
    "title": "Thinking with Comics: Enhancing Multimodal Reasoning through Structured Visual Storytelling",
    "summary": "Chain-of-Thought reasoning has driven large language models to extend from thinking with text to thinking with images and videos. However, different modalities still have clear limitations: static images struggle to represent temporal structure, while videos introduce substantial redundancy and computational cost. In this work, we propose Thinking with Comics, a visual reasoning paradigm that uses comics as a high information-density medium positioned between images and videos. Comics preserve temporal structure, embedded text, and narrative coherence while requiring significantly lower reasoning cost. We systematically study two reasoning paths based on comics and evaluate them on a range of reasoning tasks and long-context understanding tasks. Experimental results show that Thinking with Comics outperforms Thinking with Images on multi-step temporal and causal reasoning tasks, while remaining substantially more efficient than Thinking with Video. Further analysis indicates that different comic narrative structures and styles consistently affect performance across tasks, suggesting that comics serve as an effective intermediate visual representation for improving multimodal reasoning.",
    "published": "2026-02-02T18:43:57Z",
    "updated": "2026-02-02T18:43:57Z",
    "authors": [
      "Andong Chen",
      "Wenxin Zhu",
      "Qiuyu Ding",
      "Yuchen Song",
      "Muyun Yang",
      "Tiejun Zhao"
    ],
    "primary_category": "cs.AI",
    "categories": [
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02453v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02453v1",
    "comment": "Working paper",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02443v1",
    "title": "Certain Head, Uncertain Tail: Expert-Sample for Test-Time Scaling in Fine-Grained MoE",
    "summary": "Test-time scaling improves LLM performance by generating multiple candidate solutions, yet token-level sampling requires temperature tuning that trades off diversity against stability. Fine-grained MoE, featuring hundreds of well-trained experts per layer and multi-expert activation per token, offers an unexplored alternative through its rich routing space. We empirically characterize fine-grained MoE routing and uncover an informative pattern: router scores exhibit a certain head of high-confidence experts followed by an uncertain tail of low-confidence candidates. While single-run greedy accuracy remains stable when fewer experts are activated, multi-sample pass@n degrades significantly-suggesting that the certain head governs core reasoning capability while the uncertain tail correlates with reasoning diversity. Motivated by these findings, we propose Expert-Sample, a training-free method that preserves high-confidence selections while injecting controlled stochasticity into the uncertain tail, enabling diverse generation without destabilizing outputs. Evaluated on multiple fine-grained MoE models across math, knowledge reasoning, and code tasks, Expert-Sample consistently improves pass@n and verification-based accuracy. On Qwen3-30B-A3B-Instruct evaluated on GPQA-Diamond with 32 parallel samples, pass@32 rises from 85.4% to 91.9%, and accuracy improves from 59.1% to 62.6% with Best-of-N verification.",
    "published": "2026-02-02T18:39:33Z",
    "updated": "2026-02-02T18:39:33Z",
    "authors": [
      "Yuanteng Chen",
      "Peisong Wang",
      "Nanxin Zeng",
      "Yuantian Shao",
      "Gang Li",
      "Jing Liu",
      "Jian Cheng"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02443v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02443v1",
    "comment": "24 pages, 13 figures",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02425v1",
    "title": "Repurposing Protein Language Models for Latent Flow-Based Fitness Optimization",
    "summary": "Protein fitness optimization is challenged by a vast combinatorial landscape where high-fitness variants are extremely sparse. Many current methods either underperform or require computationally expensive gradient-based sampling. We present CHASE, a framework that repurposes the evolutionary knowledge of pretrained protein language models by compressing their embeddings into a compact latent space. By training a conditional flow-matching model with classifier-free guidance, we enable the direct generation of high-fitness variants without predictor-based guidance during the ODE sampling steps. CHASE achieves state-of-the-art performance on AAV and GFP protein design benchmarks. Finally, we show that bootstrapping with synthetic data can further enhance performance in data-constrained settings.",
    "published": "2026-02-02T18:25:33Z",
    "updated": "2026-02-02T18:25:33Z",
    "authors": [
      "Amaru Caceres Arroyo",
      "Lea Bogensperger",
      "Ahmed Allam",
      "Michael Krauthammer",
      "Konrad Schindler",
      "Dominik Narnhofer"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "q-bio.QM"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02425v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02425v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "vision"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02422v1",
    "title": "Poly-attention: a general scheme for higher-order self-attention",
    "summary": "The self-attention mechanism, at the heart of the Transformer model, is able to effectively model pairwise interactions between tokens. However, numerous recent works have shown that it is unable to perform basic tasks involving detecting triples of correlated tokens, or compositional tasks where multiple input tokens need to be referenced to generate a result. Some higher-dimensional alternatives to self-attention have been proposed to address this, including higher-order attention and Strassen attention, which can perform some of these polyadic tasks in exchange for slower, superquadratic running times. In this work, we define a vast class of generalizations of self-attention, which we call poly-attention mechanisms. Our mechanisms can incorporate arbitrary higher-order (tensor) computations as well as arbitrary relationship structures between the input tokens, and they include the aforementioned alternatives as special cases. We then systematically study their computational complexity and representational strength, including giving new algorithms and matching complexity-theoretic lower bounds on the time complexity of computing the attention matrix exactly as well as approximately, and tightly determining which polyadic tasks they can each perform. Our results give interesting trade-offs between different desiderata for these mechanisms, including a tight relationship between how expressive a mechanism is, and how large the coefficients in the model may be so that the mechanism can be approximated in almost-linear time. Notably, we give a new attention mechanism which can be computed exactly in quadratic time, and which can perform function composition for any fixed number of functions. Prior mechanisms, even for just composing two functions, could only be computed in superquadratic time, and our new lower bounds show that faster algorithms for them are not possible.",
    "published": "2026-02-02T18:24:53Z",
    "updated": "2026-02-02T18:24:53Z",
    "authors": [
      "Sayak Chakrabarti",
      "Toniann Pitassi",
      "Josh Alman"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02422v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02422v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02417v1",
    "title": "Trust Region Continual Learning as an Implicit Meta-Learner",
    "summary": "Continual learning aims to acquire tasks sequentially without catastrophic forgetting, yet standard strategies face a core tradeoff: regularization-based methods (e.g., EWC) can overconstrain updates when task optima are weakly overlapping, while replay-based methods can retain performance but drift due to imperfect replay. We study a hybrid perspective: \\emph{trust region continual learning} that combines generative replay with a Fisher-metric trust region constraint. We show that, under local approximations, the resulting update admits a MAML-style interpretation with a single implicit inner step: replay supplies an old-task gradient signal (query-like), while the Fisher-weighted penalty provides an efficient offline curvature shaping (support-like). This yields an emergent meta-learning property in continual learning: the model becomes an initialization that rapidly \\emph{re-converges} to prior task optima after each task transition, without explicitly optimizing a bilevel objective. Empirically, on task-incremental diffusion image generation and continual diffusion-policy control, trust region continual learning achieves the best final performance and retention, and consistently recovers early-task performance faster than EWC, replay, and continual meta-learning baselines.",
    "published": "2026-02-02T18:19:16Z",
    "updated": "2026-02-02T18:19:16Z",
    "authors": [
      "Zekun Wang",
      "Anant Gupta",
      "Christopher J. MacLellan"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02417v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02417v1",
    "comment": "19 pages, 23 tables",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "vision"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02415v1",
    "title": "Active Transfer Bagging: A New Approach for Accelerated Active Learning Acquisition of Data by Combined Transfer Learning and Bagging Based Models",
    "summary": "Modern machine learning has achieved remarkable success on many problems, but this success often depends on the existence of large, labeled datasets. While active learning can dramatically reduce labeling cost when annotations are expensive, early performance is frequently dominated by the initial seed set, typically chosen at random. In many applications, however, related or approximate datasets are readily available and can be leveraged to construct a better seed set. We introduce a new method for selecting the seed data set for active learning, Active-Transfer Bagging (ATBagging). ATBagging estimates the informativeness of candidate data point from a Bayesian interpretation of bagged ensemble models by comparing in-bag and out-of-bag predictive distributions from the labeled dataset, yielding an information-gain proxy. To avoid redundant selections, we impose feature-space diversity by sampling a determinantal point process (DPP) whose kernel uses Random Fourier Features and a quality-diversity factorization that incorporates the informativeness scores. This same blended method is used for selection of new data points to collect during the active learning phase. We evaluate ATBagging on four real-world datasets covering both target-transfer and feature-shift scenarios (QM9, ERA5, Forbes 2000, and Beijing PM2.5). Across seed sizes nseed = 10-100, ATBagging improves or ties early active learning and increases area under the learning-curve relative to alternative seed subset selection methodologies in almost all cases, with strongest benefits in low-data regimes. Thus, ATBagging provides a low-cost, high reward means to initiating active learning-based data collection.",
    "published": "2026-02-02T18:15:50Z",
    "updated": "2026-02-02T18:15:50Z",
    "authors": [
      "Vivienne Pelletier",
      "Daniel J. Rivera",
      "Obinna Nwokonkwo",
      "Steven A. Wilson",
      "Christopher L. Muhich"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02415v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02415v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02409v1",
    "title": "Catalyst: Out-of-Distribution Detection via Elastic Scaling",
    "summary": "Out-of-distribution (OOD) detection is critical for the safe deployment of deep neural networks. State-of-the-art post-hoc methods typically derive OOD scores from the output logits or penultimate feature vector obtained via global average pooling (GAP). We contend that this exclusive reliance on the logit or feature vector discards a rich, complementary signal: the raw channel-wise statistics of the pre-pooling feature map lost in GAP. In this paper, we introduce Catalyst, a post-hoc framework that exploits these under-explored signals. Catalyst computes an input-dependent scaling factor ($$) on-the-fly from these raw statistics (e.g., mean, standard deviation, and maximum activation). This $$ is then fused with the existing baseline score, multiplicatively modulating it -- an ``elastic scaling'' -- to push the ID and OOD distributions further apart. We demonstrate Catalyst is a generalizable framework: it seamlessly integrates with logit-based methods (e.g., Energy, ReAct, SCALE) and also provides a significant boost to distance-based detectors like KNN. As a result, Catalyst achieves substantial and consistent performance gains, reducing the average False Positive Rate by 32.87 on CIFAR-10 (ResNet-18), 27.94% on CIFAR-100 (ResNet-18), and 22.25% on ImageNet (ResNet-50). Our results highlight the untapped potential of pre-pooling statistics and demonstrate that Catalyst is complementary to existing OOD detection approaches.",
    "published": "2026-02-02T18:08:33Z",
    "updated": "2026-02-02T18:08:33Z",
    "authors": [
      "Abid Hassan",
      "Tuan Ngo",
      "Saad Shafiq",
      "Nenad Medvidovic"
    ],
    "primary_category": "cs.CV",
    "categories": [
      "cs.CV"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02409v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02409v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02396v1",
    "title": "PRISM: Performer RS-IMLE for Single-pass Multisensory Imitation Learning",
    "summary": "Robotic imitation learning typically requires models that capture multimodal action distributions while operating at real-time control rates and accommodating multiple sensing modalities. Although recent generative approaches such as diffusion models, flow matching, and Implicit Maximum Likelihood Estimation (IMLE) have achieved promising results, they often satisfy only a subset of these requirements. To address this, we introduce PRISM, a single-pass policy based on a batch-global rejection-sampling variant of IMLE. PRISM couples a temporal multisensory encoder (integrating RGB, depth, tactile, audio, and proprioception) with a linear-attention generator using a Performer architecture. We demonstrate the efficacy of PRISM on a diverse real-world hardware suite, including loco-manipulation using a Unitree Go2 with a 7-DoF arm D1 and tabletop manipulation with a UR5 manipulator. Across challenging physical tasks such as pre-manipulation parking, high-precision insertion, and multi-object pick-and-place, PRISM outperforms state-of-the-art diffusion policies by 10-25% in success rate while maintaining high-frequency (30-50 Hz) closed-loop control. We further validate our approach on large-scale simulation benchmarks, including CALVIN, MetaWorld, and Robomimic. In CALVIN (10% data split), PRISM improves success rates by approximately 25% over diffusion and approximately 20% over flow matching, while simultaneously reducing trajectory jerk by 20x-50x. These results position PRISM as a fast, accurate, and multisensory imitation policy that retains multimodal action coverage without the latency of iterative sampling.",
    "published": "2026-02-02T17:57:37Z",
    "updated": "2026-02-02T17:57:37Z",
    "authors": [
      "Amisha Bhaskar",
      "Pratap Tokekar",
      "Stefano Di Cairano",
      "Alexander Schperberg"
    ],
    "primary_category": "cs.RO",
    "categories": [
      "cs.RO",
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02396v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02396v1",
    "comment": "10 pages main text and 4 figures, and 11 pages appendix and 10 figures, total 21 pages and 14 figures",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02380v1",
    "title": "Unified Personalized Reward Model for Vision Generation",
    "summary": "Recent advancements in multimodal reward models (RMs) have significantly propelled the development of visual generation. Existing frameworks typically adopt Bradley-Terry-style preference modeling or leverage generative VLMs as judges, and subsequently optimize visual generation models via reinforcement learning. However, current RMs suffer from inherent limitations: they often follow a one-size-fits-all paradigm that assumes a monolithic preference distribution or relies on fixed evaluation rubrics. As a result, they are insensitive to content-specific visual cues, leading to systematic misalignment with subjective and context-dependent human preferences. To this end, inspired by human assessment, we propose UnifiedReward-Flex, a unified personalized reward model for vision generation that couples reward modeling with flexible and context-adaptive reasoning. Specifically, given a prompt and the generated visual content, it first interprets the semantic intent and grounds on visual evidence, then dynamically constructs a hierarchical assessment by instantiating fine-grained criteria under both predefined and self-generated high-level dimensions. Our training pipeline follows a two-stage process: (1) we first distill structured, high-quality reasoning traces from advanced closed-source VLMs to bootstrap SFT, equipping the model with flexible and context-adaptive reasoning behaviors; (2) we then perform direct preference optimization (DPO) on carefully curated preference pairs to further strengthen reasoning fidelity and discriminative alignment. To validate the effectiveness, we integrate UnifiedReward-Flex into the GRPO framework for image and video synthesis, and extensive results demonstrate its superiority.",
    "published": "2026-02-02T17:44:21Z",
    "updated": "2026-02-02T17:44:21Z",
    "authors": [
      "Yibin Wang",
      "Yuhang Zang",
      "Feng Han",
      "Jiazi Bu",
      "Yujie Zhou",
      "Cheng Jin",
      "Jiaqi Wang"
    ],
    "primary_category": "cs.CV",
    "categories": [
      "cs.CV"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02380v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02380v1",
    "comment": "Website: https://codegoat24.github.io/UnifiedReward/flex",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02378v1",
    "title": "From Sycophancy to Sensemaking: Premise Governance for Human-AI Decision Making",
    "summary": "As LLMs expand from assistance to decision support, a dangerous pattern emerges: fluent agreement without calibrated judgment. Low-friction assistants can become sycophantic, baking in implicit assumptions and pushing verification costs onto experts, while outcomes arrive too late to serve as reward signals. In deep-uncertainty decisions (where objectives are contested and reversals are costly), scaling fluent agreement amplifies poor commitments faster than it builds expertise. We argue reliable human-AI partnership requires a shift from answer generation to collaborative premise governance over a knowledge substrate, negotiating only what is decision-critical. A discrepancy-driven control loop operates over this substrate: detecting conflicts, localizing misalignment via typed discrepancies (teleological, epistemic, procedural), and triggering bounded negotiation through decision slices. Commitment gating blocks action on uncommitted load-bearing premises unless overridden under logged risk; value-gated challenge allocates probing under interaction cost. Trust then attaches to auditable premises and evidence standards, not conversational fluency. We illustrate with tutoring and propose falsifiable evaluation criteria.",
    "published": "2026-02-02T17:42:54Z",
    "updated": "2026-02-02T17:42:54Z",
    "authors": [
      "Raunak Jain",
      "Mudita Khurana",
      "John Stephens",
      "Srinivas Dharmasanam",
      "Shankar Venkataraman"
    ],
    "primary_category": "cs.CL",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02378v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02378v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02370v1",
    "title": "Uncertainty-Aware Image Classification In Biomedical Imaging Using Spectral-normalized Neural Gaussian Processes",
    "summary": "Accurate histopathologic interpretation is key for clinical decision-making; however, current deep learning models for digital pathology are often overconfident and poorly calibrated in out-of-distribution (OOD) settings, which limit trust and clinical adoption. Safety-critical medical imaging workflows benefit from intrinsic uncertainty-aware properties that can accurately reject OOD input. We implement the Spectral-normalized Neural Gaussian Process (SNGP), a set of lightweight modifications that apply spectral normalization and replace the final dense layer with a Gaussian process layer to improve single-model uncertainty estimation and OOD detection. We evaluate SNGP vs. deterministic and MonteCarlo dropout on six datasets across three biomedical classification tasks: white blood cells, amyloid plaques, and colorectal histopathology. SNGP has comparable in-distribution performance while significantly improving uncertainty estimation and OOD detection. Thus, SNGP or related models offer a useful framework for uncertainty-aware classification in digital pathology, supporting safe deployment and building trust with pathologists.",
    "published": "2026-02-02T17:35:10Z",
    "updated": "2026-02-02T17:35:10Z",
    "authors": [
      "Uma Meleti",
      "Jeffrey J. Nirschl"
    ],
    "primary_category": "cs.CV",
    "categories": [
      "cs.CV"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02370v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02370v1",
    "comment": "Accepted for publication at the IEEE International Symposium on Biomedical Imaging (ISBI) 2026",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02356v1",
    "title": "NAB: Neural Adaptive Binning for Sparse-View CT reconstruction",
    "summary": "Computed Tomography (CT) plays a vital role in inspecting the internal structures of industrial objects. Furthermore, achieving high-quality CT reconstruction from sparse views is essential for reducing production costs. While classic implicit neural networks have shown promising results for sparse reconstruction, they are unable to leverage shape priors of objects. Motivated by the observation that numerous industrial objects exhibit rectangular structures, we propose a novel \\textbf{N}eural \\textbf{A}daptive \\textbf{B}inning (\\textbf{NAB}) method that effectively integrates rectangular priors into the reconstruction process. Specifically, our approach first maps coordinate space into a binned vector space. This mapping relies on an innovative binning mechanism based on differences between shifted hyperbolic tangent functions, with our extension enabling rotations around the input-plane normal vector. The resulting representations are then processed by a neural network to predict CT attenuation coefficients. This design enables end-to-end optimization of the encoding parameters -- including position, size, steepness, and rotation -- via gradient flow from the projection data, thus enhancing reconstruction accuracy. By adjusting the smoothness of the binning function, NAB can generalize to objects with more complex geometries. This research provides a new perspective on integrating shape priors into neural network-based reconstruction. Extensive experiments demonstrate that NAB achieves superior performance on two industrial datasets. It also maintains robust on medical datasets when the binning function is extended to more general expression. The code will be made available.",
    "published": "2026-02-02T17:19:22Z",
    "updated": "2026-02-02T17:19:22Z",
    "authors": [
      "Wangduo Xie",
      "Matthew B. Blaschko"
    ],
    "primary_category": "cs.CV",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02356v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02356v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02354v1",
    "title": "Implicit neural representation of textures",
    "summary": "Implicit neural representation (INR) has proven to be accurate and efficient in various domains. In this work, we explore how different neural networks can be designed as a new texture INR, which operates in a continuous manner rather than a discrete one over the input UV coordinate space. Through thorough experiments, we demonstrate that these INRs perform well in terms of image quality, with considerable memory usage and rendering inference time. We analyze the balance between these objectives. In addition, we investigate various related applications in real-time rendering and down-stream tasks, e.g. mipmap fitting and INR-space generation.",
    "published": "2026-02-02T17:17:20Z",
    "updated": "2026-02-02T17:17:20Z",
    "authors": [
      "Albert Kwok",
      "Zheyuan Hu",
      "Dounia Hammou"
    ],
    "primary_category": "cs.CV",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR",
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02354v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02354v1",
    "comment": "Albert Kwok and Zheyuan Hu contributed equally to this work",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02341v1",
    "title": "LongVPO: From Anchored Cues to Self-Reasoning for Long-Form Video Preference Optimization",
    "summary": "We present LongVPO, a novel two-stage Direct Preference Optimization framework that enables short-context vision-language models to robustly understand ultra-long videos without any long-video annotations. In Stage 1, we synthesize preference triples by anchoring questions to individual short clips, interleaving them with distractors, and applying visual-similarity and question-specificity filtering to mitigate positional bias and ensure unambiguous supervision. We also approximate the reference model's scoring over long contexts by evaluating only the anchor clip, reducing computational overhead. In Stage 2, we employ a recursive captioning pipeline on long videos to generate scene-level metadata, then use a large language model to craft multi-segment reasoning queries and dispreferred responses, aligning the model's preferences through multi-segment reasoning tasks. With only 16K synthetic examples and no costly human labels, LongVPO outperforms the state-of-the-art open-source models on multiple long-video benchmarks, while maintaining strong short-video performance (e.g., on MVBench), offering a scalable paradigm for efficient long-form video understanding.",
    "published": "2026-02-02T17:03:37Z",
    "updated": "2026-02-02T17:03:37Z",
    "authors": [
      "Zhenpeng Huang",
      "Jiaqi Li",
      "Zihan Jia",
      "Xinhao Li",
      "Desen Meng",
      "Lingxue Song",
      "Xi Chen",
      "Liang Li",
      "Limin Wang"
    ],
    "primary_category": "cs.CV",
    "categories": [
      "cs.CV"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02341v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02341v1",
    "comment": "NeurIPS 2025",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02290v1",
    "title": "Hallucination or Creativity: How to Evaluate AI-Generated Scientific Stories?",
    "summary": "Generative AI can turn scientific articles into narratives for diverse audiences, but evaluating these stories remains challenging. Storytelling demands abstraction, simplification, and pedagogical creativity-qualities that are not often well-captured by standard summarization metrics. Meanwhile, factual hallucinations are critical in scientific contexts, yet, detectors often misclassify legitimate narrative reformulations or prove unstable when creativity is involved. In this work, we propose StoryScore, a composite metric for evaluating AI-generated scientific stories. StoryScore integrates semantic alignment, lexical grounding, narrative control, structural fidelity, redundancy avoidance, and entity-level hallucination detection into a unified framework. Our analysis also reveals why many hallucination detection methods fail to distinguish pedagogical creativity from factual errors, highlighting a key limitation: while automatic metrics can effectively assess semantic similarity with original content, they struggle to evaluate how it is narrated and controlled.",
    "published": "2026-02-02T16:29:32Z",
    "updated": "2026-02-02T16:29:32Z",
    "authors": [
      "Alex Argese",
      "Pasquale Lisena",
      "Raphal Troncy"
    ],
    "primary_category": "cs.CL",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02290v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02290v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02286v1",
    "title": "DFKI-Speech System for WildSpoof Challenge: A robust framework for SASV In-the-Wild",
    "summary": "This paper presents the DFKI-Speech system developed for the WildSpoof Challenge under the Spoofing aware Automatic Speaker Verification (SASV) track. We propose a robust SASV framework in which a spoofing detector and a speaker verification (SV) network operate in tandem. The spoofing detector employs a self-supervised speech embedding extractor as the frontend, combined with a state-of-the-art graph neural network backend. In addition, a top-3 layer based mixture-of-experts (MoE) is used to fuse high-level and low-level features for effective spoofed utterance detection. For speaker verification, we adapt a low-complexity convolutional neural network that fuses 2D and 1D features at multiple scales, trained with the SphereFace loss. Additionally, contrastive circle loss is applied to adaptively weight positive and negative pairs within each training batch, enabling the network to better distinguish between hard and easy sample pairs. Finally, fixed imposter cohort based AS Norm score normalization and model ensembling are used to further enhance the discriminative capability of the speaker verification system.",
    "published": "2026-02-02T16:27:04Z",
    "updated": "2026-02-02T16:27:04Z",
    "authors": [
      "Arnab Das",
      "Yassine El Kheir",
      "Enes Erdem Erdogan",
      "Feidi Kallel",
      "Tim Polzehl",
      "Sebastian Moeller"
    ],
    "primary_category": "cs.SD",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02286v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02286v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02283v1",
    "title": "Choice-Model-Assisted Q-learning for Delayed-Feedback Revenue Management",
    "summary": "We study reinforcement learning for revenue management with delayed feedback, where a substantial fraction of value is determined by customer cancellations and modifications observed days after booking. We propose \\emph{choice-model-assisted RL}: a calibrated discrete choice model is used as a fixed partial world model to impute the delayed component of the learning target at decision time. In the fixed-model deployment regime, we prove that tabular Q-learning with model-imputed targets converges to an $O(\\varepsilon/(1-))$ neighborhood of the optimal Q-function, where $\\varepsilon$ summarizes partial-model error, with an additional $O(t^{-1/2})$ sampling term. Experiments in a simulator calibrated from 61{,}619 hotel bookings (1{,}088 independent runs) show: (i) no statistically detectable difference from a maturity-buffer DQN baseline in stationary settings; (ii) positive effects under in-family parameter shifts, with significant gains in 5 of 10 shift scenarios after Holm--Bonferroni correction (up to 12.4\\%); and (iii) consistent degradation under structural misspecification, where the choice model assumptions are violated (1.4--2.6\\% lower revenue). These results characterize when partial behavioral models improve robustness under shift and when they introduce harmful bias.",
    "published": "2026-02-02T16:23:56Z",
    "updated": "2026-02-02T16:23:56Z",
    "authors": [
      "Owen Shen",
      "Patrick Jaillet"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02283v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02283v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02282v1",
    "title": "MoLF: Mixture-of-Latent-Flow for Pan-Cancer Spatial Gene Expression Prediction from Histology",
    "summary": "Inferring spatial transcriptomics (ST) from histology enables scalable histogenomic profiling, yet current methods are largely restricted to single-tissue models. This fragmentation fails to leverage biological principles shared across cancer types and hinders application to data-scarce scenarios. While pan-cancer training offers a solution, the resulting heterogeneity challenges monolithic architectures. To bridge this gap, we introduce MoLF (Mixture-of-Latent-Flow), a generative model for pan-cancer histogenomic prediction. MoLF leverages a conditional Flow Matching objective to map noise to the gene latent manifold, parameterized by a Mixture-of-Experts (MoE) velocity field. By dynamically routing inputs to specialized sub-networks, this architecture effectively decouples the optimization of diverse tissue patterns. Our experiments demonstrate that MoLF establishes a new state-of-the-art, consistently outperforming both specialized and foundation model baselines on pan-cancer benchmarks. Furthermore, MoLF exhibits zero-shot generalization to cross-species data, suggesting it captures fundamental, conserved histo-molecular mechanisms.",
    "published": "2026-02-02T16:23:31Z",
    "updated": "2026-02-02T16:23:31Z",
    "authors": [
      "Susu Hu",
      "Stefanie Speidel"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02282v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02282v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02281v1",
    "title": "Backpropagation as Physical Relaxation: Exact Gradients in Finite Time",
    "summary": "Backpropagation, the foundational algorithm for training neural networks, is typically understood as a symbolic computation that recursively applies the chain rule. We show it emerges exactly as the finite-time relaxation of a physical dynamical system. By formulating feedforward inference as a continuous-time process and applying Lagrangian theory of non-conservative systems to handle asymmetric interactions, we derive a global energy functional on a doubled state space encoding both activations and sensitivities. The saddle-point dynamics of this energy perform inference and credit assignment simultaneously through local interactions. We term this framework ''Dyadic Backpropagation''. Crucially, we prove that unit-step Euler discretization, the natural timescale of layer transitions, recovers standard backpropagation exactly in precisely 2L steps for an L-layer network, with no approximations. Unlike prior energy-based methods requiring symmetric weights, asymptotic convergence, or vanishing perturbations, our framework guarantees exact gradients in finite time. This establishes backpropagation as the digitally optimized shadow of a continuous physical relaxation, providing a rigorous foundation for exact gradient computation in analog and neuromorphic substrates where continuous dynamics are native.",
    "published": "2026-02-02T16:21:05Z",
    "updated": "2026-02-02T16:21:05Z",
    "authors": [
      "Antonino Emanuele Scurria"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE",
      "physics.class-ph",
      "physics.comp-ph"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02281v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02281v1",
    "comment": "15 pages, 8 figures",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02261v1",
    "title": "Unlocking the Duality between Flow and Field Matching",
    "summary": "Conditional Flow Matching (CFM) unifies conventional generative paradigms such as diffusion models and flow matching. Interaction Field Matching (IFM) is a newer framework that generalizes Electrostatic Field Matching (EFM) rooted in Poisson Flow Generative Models (PFGM). While both frameworks define generative dynamics, they start from different objects: CFM specifies a conditional probability path in data space, whereas IFM specifies a physics-inspired interaction field in an augmented data space. This raises a basic question: are CFM and IFM genuinely different, or are they two descriptions of the same underlying dynamics? We show that they coincide for a natural subclass of IFM that we call forward-only IFM. Specifically, we construct a bijection between CFM and forward-only IFM. We further show that general IFM is strictly more expressive: it includes EFM and other interaction fields that cannot be realized within the standard CFM formulation. Finally, we highlight how this duality can benefit both frameworks: it provides a probabilistic interpretation of forward-only IFM and yields novel, IFM-driven techniques for CFM.",
    "published": "2026-02-02T16:04:01Z",
    "updated": "2026-02-02T16:04:01Z",
    "authors": [
      "Daniil Shlenskii",
      "Alexander Varlamov",
      "Nazar Buzun",
      "Alexander Korotin"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02261v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02261v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02258v1",
    "title": "Alignment-Aware Model Adaptation via Feedback-Guided Optimization",
    "summary": "Fine-tuning is the primary mechanism for adapting foundation models to downstream tasks; however, standard approaches largely optimize task objectives in isolation and do not account for secondary yet critical alignment objectives (e.g., safety and hallucination avoidance). As a result, downstream fine-tuning can degrade alignment and fail to correct pre-existing misaligned behavior. We propose an alignment-aware fine-tuning framework that integrates feedback from an external alignment signal through policy-gradient-based regularization. Our method introduces an adaptive gating mechanism that dynamically balances supervised and alignment-driven gradients on a per-sample basis, prioritizing uncertain or misaligned cases while allowing well-aligned examples to follow standard supervised updates. The framework further learns abstention behavior for fully misaligned inputs, incorporating conservative responses directly into the fine-tuned model. Experiments on general and domain-specific instruction-tuning benchmarks demonstrate consistent reductions in harmful and hallucinated outputs without sacrificing downstream task performance. Additional analyses show robustness to adversarial fine-tuning, prompt-based attacks, and unsafe initializations, establishing adaptively gated alignment optimization as an effective approach for alignment-preserving and alignment-recovering model adaptation.",
    "published": "2026-02-02T16:03:16Z",
    "updated": "2026-02-02T16:03:16Z",
    "authors": [
      "Gaurav Bhatt",
      "Aditya Chinchure",
      "Jiawei Zhou",
      "Leonid Sigal"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02258v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02258v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02250v1",
    "title": "Well-Posed KL-Regularized Control via Wasserstein and Kalman-Wasserstein KL Divergences",
    "summary": "Kullback-Leibler divergence (KL) regularization is widely used in reinforcement learning, but it becomes infinite under support mismatch and can degenerate in low-noise limits. Utilizing a unified information-geometric framework, we introduce (Kalman)-Wasserstein-based KL analogues by replacing the Fisher-Rao geometry in the dynamical formulation of the KL with transport-based geometries, and we derive closed-form values for common distribution families. These divergences remain finite under support mismatch and yield a geometric interpretation of regularization heuristics used in Kalman ensemble methods. We demonstrate the utility of these divergences in KL-regularized optimal control. In the fully tractable setting of linear time-invariant systems with Gaussian process noise, the classical KL reduces to a quadratic control penalty that becomes singular as process noise vanishes. Our variants remove this singularity, yielding well-posed problems. On a double integrator and a cart-pole example, the resulting controls outperform KL-based regularization.",
    "published": "2026-02-02T15:57:32Z",
    "updated": "2026-02-02T15:57:32Z",
    "authors": [
      "Viktor Stein",
      "Adwait Datar",
      "Nihat Ay"
    ],
    "primary_category": "math.OC",
    "categories": [
      "math.OC",
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02250v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02250v1",
    "comment": "37 pages, 9 figures, comments welcome",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02244v1",
    "title": "Learning While Staying Curious: Entropy-Preserving Supervised Fine-Tuning via Adaptive Self-Distillation for Large Reasoning Models",
    "summary": "The standard post-training recipe for large reasoning models, supervised fine-tuning followed by reinforcement learning (SFT-then-RL), may limit the benefits of the RL stage: while SFT imitates expert demonstrations, it often causes overconfidence and reduces generation diversity, leaving RL with a narrowed solution space to explore. Adding entropy regularization during SFT is not a cure-all; it tends to flatten token distributions toward uniformity, increasing entropy without improving meaningful exploration capability. In this paper, we propose CurioSFT, an entropy-preserving SFT method designed to enhance exploration capabilities through intrinsic curiosity. It consists of (a) Self-Exploratory Distillation, which distills the model toward a self-generated, temperature-scaled teacher to encourage exploration within its capability; and (b) Entropy-Guided Temperature Selection, which adaptively adjusts distillation strength to mitigate knowledge forgetting by amplifying exploration at reasoning tokens while stabilizing factual tokens. Extensive experiments on mathematical reasoning tasks demonstrate that, in SFT stage, CurioSFT outperforms the vanilla SFT by 2.5 points on in-distribution tasks and 2.9 points on out-of-distribution tasks. We also verify that exploration capabilities preserved during SFT successfully translate into concrete gains in RL stage, yielding an average improvement of 5.0 points.",
    "published": "2026-02-02T15:53:55Z",
    "updated": "2026-02-02T15:53:55Z",
    "authors": [
      "Hao Wang",
      "Hao Gu",
      "Hongming Piao",
      "Kaixiong Gong",
      "Yuxiao Ye",
      "Xiangyu Yue",
      "Sirui Han",
      "Yike Guo",
      "Dapeng Wu"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02244v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02244v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02241v1",
    "title": "Variational Entropic Optimal Transport",
    "summary": "Entropic optimal transport (EOT) in continuous spaces with quadratic cost is a classical tool for solving the domain translation problem. In practice, recent approaches optimize a weak dual EOT objective depending on a single potential, but doing so is computationally not efficient due to the intractable log-partition term. Existing methods typically resolve this obstacle in one of two ways: by significantly restricting the transport family to obtain closed-form normalization (via Gaussian-mixture parameterizations), or by using general neural parameterizations that require simulation-based training procedures. We propose Variational Entropic Optimal Transport (VarEOT), based on an exact variational reformulation of the log-partition $\\log \\mathbb{E}[\\exp(\\cdot)]$ as a tractable minimization over an auxiliary positive normalizer. This yields a differentiable learning objective optimized with stochastic gradients and avoids the necessity of MCMC simulations during the training. We provide theoretical guarantees, including finite-sample generalization bounds and approximation results under universal function approximation. Experiments on synthetic data and unpaired image-to-image translation demonstrate competitive or improved translation quality, while comparisons within the solvers that use the same weak dual EOT objective support the benefit of the proposed optimization principle.",
    "published": "2026-02-02T15:48:44Z",
    "updated": "2026-02-02T15:48:44Z",
    "authors": [
      "Roman Dyachenko",
      "Nikita Gushchin",
      "Kirill Sokolov",
      "Petr Mokrov",
      "Evgeny Burnaev",
      "Alexander Korotin"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02241v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02241v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "vision"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02238v1",
    "title": "Geometry- and Relation-Aware Diffusion for EEG Super-Resolution",
    "summary": "Recent electroencephalography (EEG) spatial super-resolution (SR) methods, while showing improved quality by either directly predicting missing signals from visible channels or adapting latent diffusion-based generative modeling to temporal data, often lack awareness of physiological spatial structure, thereby constraining spatial generation performance. To address this issue, we introduce TopoDiff, a geometry- and relation-aware diffusion model for EEG spatial super-resolution. Inspired by how human experts interpret spatial EEG patterns, TopoDiff incorporates topology-aware image embeddings derived from EEG topographic representations to provide global geometric context for spatial generation, together with a dynamic channel-relation graph that encodes inter-electrode relationships and evolves with temporal dynamics. This design yields a spatially grounded EEG spatial super-resolution framework with consistent performance improvements. Across multiple EEG datasets spanning diverse applications, including SEED/SEED-IV for emotion recognition, PhysioNet motor imagery (MI/MM), and TUSZ for seizure detection, our method achieves substantial gains in generation fidelity and leads to notable improvements in downstream EEG task performance.",
    "published": "2026-02-02T15:44:20Z",
    "updated": "2026-02-02T15:44:20Z",
    "authors": [
      "Laura Yao",
      "Gengwei Zhang",
      "Moajjem Chowdhury",
      "Yunmei Liu",
      "Tianlong Chen"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02238v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02238v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02224v1",
    "title": "Spectral Superposition: A Theory of Feature Geometry",
    "summary": "Neural networks represent more features than they have dimensions via superposition, forcing features to share representational space. Current methods decompose activations into sparse linear features but discard geometric structure. We develop a theory for studying the geometric structre of features by analyzing the spectra (eigenvalues, eigenspaces, etc.) of weight derived matrices. In particular, we introduce the frame operator $F = WW^\\top$, which gives us a spectral measure that describes how each feature allocates norm across eigenspaces. While previous tools could describe the pairwise interactions between features, spectral methods capture the global geometry (``how do all features interact?''). In toy models of superposition, we use this theory to prove that capacity saturation forces spectral localization: features collapse onto single eigenspaces, organize into tight frames, and admit discrete classification via association schemes, classifying all geometries from prior work (simplices, polygons, antiprisms). The spectral measure formalism applies to arbitrary weight matrices, enabling diagnosis of feature localization beyond toy settings. These results point toward a broader program: applying operator theory to interpretability.",
    "published": "2026-02-02T15:28:38Z",
    "updated": "2026-02-02T15:28:38Z",
    "authors": [
      "Georgi Ivanov",
      "Narmeen Oozeer",
      "Shivam Raval",
      "Tasana Pejovic",
      "Shriyash Upadhyay",
      "Amir Abdullah"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.SP",
      "stat.ML"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02224v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02224v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02220v1",
    "title": "LangMap: A Hierarchical Benchmark for Open-Vocabulary Goal Navigation",
    "summary": "The relationships between objects and language are fundamental to meaningful communication between humans and AI, and to practically useful embodied intelligence. We introduce HieraNav, a multi-granularity, open-vocabulary goal navigation task where agents interpret natural language instructions to reach targets at four semantic levels: scene, room, region, and instance. To this end, we present Language as a Map (LangMap), a large-scale benchmark built on real-world 3D indoor scans with comprehensive human-verified annotations and tasks spanning these levels. LangMap provides region labels, discriminative region descriptions, discriminative instance descriptions covering 414 object categories, and over 18K navigation tasks. Each target features both concise and detailed descriptions, enabling evaluation across different instruction styles. LangMap achieves superior annotation quality, outperforming GOAT-Bench by 23.8% in discriminative accuracy using four times fewer words. Comprehensive evaluations of zero-shot and supervised models on LangMap reveal that richer context and memory improve success, while long-tailed, small, context-dependent, and distant goals, as well as multi-goal completion, remain challenging. HieraNav and LangMap establish a rigorous testbed for advancing language-driven embodied navigation. Project: https://bo-miao.github.io/LangMap",
    "published": "2026-02-02T15:26:19Z",
    "updated": "2026-02-02T15:26:19Z",
    "authors": [
      "Bo Miao",
      "Weijia Liu",
      "Jun Luo",
      "Lachlan Shinnick",
      "Jian Liu",
      "Thomas Hamilton-Smith",
      "Yuhe Yang",
      "Zijie Wu",
      "Vanja Videnovic",
      "Feras Dayoub",
      "Anton van den Hengel"
    ],
    "primary_category": "cs.CV",
    "categories": [
      "cs.CV",
      "cs.RO"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02220v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02220v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02208v1",
    "title": "Towards AI Evaluation in Domain-Specific RAG Systems: The AgriHubi Case Study",
    "summary": "Large language models show promise for knowledge-intensive domains, yet their use in agriculture is constrained by weak grounding, English-centric training data, and limited real-world evaluation. These issues are amplified for low-resource languages, where high-quality domain documentation exists but remains difficult to access through general-purpose models. This paper presents AgriHubi, a domain-adapted retrieval-augmented generation (RAG) system for Finnish-language agricultural decision support. AgriHubi integrates Finnish agricultural documents with open PORO family models and combines explicit source grounding with user feedback to support iterative refinement. Developed over eight iterations and evaluated through two user studies, the system shows clear gains in answer completeness, linguistic accuracy, and perceived reliability. The results also reveal practical trade-offs between response quality and latency when deploying larger models. This study provides empirical guidance for designing and evaluating domain-specific RAG systems in low-resource language settings.",
    "published": "2026-02-02T15:15:24Z",
    "updated": "2026-02-02T15:15:24Z",
    "authors": [
      "Md. Toufique Hasan",
      "Ayman Asad Khan",
      "Mika Saari",
      "Vaishnavi Bankhele",
      "Pekka Abrahamsson"
    ],
    "primary_category": "cs.CL",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "cs.SE"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02208v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02208v1",
    "comment": "6 pages, 2 figures, submitted to MIPRO 2026",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02184v1",
    "title": "Malware Detection Through Memory Analysis",
    "summary": "This paper summarizes the research conducted for a malware detection project using the Canadian Institute for Cybersecurity's MalMemAnalysis-2022 dataset. The purpose of the project was to explore the effectiveness and efficiency of machine learning techniques for the task of binary classification (i.e., benign or malicious) as well as multi-class classification to further include three malware sub-types (i.e., benign, ransomware, spyware, or Trojan horse). The XGBoost model type was the final model selected for both tasks due to the trade-off between strong detection capability and fast inference speed. The binary classifier achieved a testing subset accuracy and F1 score of 99.98\\%, while the multi-class version reached an accuracy of 87.54\\% and an F1 score of 81.26\\%, with an average F1 score over the malware sub-types of 75.03\\%. In addition to the high modelling performance, XGBoost is also efficient in terms of classification speed. It takes about 37.3 milliseconds to classify 50 samples in sequential order in the binary setting and about 43.2 milliseconds in the multi-class setting. The results from this research project help advance the efforts made towards developing accurate and real-time obfuscated malware detectors for the goal of improving online privacy and safety. *This project was completed as part of ELEC 877 (AI for Cybersecurity) in the Winter 2024 term.",
    "published": "2026-02-02T14:50:50Z",
    "updated": "2026-02-02T14:50:50Z",
    "authors": [
      "Sarah Nassar"
    ],
    "primary_category": "cs.CR",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02184v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02184v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02179v1",
    "title": "SurvKAN: A Fully Parametric Survival Model Based on Kolmogorov-Arnold Networks",
    "summary": "Accurate prediction of time-to-event outcomes is critical for clinical decision-making, treatment planning, and resource allocation in modern healthcare. While classical survival models such as Cox remain widely adopted in standard practice, they rely on restrictive assumptions, including linear covariate relationships and proportional hazards over time, that often fail to capture real-world clinical dynamics. Recent deep learning approaches like DeepSurv and DeepHit offer improved expressivity but sacrifice interpretability, limiting clinical adoption where trust and transparency are paramount. Hybrid models incorporating Kolmogorov-Arnold Networks (KANs), such as CoxKAN, have begun to address this trade-off but remain constrained by the semi-parametric Cox framework. In this work we introduce SurvKAN, a fully parametric, time-continuous survival model based on KAN architectures that eliminates the proportional hazards constraint. SurvKAN treats time as an explicit input to a KAN that directly predicts the log-hazard function, enabling end-to-end training on the full survival likelihood. Our architecture preserves interpretability through learnable univariate functions that indicate how individual features influence risk over time. Extensive experiments on standard survival benchmarks demonstrate that SurvKAN achieves competitive or superior performance compared to classical and state-of-the-art baselines across concordance and calibration metrics. Additionally, interpretability analyses reveal clinically meaningful patterns that align with medical domain knowledge.",
    "published": "2026-02-02T14:49:14Z",
    "updated": "2026-02-02T14:49:14Z",
    "authors": [
      "Marina Mastroleo",
      "Alberto Archetti",
      "Federico Mastroleo",
      "Matteo Matteucci"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02179v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02179v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02173v1",
    "title": "Generalized Optimal Classification Trees: A Mixed-Integer Programming Approach",
    "summary": "Global optimization of decision trees is a long-standing challenge in combinatorial optimization, yet such models play an important role in interpretable machine learning. Although the problem has been investigated for several decades, only recent advances in discrete optimization have enabled practical algorithms for solving optimal classification tree problems on real-world datasets. Mixed-integer programming (MIP) offers a high degree of modeling flexibility, and we therefore propose a MIP-based framework for learning optimal classification trees under nonlinear performance metrics, such as the F1-score, that explicitly addresses class imbalance. To improve scalability, we develop problem-specific acceleration techniques, including a tailored branch-and-cut algorithm, an instance-reduction scheme, and warm-start strategies. We evaluate the proposed approach on 50 benchmark datasets. The computational results show that the framework can efficiently optimize nonlinear metrics while achieving strong predictive performance and reduced solution times compared with existing methods.",
    "published": "2026-02-02T14:46:01Z",
    "updated": "2026-02-02T14:46:01Z",
    "authors": [
      "Jiancheng Tu",
      "Wenqi Fan",
      "Zhibin Wu"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02173v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02173v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02136v1",
    "title": "Mitigating Safety Tax via Distribution-Grounded Refinement in Large Reasoning Models",
    "summary": "Safety alignment incurs safety tax that perturbs a large reasoning model's (LRM) general reasoning ability. Existing datasets used for safety alignment for an LRM are usually constructed by distilling safety reasoning traces and answers from an external LRM or human labeler. However, such reasoning traces and answers exhibit a distributional gap with the target LRM that needs alignment, and we conjecture such distributional gap is the culprit leading to significant degradation of reasoning ability of the target LRM. Driven by this hypothesis, we propose a safety alignment dataset construction method, dubbed DGR. DGR transforms and refines an existing out-of-distributional safety reasoning dataset to be aligned with the target's LLM inner distribution. Experimental results demonstrate that i) DGR effectively mitigates the safety tax while maintaining safety performance across all baselines, i.e., achieving \\textbf{+30.2\\%} on DirectRefusal and \\textbf{+21.2\\%} on R1-ACT improvement in average reasoning accuracy compared to Vanilla SFT; ii) the degree of reasoning degradation correlates with the extent of distribution shift, suggesting that bridging this gap is central to preserving capabilities. Furthermore, we find that safety alignment in LRMs may primarily function as a mechanism to activate latent knowledge, as a mere \\textbf{10} samples are sufficient for activating effective refusal behaviors. These findings not only emphasize the importance of distributional consistency but also provide insights into the activation mechanism of safety in reasoning models.",
    "published": "2026-02-02T14:18:48Z",
    "updated": "2026-02-02T14:18:48Z",
    "authors": [
      "Yingsha Xie",
      "Tiansheng Huang",
      "Enneng Yang",
      "Rui Min",
      "Wenjie Lu",
      "Xiaochun Cao",
      "Naiqiang Tan",
      "Li Shen"
    ],
    "primary_category": "cs.AI",
    "categories": [
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02136v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02136v1",
    "comment": "Code will be released soon",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02130v1",
    "title": "Eliminating Registration Bias in Synthetic CT Generation: A Physics-Based Simulation Framework",
    "summary": "Supervised synthetic CT generation from CBCT requires registered training pairs, yet perfect registration between separately acquired scans remains unattainable. This registration bias propagates into trained models and corrupts standard evaluation metrics. This may suggest that superior benchmark performance indicates better reproduction of registration artifacts rather than anatomical fidelity. We propose physics-based CBCT simulation to provide geometrically aligned training pairs by construction, combined with evaluation using geometric alignment metrics against input CBCT rather than biased ground truth. On two independent pelvic datasets, models trained on synthetic data achieved superior geometric alignment (Normalized Mutual Information: 0.31 vs 0.22) despite lower conventional intensity scores. Intensity metrics showed inverted correlations with clinical assessment for deformably registered data, while Normalized Mutual Information consistently predicted observer preference across registration methodologies (rho = 0.31, p < 0.001). Clinical observers preferred synthetic-trained outputs in 87% of cases, demonstrating that geometric fidelity, not intensity agreement with biased ground truth, aligns with clinical requirements.",
    "published": "2026-02-02T14:14:47Z",
    "updated": "2026-02-02T14:14:47Z",
    "authors": [
      "Lukas Zimmermann",
      "Michael Rauter",
      "Maximilian Schmid",
      "Dietmar Georg",
      "Barbara Knusl"
    ],
    "primary_category": "cs.CV",
    "categories": [
      "cs.CV"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02130v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02130v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "vision"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02110v1",
    "title": "An Empirical Study of World Model Quantization",
    "summary": "World models learn an internal representation of environment dynamics, enabling agents to simulate and reason about future states within a compact latent space for tasks such as planning, prediction, and inference. However, running world models rely on hevay computational cost and memory footprint, making model quantization essential for efficient deployment. To date, the effects of post-training quantization (PTQ) on world models remain largely unexamined. In this work, we present a systematic empirical study of world model quantization using DINO-WM as a representative case, evaluating diverse PTQ methods under both weight-only and joint weight-activation settings. We conduct extensive experiments on different visual planning tasks across a wide range of bit-widths, quantization granularities, and planning horizons up to 50 iterations. Our results show that quantization effects in world models extend beyond standard accuracy and bit-width trade-offs: group-wise weight quantization can stabilize low-bit rollouts, activation quantization granularity yields inconsistent benefits, and quantization sensitivity is highly asymmetric between encoder and predictor modules. Moreover, aggressive low-bit quantization significantly degrades the alignment between the planning objective and task success, leading to failures that cannot be remedied by additional optimization. These findings reveal distinct quantization-induced failure modes in world model-based planning and provide practical guidance for deploying quantized world models under strict computational constraints. The code will be available at https://github.com/huawei-noah/noah-research/tree/master/QuantWM.",
    "published": "2026-02-02T13:54:03Z",
    "updated": "2026-02-02T13:54:03Z",
    "authors": [
      "Zhongqian Fu",
      "Tianyi Zhao",
      "Kai Han",
      "Hang Zhou",
      "Xinghao Chen",
      "Yunhe Wang"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02110v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02110v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02100v1",
    "title": "The Verification Crisis: Expert Perceptions of GenAI Disinformation and the Case for Reproducible Provenance",
    "summary": "The growth of Generative Artificial Intelligence (GenAI) has shifted disinformation production from manual fabrication to automated, large-scale manipulation. This article presents findings from the first wave of a longitudinal expert perception survey (N=21) involving AI researchers, policymakers, and disinformation specialists. It examines the perceived severity of multimodal threats -- text, image, audio, and video -- and evaluates current mitigation strategies. Results indicate that while deepfake video presents immediate \"shock\" value, large-scale text generation poses a systemic risk of \"epistemic fragmentation\" and \"synthetic consensus,\" particularly in the political domain. The survey reveals skepticism about technical detection tools, with experts favoring provenance standards and regulatory frameworks despite implementation barriers. GenAI disinformation research requires reproducible methods. The current challenge is measurement: without standardized benchmarks and reproducibility checklists, tracking or countering synthetic media remains difficult. We propose treating information integrity as an infrastructure with rigor in data provenance and methodological reproducibility.",
    "published": "2026-02-02T13:45:12Z",
    "updated": "2026-02-02T13:45:12Z",
    "authors": [
      "Alexander Loth",
      "Martin Kappes",
      "Marc-Oliver Pahl"
    ],
    "primary_category": "cs.CY",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.SI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02100v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02100v1",
    "comment": "Accepted at ACM TheWebConf '26 Companion",
    "journal_ref": null,
    "doi": "10.1145/3774905.3795484",
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02099v1",
    "title": "Think Dense, Not Long: Dynamic Decoupled Conditional Advantage for Efficient Reasoning",
    "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) can elicit strong multi-step reasoning, yet it often encourages overly verbose traces. Moreover, naive length penalties in group-relative optimization can severely hurt accuracy. We attribute this failure to two structural issues: (i) Dilution of Length Baseline, where incorrect responses (with zero length reward) depress the group baseline and over-penalize correct solutions; and (ii) Difficulty-Penalty Mismatch, where a static penalty cannot adapt to problem difficulty, suppressing necessary reasoning on hard instances while leaving redundancy on easy ones. We propose Dynamic Decoupled Conditional Advantage (DDCA) to decouple efficiency optimization from correctness. DDCA computes length advantages conditionally within the correct-response cluster to eliminate baseline dilution, and dynamically scales the penalty strength using the group pass rate as a proxy for difficulty. Experiments on GSM8K, MATH500, AMC23, and AIME25 show that DDCA consistently improves the efficiency--accuracy trade-off relative to adaptive baselines, reducing generated tokens by approximately 60% on simpler tasks (e.g., GSM8K) versus over 20% on harder benchmarks (e.g., AIME25), thereby maintaining or improving accuracy. Code is available at https://github.com/alphadl/DDCA.",
    "published": "2026-02-02T13:43:52Z",
    "updated": "2026-02-02T13:43:52Z",
    "authors": [
      "Keqin Peng",
      "Yuanxin Ouyang",
      "Xuebo Liu",
      "Zhiliang Tian",
      "Ruijian Han",
      "Yancheng Yuan",
      "Liang Ding"
    ],
    "primary_category": "cs.CL",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02099v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02099v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02072v1",
    "title": "Calibrating Adaptive Smoothing Methods for Freeway Traffic Reconstruction",
    "summary": "The adaptive smoothing method (ASM) is a widely used approach for traffic state reconstruction. This article presents a Python implementation of ASM, featuring end-to-end calibration using real-world ground truth data. The calibration is formulated as a parameterized kernel optimization problem. The model is calibrated using data from a full-state observation testbed, with input from a sparse radar sensor network. The implementation is developed in PyTorch, enabling integration with various deep learning methods. We evaluate the results in terms of speed distribution, spatio-temporal error distribution, and spatial error to provide benchmark metrics for the traffic reconstruction problem. We further demonstrate the usability of the calibrated method across multiple freeways. Finally, we discuss the challenges of reproducibility in general traffic model calibration and the limitations of ASM. This article is reproducible and can serve as a benchmark for various freeway operation tasks.",
    "published": "2026-02-02T13:12:39Z",
    "updated": "2026-02-02T13:12:39Z",
    "authors": [
      "Junyi Ji",
      "Derek Gloudemans",
      "Gergely Zachr",
      "Matthew Nice",
      "William Barbour",
      "Daniel B. Work"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02072v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02072v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02071v1",
    "title": "BAPS: A Fine-Grained Low-Precision Scheme for Softmax in Attention via Block-Aware Precision reScaling",
    "summary": "As the performance gains from accelerating quantized matrix multiplication plateau, the softmax operation becomes the critical bottleneck in Transformer inference. This bottleneck stems from two hardware limitations: (1) limited data bandwidth between matrix and vector compute cores, and (2) the significant area cost of high-precision (FP32/16) exponentiation units (EXP2). To address these issues, we introduce a novel low-precision workflow that employs a specific 8-bit floating-point format (HiF8) and block-aware precision rescaling for softmax. Crucially, our algorithmic innovations make low-precision softmax feasible without the significant model accuracy loss that hampers direct low-precision approaches. Specifically, our design (i) halves the required data movement bandwidth by enabling matrix multiplication outputs constrained to 8-bit, and (ii) substantially reduces the EXP2 unit area by computing exponentiations in low (8-bit) precision. Extensive evaluation on language models and multi-modal models confirms the validity of our method. By alleviating the vector computation bottleneck, our work paves the way for doubling end-to-end inference throughput without increasing chip area, and offers a concrete co-design path for future low-precision hardware and software.",
    "published": "2026-02-02T13:12:18Z",
    "updated": "2026-02-02T13:12:18Z",
    "authors": [
      "Zisheng Ye",
      "Xiaoyu He",
      "Maoyuan Song",
      "Guoliang Qiu",
      "Chao Liao",
      "Chen Wu",
      "Yonggang Sun",
      "Zhichun Li",
      "Xiaoru Xie",
      "Yuanyong Luo",
      "Hu Liu",
      "Pinyan Lu",
      "Heng Liao"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02071v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02071v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02060v1",
    "title": "FiLoRA: Focus-and-Ignore LoRA for Controllable Feature Reliance",
    "summary": "Multimodal foundation models integrate heterogeneous signals across modalities, yet it remains poorly understood how their predictions depend on specific internal feature groups and whether such reliance can be deliberately controlled. Existing studies of shortcut and spurious behavior largely rely on post hoc analyses or feature removal, offering limited insight into whether reliance can be modulated without altering task semantics. We introduce FiLoRA (Focus-and-Ignore LoRA), an instruction-conditioned, parameter-efficient adaptation framework that enables explicit control over internal feature reliance while keeping the predictive objective fixed. FiLoRA decomposes adaptation into feature group-aligned LoRA modules and applies instruction-conditioned gating, allowing natural language instructions to act as computation-level control signals rather than task redefinitions. Across text--image and audio--visual benchmarks, we show that instruction-conditioned gating induces consistent and causal shifts in internal computation, selectively amplifying or suppressing core and spurious feature groups without modifying the label space or training objective. Further analyses demonstrate that FiLoRA yields improved robustness under spurious feature interventions, revealing a principled mechanism to regulate reliance beyond correlation-driven learning.",
    "published": "2026-02-02T13:00:57Z",
    "updated": "2026-02-02T13:00:57Z",
    "authors": [
      "Hyunsuk Chung",
      "Caren Han",
      "Yerin Choi",
      "Seungyeon Ji",
      "Jinwoo Kim",
      "Eun-Jung Holden",
      "Kyungreem Han"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02060v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02060v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02045v1",
    "title": "On Stability and Robustness of Diffusion Posterior Sampling for Bayesian Inverse Problems",
    "summary": "Diffusion models have recently emerged as powerful learned priors for Bayesian inverse problems (BIPs). Diffusion-based solvers rely on a presumed likelihood for the observations in BIPs to guide the generation process. However, the link between likelihood and recovery quality for BIPs is unclear in previous works. We bridge this gap by characterizing the posterior approximation error and proving the \\emph{stability} of the diffusion-based solvers. Meanwhile, an immediate result of our findings on stability demonstrates the lack of robustness in diffusion-based solvers, which remains unexplored. This can degrade performance when the presumed likelihood mismatches the unknown true data generation processes. To address this issue, we propose a simple yet effective solution, \\emph{robust diffusion posterior sampling}, which is provably \\emph{robust} and compatible with existing gradient-based posterior samplers. Empirical results on scientific inverse problems and natural image tasks validate the effectiveness and robustness of our method, showing consistent performance improvements under challenging likelihood misspecifications.",
    "published": "2026-02-02T12:47:15Z",
    "updated": "2026-02-02T12:47:15Z",
    "authors": [
      "Yiming Yang",
      "Xiaoyuan Cheng",
      "Yi He",
      "Kaiyu Li",
      "Wenxuan Yuan",
      "Zhuo Sun"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02045v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02045v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02044v1",
    "title": "Twinning Complex Networked Systems: Data-Driven Calibration of the mABCD Synthetic Graph Generator",
    "summary": "The increasing availability of relational data has contributed to a growing reliance on network-based representations of complex systems. Over time, these models have evolved to capture more nuanced properties, such as the heterogeneity of relationships, leading to the concept of multilayer networks. However, the analysis and evaluation of methods for these structures is often hindered by the limited availability of large-scale empirical data. As a result, graph generators are commonly used as a workaround, albeit at the cost of introducing systematic biases. In this paper, we address the inverse-generator problem by inferring the configuration parameters of a multilayer network generator, mABCD, from a real-world system. Our goal is to identify parameter settings that enable the generator to produce synthetic networks that act as digital twins of the original structure. We propose a method for estimating matching configurations and for quantifying the associated error. Our results demonstrate that this task is non-trivial, as strong interdependencies between configuration parameters weaken independent estimation and instead favour a joint-prediction approach.",
    "published": "2026-02-02T12:40:19Z",
    "updated": "2026-02-02T12:40:19Z",
    "authors": [
      "Piotr Brdka",
      "Micha Czuba",
      "Bogumi Kamiski",
      "ukasz Kraiski",
      "Katarzyna Musial",
      "Pawe Praat",
      "Mateusz Stolarski"
    ],
    "primary_category": "cs.SI",
    "categories": [
      "cs.SI",
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02044v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02044v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "manufacturing"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02043v1",
    "title": "Auto-Comp: An Automated Pipeline for Scalable Compositional Probing of Contrastive Vision-Language Models",
    "summary": "Modern Vision-Language Models (VLMs) exhibit a critical flaw in compositional reasoning, often confusing \"a red cube and a blue sphere\" with \"a blue cube and a red sphere\". Disentangling the visual and linguistic roots of these failures is a fundamental challenge for robust evaluation. To enable fine-grained, controllable analysis, we introduce Auto-Comp, a fully automated and synthetic pipeline for generating scalable benchmarks. Its controllable nature is key to dissecting and isolating different reasoning skills. Auto-Comp generates paired images from Minimal (e.g., \"a monitor to the left of a bicycle on a white background\") and LLM-generated Contextual captions (e.g., \"In a brightly lit photography studio, a monitor is positioned to the left of a bicycle\"), allowing a controlled A/B test to disentangle core binding ability from visio-linguistic complexity. Our evaluation of 20 VLMs on novel benchmarks for color binding and spatial relations reveals universal compositional failures in both CLIP and SigLIP model families. Crucially, our novel \"Confusion Benchmark\" reveals a deeper flaw beyond simple attribute swaps: models are highly susceptible to low-entropy distractors (e.g., repeated objects or colors), demonstrating their compositional failures extend beyond known bag-of-words limitations. we uncover a surprising trade-off: visio-linguistic context, which provides global scene cues, aids spatial reasoning but simultaneously hinders local attribute binding by introducing visual clutter. We release the Auto-Comp pipeline to facilitate future benchmark creation, alongside all our generated benchmarks (https://huggingface.co/AutoComp).",
    "published": "2026-02-02T12:39:39Z",
    "updated": "2026-02-02T12:39:39Z",
    "authors": [
      "Cristian Sbrolli",
      "Matteo Matteucci",
      "Toshihiko Yamasaki"
    ],
    "primary_category": "cs.CV",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02043v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02043v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02020v1",
    "title": "Scale-covariant spiking wavelets",
    "summary": "We establish a theoretical connection between wavelet transforms and spiking neural networks through scale-space theory. We rely on the scale-covariant guarantees in the leaky integrate-and-fire neurons to implement discrete mother wavelets that approximate continuous wavelets. A reconstruction experiment demonstrates the feasibility of the approach and warrants further analysis to mitigate current approximation errors. Our work suggests a novel spiking signal representation that could enable more energy-efficient signal processing algorithms.",
    "published": "2026-02-02T12:16:44Z",
    "updated": "2026-02-02T12:16:44Z",
    "authors": [
      "Jens Egholm Pedersen",
      "Tony Lindeberg",
      "Peter Gerstoft"
    ],
    "primary_category": "cs.NE",
    "categories": [
      "cs.NE",
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02020v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02020v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02002v1",
    "title": "UniDriveDreamer: A Single-Stage Multimodal World Model for Autonomous Driving",
    "summary": "World models have demonstrated significant promise for data synthesis in autonomous driving. However, existing methods predominantly concentrate on single-modality generation, typically focusing on either multi-camera video or LiDAR sequence synthesis. In this paper, we propose UniDriveDreamer, a single-stage unified multimodal world model for autonomous driving, which directly generates multimodal future observations without relying on intermediate representations or cascaded modules. Our framework introduces a LiDAR-specific variational autoencoder (VAE) designed to encode input LiDAR sequences, alongside a video VAE for multi-camera images. To ensure cross-modal compatibility and training stability, we propose Unified Latent Anchoring (ULA), which explicitly aligns the latent distributions of the two modalities. The aligned features are fused and processed by a diffusion transformer that jointly models their geometric correspondence and temporal evolution. Additionally, structured scene layout information is projected per modality as a conditioning signal to guide the synthesis. Extensive experiments demonstrate that UniDriveDreamer outperforms previous state-of-the-art methods in both video and LiDAR generation, while also yielding measurable improvements in downstream",
    "published": "2026-02-02T12:02:27Z",
    "updated": "2026-02-02T12:02:27Z",
    "authors": [
      "Guosheng Zhao",
      "Yaozeng Wang",
      "Xiaofeng Wang",
      "Zheng Zhu",
      "Tingdong Yu",
      "Guan Huang",
      "Yongchen Zai",
      "Ji Jiao",
      "Changliang Xue",
      "Xiaole Wang",
      "Zhen Yang",
      "Futang Zhu",
      "Xingang Wang"
    ],
    "primary_category": "cs.CV",
    "categories": [
      "cs.CV"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02002v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02002v1",
    "comment": "16 pages, 7 figures",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.02000v1",
    "title": "SurfSplat: Conquering Feedforward 2D Gaussian Splatting with Surface Continuity Priors",
    "summary": "Reconstructing 3D scenes from sparse images remains a challenging task due to the difficulty of recovering accurate geometry and texture without optimization. Recent approaches leverage generalizable models to generate 3D scenes using 3D Gaussian Splatting (3DGS) primitive. However, they often fail to produce continuous surfaces and instead yield discrete, color-biased point clouds that appear plausible at normal resolution but reveal severe artifacts under close-up views. To address this issue, we present SurfSplat, a feedforward framework based on 2D Gaussian Splatting (2DGS) primitive, which provides stronger anisotropy and higher geometric precision. By incorporating a surface continuity prior and a forced alpha blending strategy, SurfSplat reconstructs coherent geometry together with faithful textures. Furthermore, we introduce High-Resolution Rendering Consistency (HRRC), a new evaluation metric designed to evaluate high-resolution reconstruction quality. Extensive experiments on RealEstate10K, DL3DV, and ScanNet demonstrate that SurfSplat consistently outperforms prior methods on both standard metrics and HRRC, establishing a robust solution for high-fidelity 3D reconstruction from sparse inputs. Project page: https://hebing-sjtu.github.io/SurfSplat-website/",
    "published": "2026-02-02T11:58:26Z",
    "updated": "2026-02-02T11:58:26Z",
    "authors": [
      "Bing He",
      "Jingnan Gao",
      "Yunuo Chen",
      "Ning Cao",
      "Gang Chen",
      "Zhengxue Cheng",
      "Li Song",
      "Wenjun Zhang"
    ],
    "primary_category": "cs.CV",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.02000v1",
    "pdf_url": "https://arxiv.org/pdf/2602.02000v1",
    "comment": "ICLR 2026",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "vision"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01995v1",
    "title": "Thinking Like a Doctor: Conversational Diagnosis through the Exploration of Diagnostic Knowledge Graphs",
    "summary": "Conversational diagnosis requires multi-turn history-taking, where an agent asks clarifying questions to refine differential diagnoses under incomplete information. Existing approaches often rely on the parametric knowledge of a model or assume that patients provide rich and concrete information, which is unrealistic. To address these limitations, we propose a conversational diagnosis system that explores a diagnostic knowledge graph to reason in two steps: (i) generating diagnostic hypotheses from the dialogue context, and (ii) verifying hypotheses through clarifying questions, which are repeated until a final diagnosis is reached. Since evaluating the system requires a realistic patient simulator that responds to the system's questions, we adopt a well-established simulator along with patient profiles from MIMIC-IV. We further adapt it to describe symptoms vaguely to reflect real-world patients during early clinical encounters. Experiments show improved diagnostic accuracy and efficiency over strong baselines, and evaluations by physicians support the realism of our simulator and the clinical utility of the generated questions. Our code will be released upon publication.",
    "published": "2026-02-02T11:56:36Z",
    "updated": "2026-02-02T11:56:36Z",
    "authors": [
      "Jeongmoon Won",
      "Seungwon Kook",
      "Yohan Jo"
    ],
    "primary_category": "cs.AI",
    "categories": [
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01995v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01995v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01996v1",
    "title": "Optimizing Tensor Train Decomposition in DNNs for RISC-V Architectures Using Design Space Exploration and Compiler Optimizations",
    "summary": "Deep neural networks (DNNs) have become indispensable in many real-life applications like natural language processing, and autonomous systems. However, deploying DNNs on resource-constrained devices, e.g., in RISC-V platforms, remains challenging due to the high computational and memory demands of fully connected (FC) layers, which dominate resource consumption. Low-rank factorization (LRF) offers an effective approach to compressing FC layers, but the vast design space of LRF solutions involves complex trade-offs among FLOPs, memory size, inference time, and accuracy, making the LRF process complex and time-consuming. This paper introduces an end-to-end LRF design space exploration methodology and a specialized design tool for optimizing FC layers on RISC-V processors. Using Tensor Train Decomposition (TTD) offered by TensorFlow T3F library, the proposed work prunes the LRF design space by excluding first, inefficient decomposition shapes and second, solutions with poor inference performance on RISC-V architectures. Compiler optimizations are then applied to enhance custom T3F layer performance, minimizing inference time and boosting computational efficiency. On average, our TT-decomposed layers run 3x faster than IREE and 8x faster than Pluto on the same compressed model. This work provides an efficient solution for deploying DNNs on edge and embedded devices powered by RISC-V architectures.",
    "published": "2026-02-02T11:56:36Z",
    "updated": "2026-02-02T11:56:36Z",
    "authors": [
      "Theologos Anthimopoulos",
      "Milad Kokhazadeh",
      "Vasilios Kelefouras",
      "Benjamin Himpel",
      "Georgios Keramidas"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.AR",
      "cs.MS"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01996v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01996v1",
    "comment": "36 pages, 16 figures, this is the author-accepted version of the article published in ACM Transactions on Embedded Computing Systems (TECS), Vol. 24, No. 6",
    "journal_ref": "ACM Transactions on Embedded Computing Systems 24, 6, Article 171 (October 2025), 34 pages",
    "doi": "10.1145/3768624",
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01988v1",
    "title": "Stochastic Interpolants in Hilbert Spaces",
    "summary": "Although diffusion models have successfully extended to function-valued data, stochastic interpolants -- which offer a flexible way to bridge arbitrary distributions -- remain limited to finite-dimensional settings. This work bridges this gap by establishing a rigorous framework for stochastic interpolants in infinite-dimensional Hilbert spaces. We provide comprehensive theoretical foundations, including proofs of well-posedness and explicit error bounds. We demonstrate the effectiveness of the proposed framework for conditional generation, focusing particularly on complex PDE-based benchmarks. By enabling generative bridges between arbitrary functional distributions, our approach achieves state-of-the-art results, offering a powerful, general-purpose tool for scientific discovery.",
    "published": "2026-02-02T11:44:34Z",
    "updated": "2026-02-02T11:44:34Z",
    "authors": [
      "James Boran Yu",
      "RuiKang OuYang",
      "Julien Horwood",
      "Jos Miguel Hernndez-Lobato"
    ],
    "primary_category": "stat.ML",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01988v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01988v1",
    "comment": "8 pages, 1 figure, 2 tables",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01951v1",
    "title": "Enabling Progressive Whole-slide Image Analysis with Multi-scale Pyramidal Network",
    "summary": "Multiple-instance Learning (MIL) is commonly used to undertake computational pathology (CPath) tasks, and the use of multi-scale patches allows diverse features across scales to be learned. Previous studies using multi-scale features in clinical applications rely on multiple inputs across magnifications with late feature fusion, which does not retain the link between features across scales while the inputs are dependent on arbitrary, manufacturer-defined magnifications, being inflexible and computationally expensive. In this paper, we propose the Multi-scale Pyramidal Network (MSPN), which is plug-and-play over attention-based MIL that introduces progressive multi-scale analysis on WSI. Our MSPN consists of (1) grid-based remapping that uses high magnification features to derive coarse features and (2) the coarse guidance network (CGN) that learns coarse contexts. We benchmark MSPN as an add-on module to 4 attention-based frameworks using 4 clinically relevant tasks across 3 types of foundation model, as well as the pre-trained MIL framework. We show that MSPN consistently improves MIL across the compared configurations and tasks, while being lightweight and easy-to-use.",
    "published": "2026-02-02T11:00:07Z",
    "updated": "2026-02-02T11:00:07Z",
    "authors": [
      "Shuyang Wu",
      "Yifu Qiu",
      "Ines P. Nearchou",
      "Sandrine Prost",
      "Jonathan A Fallowfield",
      "Hakan Bilen",
      "Timothy J Kendall"
    ],
    "primary_category": "cs.CV",
    "categories": [
      "cs.CV"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01951v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01951v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01916v1",
    "title": "ForSim: Stepwise Forward Simulation for Traffic Policy Fine-Tuning",
    "summary": "As the foundation of closed-loop training and evaluation in autonomous driving, traffic simulation still faces two fundamental challenges: covariate shift introduced by open-loop imitation learning and limited capacity to reflect the multimodal behaviors observed in real-world traffic. Although recent frameworks such as RIFT have partially addressed these issues through group-relative optimization, their forward simulation procedures remain largely non-reactive, leading to unrealistic agent interactions within the virtual domain and ultimately limiting simulation fidelity. To address these issues, we propose ForSim, a stepwise closed-loop forward simulation paradigm. At each virtual timestep, the traffic agent propagates the virtual candidate trajectory that best spatiotemporally matches the reference trajectory through physically grounded motion dynamics, thereby preserving multimodal behavioral diversity while ensuring intra-modality consistency. Other agents are updated with stepwise predictions, yielding coherent and interaction-aware evolution. When incorporated into the RIFT traffic simulation framework, ForSim operates in conjunction with group-relative optimization to fine-tune traffic policy. Extensive experiments confirm that this integration consistently improves safety while maintaining efficiency, realism, and comfort. These results underscore the importance of modeling closed-loop multimodal interactions within forward simulation and enhance the fidelity and reliability of traffic simulation for autonomous driving. Project Page: https://currychen77.github.io/ForSim/",
    "published": "2026-02-02T10:20:11Z",
    "updated": "2026-02-02T10:20:11Z",
    "authors": [
      "Keyu Chen",
      "Wenchao Sun",
      "Hao Cheng",
      "Zheng Fu",
      "Sifa Zheng"
    ],
    "primary_category": "cs.RO",
    "categories": [
      "cs.RO"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01916v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01916v1",
    "comment": "Accepted by ICRA 2026",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01899v1",
    "title": "Multi-Task Learning for Robot Perception with Imbalanced Data",
    "summary": "Multi-task problem solving has been shown to improve the accuracy of the individual tasks, which is an important feature for robots, as they have a limited resource. However, when the number of labels for each task is not equal, namely imbalanced data exist, a problem may arise due to insufficient number of samples, and labeling is not very easy for mobile robots in every environment. We propose a method that can learn tasks even in the absence of the ground truth labels for some of the tasks. We also provide a detailed analysis of the proposed method. An interesting finding is related to the interaction of the tasks. We show a methodology to find out which tasks can improve the performance of other tasks. We investigate this by training the teacher network with the task outputs such as depth as inputs. We further provide empirical evidence when trained with a small amount of data. We use semantic segmentation and depth estimation tasks on different datasets, NYUDv2 and Cityscapes.",
    "published": "2026-02-02T10:05:59Z",
    "updated": "2026-02-02T10:05:59Z",
    "authors": [
      "Ozgur Erkent"
    ],
    "primary_category": "cs.RO",
    "categories": [
      "cs.RO",
      "cs.CV"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01899v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01899v1",
    "comment": "16 pages",
    "journal_ref": "Ordu niversitesi Bilim ve Teknoloji Dergisi, 15(2), 151-164 (2025)",
    "doi": "10.54370/ordubtd.1526381",
    "relevance_score": 1.2,
    "matched_areas": [
      "vision"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01884v1",
    "title": "Entropy-Guided Data-Efficient Training for Multimodal Reasoning Reward Models",
    "summary": "Multimodal reward models are crucial for aligning multimodal large language models with human preferences. Recent works have incorporated reasoning capabilities into these models, achieving promising results. However, training these models suffers from two critical challenges: (1) the inherent noise in preference datasets, which degrades model performance, and (2) the inefficiency of conventional training methods, which ignore the differences in sample difficulty. In this paper, we identify a strong correlation between response entropy and accuracy, indicating that entropy can serve as a reliable and unsupervised proxy for annotation noise and sample difficulty. Based on this insight, we propose a novel Entropy-Guided Training (EGT) approach for multimodal reasoning reward models, which combines two strategies: (1) entropy-guided data curation to mitigate the impact of unreliable samples, and (2) an entropy-guided training strategy that progressively introduces more complex examples. Extensive experiments across three benchmarks show that the EGT-trained model consistently outperforms state-of-the-art multimodal reward models.",
    "published": "2026-02-02T09:58:24Z",
    "updated": "2026-02-02T09:58:24Z",
    "authors": [
      "Shidong Yang",
      "Tongwen Huang",
      "Hao Wen",
      "Yong Wang",
      "Li Chen",
      "Xiangxiang Chu"
    ],
    "primary_category": "cs.AI",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01884v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01884v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01877v1",
    "title": "Autocorrelated Optimize-via-Estimate: Predict-then-Optimize versus Finite-sample Optimal",
    "summary": "Models that directly optimize for out-of-sample performance in the finite-sample regime have emerged as a promising alternative to traditional estimate-then-optimize approaches in data-driven optimization. In this work, we compare their performance in the context of autocorrelated uncertainties, specifically, under a Vector Autoregressive Moving Average VARMA(p,q) process. We propose an autocorrelated Optimize-via-Estimate (A-OVE) model that obtains an out-of-sample optimal solution as a function of sufficient statistics, and propose a recursive form for computing its sufficient statistics. We evaluate these models on a portfolio optimization problem with trading costs. A-OVE achieves low regret relative to a perfect information oracle, outperforming predict-then-optimize machine learning benchmarks. Notably, machine learning models with higher accuracy can have poorer decision quality, echoing the growing literature in data-driven optimization. Performance is retained under small mis-specification.",
    "published": "2026-02-02T09:49:51Z",
    "updated": "2026-02-02T09:49:51Z",
    "authors": [
      "Zichun Wang",
      "Gar Goei Loke",
      "Ruiting Zuo"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "math.OC"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01877v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01877v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01845v1",
    "title": "No Generation without Representation: Efficient Causal Protein Language Models Enable Zero-Shot Fitness Estimation",
    "summary": "Protein language models (PLMs) face a fundamental divide: masked language models (MLMs) excel at fitness prediction while causal models enable generation, forcing practitioners to maintain separate architectures. We introduce \\textbf{Proust}, a 309M-parameter causal PLM that bridges this gap through architectural innovations adapted from recent LLM research, including grouped-query attention with shared K/V projections, cross-layer value residuals, and depthwise causal convolutions. Trained on 33B tokens in 40 B200 GPU-hours, Proust achieves Spearman $= 0.390$ on ProteinGym substitutions, competitive with MLMs requiring 50--200$\\times$ the compute. On indels, Proust sets a new state-of-the-art, outperforming models up to 20$\\times$ larger. On EVEREST viral fitness benchmarks, it approaches structure-aware methods using sequence alone. These powerful representations position Proust in a sweet spot as it also retains native generative capabilities that MLMs lack by design. Interpretability analysis reveals that per-position entropy variance predicts, to an extent, when retrieval augmentation helps and hurts. Such insights can grow in both quantity and quality at scale and inform capabilities such as test-time scaling. Code and weights are available at https://github.com/Furkan9015/proust-inference",
    "published": "2026-02-02T09:17:09Z",
    "updated": "2026-02-02T09:17:09Z",
    "authors": [
      "Furkan Eris"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "q-bio.QM"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01845v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01845v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01844v1",
    "title": "CloDS: Visual-Only Unsupervised Cloth Dynamics Learning in Unknown Conditions",
    "summary": "Deep learning has demonstrated remarkable capabilities in simulating complex dynamic systems. However, existing methods require known physical properties as supervision or inputs, limiting their applicability under unknown conditions. To explore this challenge, we introduce Cloth Dynamics Grounding (CDG), a novel scenario for unsupervised learning of cloth dynamics from multi-view visual observations. We further propose Cloth Dynamics Splatting (CloDS), an unsupervised dynamic learning framework designed for CDG. CloDS adopts a three-stage pipeline that first performs video-to-geometry grounding and then trains a dynamics model on the grounded meshes. To cope with large non-linear deformations and severe self-occlusions during grounding, we introduce a dual-position opacity modulation that supports bidirectional mapping between 2D observations and 3D geometry via mesh-based Gaussian splatting in video-to-geometry grounding stage. It jointly considers the absolute and relative position of Gaussian components. Comprehensive experimental evaluations demonstrate that CloDS effectively learns cloth dynamics from visual data while maintaining strong generalization capabilities for unseen configurations. Our code is available at https://github.com/whynot-zyl/CloDS. Visualization results are available at https://github.com/whynot-zyl/CloDS_video}.%\\footnote{As in this example.",
    "published": "2026-02-02T09:16:16Z",
    "updated": "2026-02-02T09:16:16Z",
    "authors": [
      "Yuliang Zhan",
      "Jian Li",
      "Wenbing Huang",
      "Wenbing Huang",
      "Yang Liu",
      "Hao Sun"
    ],
    "primary_category": "cs.CV",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01844v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01844v1",
    "comment": "ICLR 2026",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01842v1",
    "title": "Prism: Efficient Test-Time Scaling via Hierarchical Search and Self-Verification for Discrete Diffusion Language Models",
    "summary": "Inference-time compute has re-emerged as a practical way to improve LLM reasoning. Most test-time scaling (TTS) algorithms rely on autoregressive decoding, which is ill-suited to discrete diffusion language models (dLLMs) due to their parallel decoding over the entire sequence. As a result, developing effective and efficient TTS methods to unlock dLLMs' full generative potential remains an underexplored challenge. To address this, we propose Prism (Pruning, Remasking, and Integrated Self-verification Method), an efficient TTS framework for dLLMs that (i) performs Hierarchical Trajectory Search (HTS) which dynamically prunes and reallocates compute in an early-to-mid denoising window, (ii) introduces Local branching with partial remasking to explore diverse implementations while preserving high-confidence tokens, and (iii) replaces external verifiers with Self-Verified Feedback (SVF) obtained via self-evaluation prompts on intermediate completions. Across four mathematical reasoning and code generation benchmarks on three dLLMs, including LLaDA 8B Instruct, Dream 7B Instruct, and LLaDA 2.0-mini, our Prism achieves a favorable performance-efficiency trade-off, matching best-of-N performance with substantially fewer function evaluations (NFE). The code is released at https://github.com/viiika/Prism.",
    "published": "2026-02-02T09:14:51Z",
    "updated": "2026-02-02T09:14:51Z",
    "authors": [
      "Jinbin Bai",
      "Yixuan Li",
      "Yuchen Zhu",
      "Yi Xin",
      "Qingyu Shi",
      "Aosong Feng",
      "Xiaohong Liu",
      "Molei Tao",
      "Jianru Xue",
      "Xiangtai Li",
      "Ming-Hsuan Yang"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01842v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01842v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01836v1",
    "title": "Efficient Cross-Country Data Acquisition Strategy for ADAS via Street-View Imagery",
    "summary": "Deploying ADAS and ADS across countries remains challenging due to differences in legislation, traffic infrastructure, and visual conventions, which introduce domain shifts that degrade perception performance. Traditional cross-country data collection relies on extensive on-road driving, making it costly and inefficient to identify representative locations. To address this, we propose a street-view-guided data acquisition strategy that leverages publicly available imagery to identify places of interest (POI). Two POI scoring methods are introduced: a KNN-based feature distance approach using a vision foundation model, and a visual-attribution approach using a vision-language model. To enable repeatable evaluation, we adopt a collect-detect protocol and construct a co-located dataset by pairing the Zenseact Open Dataset with Mapillary street-view images. Experiments on traffic sign detection, a task particularly sensitive to cross-country variations in sign appearance, show that our approach achieves performance comparable to random sampling while using only half of the target-domain data. We further provide cost estimations for full-country analysis, demonstrating that large-scale street-view processing remains economically feasible. These results highlight the potential of street-view-guided data acquisition for efficient and cost-effective cross-country model adaptation.",
    "published": "2026-02-02T09:09:07Z",
    "updated": "2026-02-02T09:09:07Z",
    "authors": [
      "Yin Wu",
      "Daniel Slieter",
      "Carl Esselborn",
      "Ahmed Abouelazm",
      "Tsung Yuan Tseng",
      "J. Marius Zllner"
    ],
    "primary_category": "cs.CV",
    "categories": [
      "cs.CV"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01836v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01836v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01834v1",
    "title": "Concept-Based Dictionary Learning for Inference-Time Safety in Vision Language Action Models",
    "summary": "Vision Language Action (VLA) models close the perception action loop by translating multimodal instructions into executable behaviors, but this very capability magnifies safety risks: jailbreaks that merely yield toxic text in LLMs can trigger unsafe physical actions in embodied systems. Existing defenses alignment, filtering, or prompt hardening intervene too late or at the wrong modality, leaving fused representations exploitable. We introduce a concept-based dictionary learning framework for inference-time safety control. By constructing sparse, interpretable dictionaries from hidden activations, our method identifies harmful concept directions and applies threshold-based interventions to suppress or block unsafe activations. Experiments on Libero-Harm, BadRobot, RoboPair, and IS-Bench show that our approach achieves state-of-the-art defense performance, cutting attack success rates by over 70\\% while maintaining task success. Crucially, the framework is plug-in and model-agnostic, requiring no retraining and integrating seamlessly with diverse VLAs. To our knowledge, this is the first inference-time concept-based safety method for embodied systems, advancing both interpretability and safe deployment of VLA models.",
    "published": "2026-02-02T09:06:43Z",
    "updated": "2026-02-02T09:06:43Z",
    "authors": [
      "Siqi Wen",
      "Shu Yang",
      "Shaopeng Fu",
      "Jingfeng Zhang",
      "Lijie Hu",
      "Di Wang"
    ],
    "primary_category": "cs.RO",
    "categories": [
      "cs.RO"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01834v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01834v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01825v1",
    "title": "Learning Sequential Decisions from Multiple Sources via Group-Robust Markov Decision Processes",
    "summary": "We often collect data from multiple sites (e.g., hospitals) that share common structure but also exhibit heterogeneity. This paper aims to learn robust sequential decision-making policies from such offline, multi-site datasets. To model cross-site uncertainty, we study distributionally robust MDPs with a group-linear structure: all sites share a common feature map, and both the transition kernels and expected reward functions are linear in these shared features. We introduce feature-wise (d-rectangular) uncertainty sets, which preserve tractable robust Bellman recursions while maintaining key cross-site structure. Building on this, we then develop an offline algorithm based on pessimistic value iteration that includes: (i) per-site ridge regression for Bellman targets, (ii) feature-wise worst-case (row-wise minimization) aggregation, and (iii) a data-dependent pessimism penalty computed from the diagonals of the inverse design matrices. We further propose a cluster-level extension that pools similar sites to improve sample efficiency, guided by prior knowledge of site similarity. Under a robust partial coverage assumption, we prove a suboptimality bound for the resulting policy. Overall, our framework addresses multi-site learning with heterogeneous data sources and provides a principled approach to robust planning without relying on strong state-action rectangularity assumptions.",
    "published": "2026-02-02T08:58:55Z",
    "updated": "2026-02-02T08:58:55Z",
    "authors": [
      "Mingyuan Xu",
      "Zongqi Xia",
      "Tianxi Cai",
      "Doudou Zhou",
      "Nian Si"
    ],
    "primary_category": "stat.ME",
    "categories": [
      "stat.ME",
      "cs.LG",
      "math.OC",
      "stat.ML"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01825v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01825v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01812v1",
    "title": "LDRNet: Large Deformation Registration Model for Chest CT Registration",
    "summary": "Most of the deep learning based medical image registration algorithms focus on brain image registration tasks.Compared with brain registration, the chest CT registration has larger deformation, more complex background and region over-lap. In this paper, we propose a fast unsupervised deep learning method, LDRNet, for large deformation image registration of chest CT images. We first predict a coarse resolution registration field, then refine it from coarse to fine. We propose two innovative technical components: 1) a refine block that is used to refine the registration field in different resolutions, 2) a rigid block that is used to learn transformation matrix from high-level features. We train and evaluate our model on the private dataset and public dataset SegTHOR. We compare our performance with state-of-the-art traditional registration methods as well as deep learning registration models VoxelMorph, RCN, and LapIRN. The results demonstrate that our model achieves state-of-the-art performance for large deformation images registration and is much faster.",
    "published": "2026-02-02T08:44:53Z",
    "updated": "2026-02-02T08:44:53Z",
    "authors": [
      "Cheng Wang",
      "Qiyu Gao",
      "Fandong Zhang",
      "Shu Zhang",
      "Yizhou Yu"
    ],
    "primary_category": "cs.CV",
    "categories": [
      "cs.CV"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01812v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01812v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01811v1",
    "title": "From Knowing to Doing Precisely: A General Self-Correction and Termination Framework for VLA models",
    "summary": "While vision-language-action (VLA) models for embodied agents integrate perception, reasoning, and control, they remain constrained by two critical weaknesses: first, during grasping tasks, the action tokens generated by the language model often exhibit subtle spatial deviations from the target object, resulting in grasp failures; second, they lack the ability to reliably recognize task completion, which leads to redundant actions and frequent timeout errors. To address these challenges and enhance robustness, we propose a lightweight, training-free framework, VLA-SCT. This framework operates as a self-correcting control loop, combining data-driven action refinement with conditional logic for termination. Consequently, compared to baseline approaches, our method achieves consistent improvements across all datasets in the LIBERO benchmark, significantly increasing the success rate of fine manipulation tasks and ensuring accurate task completion, thereby promoting the deployment of more reliable VLA agents in complex, unstructured environments.",
    "published": "2026-02-02T08:44:40Z",
    "updated": "2026-02-02T08:44:40Z",
    "authors": [
      "Wentao Zhang",
      "Aolan Sun",
      "Wentao Mo",
      "Xiaoyang Qu",
      "Yuxin Zheng",
      "Jianzong Wang"
    ],
    "primary_category": "cs.RO",
    "categories": [
      "cs.RO"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01811v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01811v1",
    "comment": "Accepted to 2026 IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP 2026)",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01801v1",
    "title": "Fast Autoregressive Video Diffusion and World Models with Temporal Cache Compression and Sparse Attention",
    "summary": "Autoregressive video diffusion models enable streaming generation, opening the door to long-form synthesis, video world models, and interactive neural game engines. However, their core attention layers become a major bottleneck at inference time: as generation progresses, the KV cache grows, causing both increasing latency and escalating GPU memory, which in turn restricts usable temporal context and harms long-range consistency. In this work, we study redundancy in autoregressive video diffusion and identify three persistent sources: near-duplicate cached keys across frames, slowly evolving (largely semantic) queries/keys that make many attention computations redundant, and cross-attention over long prompts where only a small subset of tokens matters per frame. Building on these observations, we propose a unified, training-free attention framework for autoregressive diffusion: TempCache compresses the KV cache via temporal correspondence to bound cache growth; AnnCA accelerates cross-attention by selecting frame-relevant prompt tokens using fast approximate nearest neighbor (ANN) matching; and AnnSA sparsifies self-attention by restricting each query to semantically matched keys, also using a lightweight ANN. Together, these modules reduce attention, compute, and memory and are compatible with existing autoregressive diffusion backbones and world models. Experiments demonstrate up to x5--x10 end-to-end speedups while preserving near-identical visual quality and, crucially, maintaining stable throughput and nearly constant peak GPU memory usage over long rollouts, where prior methods progressively slow down and suffer from increasing memory usage.",
    "published": "2026-02-02T08:31:21Z",
    "updated": "2026-02-02T08:31:21Z",
    "authors": [
      "Dvir Samuel",
      "Issar Tzachor",
      "Matan Levy",
      "Micahel Green",
      "Gal Chechik",
      "Rami Ben-Ari"
    ],
    "primary_category": "cs.CV",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01801v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01801v1",
    "comment": "Project Page: https://dvirsamuel.github.io/fast-auto-regressive-video/",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01780v1",
    "title": "DDP-WM: Disentangled Dynamics Prediction for Efficient World Models",
    "summary": "World models are essential for autonomous robotic planning. However, the substantial computational overhead of existing dense Transformerbased models significantly hinders real-time deployment. To address this efficiency-performance bottleneck, we introduce DDP-WM, a novel world model centered on the principle of Disentangled Dynamics Prediction (DDP). We hypothesize that latent state evolution in observed scenes is heterogeneous and can be decomposed into sparse primary dynamics driven by physical interactions and secondary context-driven background updates. DDP-WM realizes this decomposition through an architecture that integrates efficient historical processing with dynamic localization to isolate primary dynamics. By employing a crossattention mechanism for background updates, the framework optimizes resource allocation and provides a smooth optimization landscape for planners. Extensive experiments demonstrate that DDP-WM achieves significant efficiency and performance across diverse tasks, including navigation, precise tabletop manipulation, and complex deformable or multi-body interactions. Specifically, on the challenging Push-T task, DDP-WM achieves an approximately 9 times inference speedup and improves the MPC success rate from 90% to98% compared to state-of-the-art dense models. The results establish a promising path for developing efficient, high-fidelity world models. Codes will be available at https://github.com/HCPLabSYSU/DDP-WM.",
    "published": "2026-02-02T08:04:25Z",
    "updated": "2026-02-02T08:04:25Z",
    "authors": [
      "Shicheng Yin",
      "Kaixuan Yin",
      "Weixing Chen",
      "Yang Liu",
      "Guanbin Li",
      "Liang Lin"
    ],
    "primary_category": "cs.CV",
    "categories": [
      "cs.CV",
      "cs.RO"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01780v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01780v1",
    "comment": "Codes will be available at https://github.com/HCPLabSYSU/DDP-WM",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01777v1",
    "title": "Stein-Rule Shrinkage for Stochastic Gradient Estimation in High Dimensions",
    "summary": "Stochastic gradient methods are central to large-scale learning, yet their analysis typically treats mini-batch gradients as unbiased estimators of the population gradient. In high-dimensional settings, however, classical results from statistical decision theory show that unbiased estimators are generally inadmissible under quadratic loss, suggesting that standard stochastic gradients may be suboptimal from a risk perspective. In this work, we formulate stochastic gradient computation as a high-dimensional estimation problem and introduce a decision-theoretic framework based on Stein-rule shrinkage. We construct a shrinkage gradient estimator that adaptively contracts noisy mini-batch gradients toward a stable restricted estimator derived from historical momentum. The shrinkage intensity is determined in a data-driven manner using an online estimate of gradient noise variance, leveraging second-moment statistics commonly maintained by adaptive optimization methods. Under a Gaussian noise model and for dimension p>=3, we show that the proposed estimator uniformly dominates the standard stochastic gradient under squared error loss and is minimax-optimal in the classical decision-theoretic sense. We further demonstrate how this estimator can be incorporated into the Adam optimizer, yielding a practical algorithm with negligible additional computational cost. Empirical evaluations on CIFAR10 and CIFAR100, across multiple levels of label noise, show consistent improvements over Adam in the large-batch regime. Ablation studies indicate that the gains arise primarily from selectively applying shrinkage to high-dimensional convolutional layers, while indiscriminate shrinkage across all parameters degrades performance. These results illustrate that classical shrinkage principles provide a principled and effective approach to improving stochastic gradient estimation in modern deep learning.",
    "published": "2026-02-02T08:01:13Z",
    "updated": "2026-02-02T08:01:13Z",
    "authors": [
      "M. Arashi",
      "M. Amintoosi"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.ST",
      "stat.ML"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01777v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01777v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01764v1",
    "title": "GDPR-Compliant Person Recognition in Industrial Environments Using MEMS-LiDAR and Hybrid Data",
    "summary": "The reliable detection of unauthorized individuals in safety-critical industrial indoor spaces is crucial to avoid plant shutdowns, property damage, and personal hazards. Conventional vision-based methods that use deep-learning approaches for person recognition provide image information but are sensitive to lighting and visibility conditions and often violate privacy regulations, such as the General Data Protection Regulation (GDPR) in the European Union. Typically, detection systems based on deep learning require annotated data for training. Collecting and annotating such data, however, is highly time-consuming and due to manual treatments not necessarily error free. Therefore, this paper presents a privacy-compliant approach based on Micro-Electro-Mechanical Systems LiDAR (MEMS-LiDAR), which exclusively captures anonymized 3D point clouds and avoids personal identification features. To compensate for the large amount of time required to record real LiDAR data and for post-processing and annotation, real recordings are augmented with synthetically generated scenes from the CARLA simulation framework. The results demonstrate that the hybrid data improves the average precision by 44 percentage points compared to a model trained exclusively with real data while reducing the manual annotation effort by 50 %. Thus, the proposed approach provides a scalable, cost-efficient alternative to purely real-data-based methods and systematically shows how synthetic LiDAR data can combine high performance in person detection with GDPR compliance in an industrial environment.",
    "published": "2026-02-02T07:48:03Z",
    "updated": "2026-02-02T07:48:03Z",
    "authors": [
      "Dennis Basile",
      "Dennis Sprute",
      "Helene Drksen",
      "Holger Flatt"
    ],
    "primary_category": "cs.CV",
    "categories": [
      "cs.CV"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01764v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01764v1",
    "comment": "Accepted at 19th CIRP Conference on Intelligent Computation in Manufacturing Engineering",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01760v1",
    "title": "MagicFuse: Single Image Fusion for Visual and Semantic Reinforcement",
    "summary": "This paper focuses on a highly practical scenario: how to continue benefiting from the advantages of multi-modal image fusion under harsh conditions when only visible imaging sensors are available. To achieve this goal, we propose a novel concept of single-image fusion, which extends conventional data-level fusion to the knowledge level. Specifically, we develop MagicFuse, a novel single image fusion framework capable of deriving a comprehensive cross-spectral scene representation from a single low-quality visible image. MagicFuse first introduces an intra-spectral knowledge reinforcement branch and a cross-spectral knowledge generation branch based on the diffusion models. They mine scene information obscured in the visible spectrum and learn thermal radiation distribution patterns transferred to the infrared spectrum, respectively. Building on them, we design a multi-domain knowledge fusion branch that integrates the probabilistic noise from the diffusion streams of these two branches, from which a cross-spectral scene representation can be obtained through successive sampling. Then, we impose both visual and semantic constraints to ensure that this scene representation can satisfy human observation while supporting downstream semantic decision-making. Extensive experiments show that our MagicFuse achieves visual and semantic representation performance comparable to or even better than state-of-the-art fusion methods with multi-modal inputs, despite relying solely on a single degraded visible image.",
    "published": "2026-02-02T07:43:29Z",
    "updated": "2026-02-02T07:43:29Z",
    "authors": [
      "Hao Zhang",
      "Yanping Zha",
      "Zizhuo Li",
      "Meiqi Gong",
      "Jiayi Ma"
    ],
    "primary_category": "cs.CV",
    "categories": [
      "cs.CV"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01760v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01760v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01757v1",
    "title": "Zero2Text: Zero-Training Cross-Domain Inversion Attacks on Textual Embeddings",
    "summary": "The proliferation of retrieval-augmented generation (RAG) has established vector databases as critical infrastructure, yet they introduce severe privacy risks via embedding inversion attacks. Existing paradigms face a fundamental trade-off: optimization-based methods require computationally prohibitive queries, while alignment-based approaches hinge on the unrealistic assumption of accessible in-domain training data. These constraints render them ineffective in strict black-box and cross-domain settings. To dismantle these barriers, we introduce Zero2Text, a novel training-free framework based on recursive online alignment. Unlike methods relying on static datasets, Zero2Text synergizes LLM priors with a dynamic ridge regression mechanism to iteratively align generation to the target embedding on-the-fly. We further demonstrate that standard defenses, such as differential privacy, fail to effectively mitigate this adaptive threat. Extensive experiments across diverse benchmarks validate Zero2Text; notably, on MS MARCO against the OpenAI victim model, it achieves 1.8x higher ROUGE-L and 6.4x higher BLEU-2 scores compared to baselines, recovering sentences from unknown domains without a single leaked data pair.",
    "published": "2026-02-02T07:42:18Z",
    "updated": "2026-02-02T07:42:18Z",
    "authors": [
      "Doohyun Kim",
      "Donghwa Kang",
      "Kyungjae Lee",
      "Hyeongboo Baek",
      "Brent Byunghoon Kang"
    ],
    "primary_category": "cs.CL",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01757v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01757v1",
    "comment": "10 pages",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01753v1",
    "title": "ObjEmbed: Towards Universal Multimodal Object Embeddings",
    "summary": "Aligning objects with corresponding textual descriptions is a fundamental challenge and a realistic requirement in vision-language understanding. While recent multimodal embedding models excel at global image-text alignment, they often struggle with fine-grained alignment between image regions and specific phrases. In this work, we present ObjEmbed, a novel MLLM embedding model that decomposes the input image into multiple regional embeddings, each corresponding to an individual object, along with global embeddings. It supports a wide range of visual understanding tasks like visual grounding, local image retrieval, and global image retrieval. ObjEmbed enjoys three key properties: (1) Object-Oriented Representation: It captures both semantic and spatial aspects of objects by generating two complementary embeddings for each region: an object embedding for semantic matching and an IoU embedding that predicts localization quality. The final object matching score combines semantic similarity with the predicted IoU, enabling more accurate retrieval. (2) Versatility: It seamlessly handles both region-level and image-level tasks. (3) Efficient Encoding: All objects in an image, along with the full image, are encoded in a single forward pass for high efficiency. Superior performance on 18 diverse benchmarks demonstrates its strong semantic discrimination.",
    "published": "2026-02-02T07:38:45Z",
    "updated": "2026-02-02T07:38:45Z",
    "authors": [
      "Shenghao Fu",
      "Yukun Su",
      "Fengyun Rao",
      "Jing Lyu",
      "Xiaohua Xie",
      "Wei-Shi Zheng"
    ],
    "primary_category": "cs.CV",
    "categories": [
      "cs.CV"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01753v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01753v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01751v1",
    "title": "MGKAN: Predicting Asymmetric Drug-Drug Interactions via a Multimodal Graph Kolmogorov-Arnold Network",
    "summary": "Predicting drug-drug interactions (DDIs) is essential for safe pharmacological treatments. Previous graph neural network (GNN) models leverage molecular structures and interaction networks but mostly rely on linear aggregation and symmetric assumptions, limiting their ability to capture nonlinear and heterogeneous patterns. We propose MGKAN, a Graph Kolmogorov-Arnold Network that introduces learnable basis functions into asymmetric DDI prediction. MGKAN replaces conventional MLP transformations with KAN-driven basis functions, enabling more expressive and nonlinear modeling of drug relationships. To capture pharmacological dependencies, MGKAN integrates three network views-an asymmetric DDI network, a co-interaction network, and a biochemical similarity network-with role-specific embeddings to preserve directional semantics. A fusion module combines linear attention and nonlinear transformation to enhance representational capacity. On two benchmark datasets, MGKAN outperforms seven state-of-the-art baselines. Ablation studies and case studies confirm its predictive accuracy and effectiveness in modeling directional drug effects.",
    "published": "2026-02-02T07:35:08Z",
    "updated": "2026-02-02T07:35:08Z",
    "authors": [
      "Kunyi Fan",
      "Mengjie Chen",
      "Longlong Li",
      "Cunquan Qu"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "q-bio.QM"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01751v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01751v1",
    "comment": "Submitted to ICASSP 2026",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01750v1",
    "title": "Adversarial Reward Auditing for Active Detection and Mitigation of Reward Hacking",
    "summary": "Reinforcement Learning from Human Feedback (RLHF) remains vulnerable to reward hacking, where models exploit spurious correlations in learned reward models to achieve high scores while violating human intent. Existing mitigations rely on static defenses that cannot adapt to novel exploitation strategies. We propose Adversarial Reward Auditing (ARA), a framework that reconceptualizes reward hacking as a dynamic, competitive game. ARA operates in two stages: first, a Hacker policy discovers reward model vulnerabilities while an Auditor learns to detect exploitation from latent representations; second, Auditor-Guided RLHF (AG-RLHF) gates reward signals to penalize detected hacking, transforming reward hacking from an unobservable failure into a measurable, controllable signal. Experiments across three hacking scenarios demonstrate that ARA achieves the best alignment-utility tradeoff among all baselines: reducing sycophancy to near-SFT levels while improving helpfulness, decreasing verbosity while achieving the highest ROUGE-L, and suppressing code gaming while improving Pass@1. Beyond single-domain evaluation, we show that reward hacking, detection, and mitigation all generalize across domains -- a Hacker trained on code gaming exhibits increased sycophancy despite no reward for this behavior, and an Auditor trained on one domain effectively suppresses exploitation in others, enabling efficient multi-domain defense with a single model.",
    "published": "2026-02-02T07:34:57Z",
    "updated": "2026-02-02T07:34:57Z",
    "authors": [
      "Mohammad Beigi",
      "Ming Jin",
      "Junshan Zhang",
      "Qifan Wang",
      "Lifu Huang"
    ],
    "primary_category": "cs.AI",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01750v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01750v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01744v1",
    "title": "Softmax Linear Attention: Reclaiming Global Competition",
    "summary": "While linear attention reduces the quadratic complexity of standard Transformers to linear time, it often lags behind in expressivity due to the removal of softmax normalization. This omission eliminates \\emph{global competition}, a critical mechanism that enables models to sharply focus on relevant information amidst long-context noise. In this work, we propose \\textbf{Softmax Linear Attention (SLA)}, a framework designed to restore this competitive selection without sacrificing efficiency. By lifting the softmax operation from the token level to the head level, SLA leverages attention heads as coarse semantic slots, applying a competitive gating mechanism to dynamically select the most relevant subspaces. This reintroduces the ``winner-take-all'' dynamics essential for precise retrieval and robust long-context understanding. Distinct from prior methods that focus on refining local kernel functions, SLA adopts a broader perspective by exploiting the higher-level multi-head aggregation structure. Extensive experiments demonstrate that SLA consistently enhances state-of-the-art linear baselines (RetNet, GLA, GDN) across language modeling and long-context benchmarks, particularly in challenging retrieval scenarios where it significantly boosts robustness against noise, validating its capability to restore precise focus while maintaining linear complexity.",
    "published": "2026-02-02T07:25:03Z",
    "updated": "2026-02-02T07:25:03Z",
    "authors": [
      "Mingwei Xu",
      "Xuan Lin",
      "Xinnan Guo",
      "Wanqing Xu",
      "Wanyun Cui"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01744v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01744v1",
    "comment": "11 pages,4 figures",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01741v1",
    "title": "Tail-Aware Post-Training Quantization for 3D Geometry Models",
    "summary": "The burgeoning complexity and scale of 3D geometry models pose significant challenges for deployment on resource-constrained platforms. While Post-Training Quantization (PTQ) enables efficient inference without retraining, conventional methods, primarily optimized for 2D Vision Transformers, fail to transfer effectively to 3D models due to intricate feature distributions and prohibitive calibration overhead. To address these challenges, we propose TAPTQ, a Tail-Aware Post-Training Quantization pipeline specifically engineered for 3D geometric learning. Our contribution is threefold: (1) To overcome the data-scale bottleneck in 3D datasets, we develop a progressive coarse-to-fine calibration construction strategy that constructs a highly compact subset to achieve both statistical purity and geometric representativeness. (2) We reformulate the quantization interval search as an optimization problem and introduce a ternary-search-based solver, reducing the computational complexity from $\\mathcal{O}(N)$ to $\\mathcal{O}(\\log N)$ for accelerated deployment. (3) To mitigate quantization error accumulation, we propose TRE-Guided Module-wise Compensation, which utilizes a Tail Relative Error (TRE) metric to adaptively identify and rectify distortions in modules sensitive to long-tailed activation outliers. Extensive experiments on the VGGT and Pi3 benchmarks demonstrate that TAPTQ consistently outperforms state-of-the-art PTQ methods in accuracy while significantly reducing calibration time. The code will be released soon.",
    "published": "2026-02-02T07:21:15Z",
    "updated": "2026-02-02T07:21:15Z",
    "authors": [
      "Sicheng Pan",
      "Chen Tang",
      "Shuzhao Xie",
      "Ke Yang",
      "Weixiang Zhang",
      "Jiawei Li",
      "Bin Chen",
      "Shu-Tao Xia",
      "Zhi Wang"
    ],
    "primary_category": "cs.CV",
    "categories": [
      "cs.CV"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01741v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01741v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01740v1",
    "title": "MACD: Model-Aware Contrastive Decoding via Counterfactual Data",
    "summary": "Video language models (Video-LLMs) are prone to hallucinations, often generating plausible but ungrounded content when visual evidence is weak, ambiguous, or biased. Existing decoding methods, such as contrastive decoding (CD), rely on random perturbations to construct contrastive data for mitigating hallucination patterns. However, such a way is hard to control the visual cues that drive hallucination or well align with model weaknesses. We propose Model-aware Counterfactual Data based Contrastive Decoding (MACD), a new inference strategy that combines model-guided counterfactual construction with decoding. Our approach uses the Video-LLM's own feedback to identify object regions most responsible for hallucination, generating targeted counterfactual inputs at the object level rather than arbitrary frame or temporal modifications. These model-aware counterfactual data is then integrated into CD to enforce evidence-grounded token selection during decoding. Experiments on EventHallusion, MVBench, Perception-test and Video-MME show that MACD consistently reduces hallucination while maintaining or improving task accuracy across diverse Video-LLMs, including Qwen and InternVL families. The method is especially effective in challenging scenarios involving small, occluded, or co-occurring objects. Our code and data will be publicly released.",
    "published": "2026-02-02T07:21:02Z",
    "updated": "2026-02-02T07:21:02Z",
    "authors": [
      "Qixin Xiao",
      "Kun Zhou"
    ],
    "primary_category": "cs.AI",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01740v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01740v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01737v1",
    "title": "Physics-Informed Chebyshev Polynomial Neural Operator for Parametric Partial Differential Equations",
    "summary": "Neural operators have emerged as powerful deep learning frameworks for approximating solution operators of parameterized partial differential equations (PDE). However, current methods predominantly rely on multilayer perceptrons (MLPs) for mapping inputs to solutions, which impairs training robustness in physics-informed settings due to inherent spectral biases and fixed activation functions. To overcome the architectural limitations, we introduce the Physics-Informed Chebyshev Polynomial Neural Operator (CPNO), a novel mesh-free framework that leverages a basis transformation to replace unstable monomial expansions with the numerically stable Chebyshev spectral basis. By integrating parameter dependent modulation mechanism to main net, CPNO constructs PDE solutions in a near-optimal functional space, decoupling the model from MLP-specific constraints and enhancing multi-scale representation. Theoretical analysis demonstrates the Chebyshev basis's near-minimax uniform approximation properties and superior conditioning, with Lebesgue constants growing logarithmically with degree, thereby mitigating spectral bias and ensuring stable gradient flow during optimization. Numerical experiments on benchmark parameterized PDEs show that CPNO achieves superior accuracy, faster convergence, and enhanced robustness to hyperparameters. The experiment of transonic airfoil flow has demonstrated the capability of CPNO in characterizing complex geometric problems.",
    "published": "2026-02-02T07:19:56Z",
    "updated": "2026-02-02T07:19:56Z",
    "authors": [
      "Biao Chen",
      "Jing Wang",
      "Hairun Xie",
      "Qineng Wang",
      "Shuai Zhang",
      "Yifan Xia",
      "Jifa Zhang"
    ],
    "primary_category": "physics.flu-dyn",
    "categories": [
      "physics.flu-dyn",
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01737v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01737v1",
    "comment": "28pages",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01731v1",
    "title": "Uncertainty-Aware Non-Prehensile Manipulation with Mobile Manipulators under Object-Induced Occlusion",
    "summary": "Non-prehensile manipulation using onboard sensing presents a fundamental challenge: the manipulated object occludes the sensor's field of view, creating occluded regions that can lead to collisions. We propose CURA-PPO, a reinforcement learning framework that addresses this challenge by explicitly modeling uncertainty under partial observability. By predicting collision possibility as a distribution, we extract both risk and uncertainty to guide the robot's actions. The uncertainty term encourages active perception, enabling simultaneous manipulation and information gathering to resolve occlusions. When combined with confidence maps that capture observation reliability, our approach enables safe navigation despite severe sensor occlusion. Extensive experiments across varying object sizes and obstacle configurations demonstrate that CURA-PPO achieves up to 3X higher success rates than the baselines, with learned behaviors that handle occlusions. Our method provides a practical solution for autonomous manipulation in cluttered environments using only onboard sensing.",
    "published": "2026-02-02T07:12:27Z",
    "updated": "2026-02-02T07:12:27Z",
    "authors": [
      "Jiwoo Hwang",
      "Taegeun Yang",
      "Jeil Jeong",
      "Minsung Yoon",
      "Sung-Eui Yoon"
    ],
    "primary_category": "cs.RO",
    "categories": [
      "cs.RO"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01731v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01731v1",
    "comment": "8 pages, 7 figures, Accepted to ICRA 2026, Webpage: https://jiw0o.github.io/cura-ppo/",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01724v1",
    "title": "DenVisCoM: Dense Vision Correspondence Mamba for Efficient and Real-time Optical Flow and Stereo Estimation",
    "summary": "In this work, we propose a novel Mamba block DenVisCoM, as well as a novel hybrid architecture specifically tailored for accurate and real-time estimation of optical flow and disparity estimation. Given that such multi-view geometry and motion tasks are fundamentally related, we propose a unified architecture to tackle them jointly. Specifically, the proposed hybrid architecture is based on DenVisCoM and a Transformer-based attention block that efficiently addresses real-time inference, memory footprint, and accuracy at the same time for joint estimation of motion and 3D dense perception tasks. We extensively analyze the benchmark trade-off of accuracy and real-time processing on a large number of datasets. Our experimental results and related analysis suggest that our proposed model can accurately estimate optical flow and disparity estimation in real time. All models and associated code are available at https://github.com/vimstereo/DenVisCoM.",
    "published": "2026-02-02T07:03:07Z",
    "updated": "2026-02-02T07:03:07Z",
    "authors": [
      "Tushar Anand",
      "Maheswar Bora",
      "Antitza Dantcheva",
      "Abhijit Das"
    ],
    "primary_category": "cs.CV",
    "categories": [
      "cs.CV"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01724v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01724v1",
    "comment": "IEEE International Conference on Robotics and Automation 2026",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01718v1",
    "title": "Revisiting Generalization Measures Beyond IID: An Empirical Study under Distributional Shift",
    "summary": "Generalization remains a central yet unresolved challenge in deep learning, particularly the ability to predict a model's performance beyond its training distribution using quantities available prior to test-time evaluation. Building on the large-scale study of Jiang et al. (2020). and concerns by Dziugaite et al. (2020). about instability across training configurations, we benchmark the robustness of generalization measures beyond IID regime. We train small-to-medium models over 10,000 hyperparameter configurations and evaluate more than 40 measures computable from the trained model and the available training data alone. We significantly broaden the experimental scope along multiple axes: (i) extending the evaluation beyond the standard IID setting to include benchmarking for robustness across diverse distribution shifts, (ii) evaluating multiple architectures and training recipes, and (iii) newly incorporating calibration- and information-criteria-based measures to assess their alignment with both IID and OOD generalization. We find that distribution shifts can substantially alter the predictive performance of many generalization measures, while a smaller subset remains comparatively stable across settings.",
    "published": "2026-02-02T06:56:33Z",
    "updated": "2026-02-02T06:56:33Z",
    "authors": [
      "Sora Nakai",
      "Youssef Fadhloun",
      "Kacem Mathlouthi",
      "Kotaro Yoshida",
      "Ganesh Talluri",
      "Ioannis Mitliagkas",
      "Hiroki Naganuma"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01718v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01718v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01698v1",
    "title": "Restoring Exploration after Post-Training: Latent Exploration Decoding for Large Reasoning Models",
    "summary": "Large Reasoning Models (LRMs) have recently achieved strong mathematical and code reasoning performance through Reinforcement Learning (RL) post-training. However, we show that modern reasoning post-training induces an unintended exploration collapse: temperature-based sampling no longer increases pass@$n$ accuracy. Empirically, the final-layer posterior of post-trained LRMs exhibit sharply reduced entropy, while the entropy of intermediate layers remains relatively high. Motivated by this entropy asymmetry, we propose Latent Exploration Decoding (LED), a depth-conditioned decoding strategy. LED aggregates intermediate posteriors via cumulative sum and selects depth configurations with maximal entropy as exploration candidates. Without additional training or parameters, LED consistently improves pass@1 and pass@16 accuracy by 0.61 and 1.03 percentage points across multiple reasoning benchmarks and models. Project page: https://GitHub.com/Xiaomi-Research/LED.",
    "published": "2026-02-02T06:12:33Z",
    "updated": "2026-02-02T06:12:33Z",
    "authors": [
      "Wenhui Tan",
      "Fiorenzo Parascandolo",
      "Enver Sangineto",
      "Jianzhong Ju",
      "Zhenbo Luo",
      "Qian Cao",
      "Rita Cucchiara",
      "Ruihua Song",
      "Jian Luan"
    ],
    "primary_category": "cs.CL",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01698v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01698v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01693v1",
    "title": "GSR: Learning Structured Reasoning for Embodied Manipulation",
    "summary": "Despite rapid progress, embodied agents still struggle with long-horizon manipulation that requires maintaining spatial consistency, causal dependencies, and goal constraints. A key limitation of existing approaches is that task reasoning is implicitly embedded in high-dimensional latent representations, making it challenging to separate task structure from perceptual variability. We introduce Grounded Scene-graph Reasoning (GSR), a structured reasoning paradigm that explicitly models world-state evolution as transitions over semantically grounded scene graphs. By reasoning step-wise over object states and spatial relations, rather than directly mapping perception to actions, GSR enables explicit reasoning about action preconditions, consequences, and goal satisfaction in a physically grounded space. To support learning such reasoning, we construct Manip-Cognition-1.6M, a large-scale dataset that jointly supervises world understanding, action planning, and goal interpretation. Extensive evaluations across RLBench, LIBERO, GSR-benchmark, and real-world robotic tasks show that GSR significantly improves zero-shot generalization and long-horizon task completion over prompting-based baselines. These results highlight explicit world-state representations as a key inductive bias for scalable embodied reasoning.",
    "published": "2026-02-02T06:07:42Z",
    "updated": "2026-02-02T06:07:42Z",
    "authors": [
      "Kewei Hu",
      "Michael Zhang",
      "Wei Ying",
      "Tianhao Liu",
      "Guoqiang Hao",
      "Zimeng Li",
      "Wanchan Yu",
      "Jiajian Jing",
      "Fangwen Chen",
      "Hanwen Kang"
    ],
    "primary_category": "cs.RO",
    "categories": [
      "cs.RO"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01693v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01693v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01682v1",
    "title": "Finite and Corruption-Robust Regret Bounds in Online Inverse Linear Optimization under M-Convex Action Sets",
    "summary": "We study online inverse linear optimization, also known as contextual recommendation, where a learner sequentially infers an agent's hidden objective vector from observed optimal actions over feasible sets that change over time. The learner aims to recommend actions that perform well under the agent's true objective, and the performance is measured by the regret, defined as the cumulative gap between the agent's optimal values and those achieved by the learner's recommended actions. Prior work has established a regret bound of $O(d\\log T)$, as well as a finite but exponentially large bound of $\\exp(O(d\\log d))$, where $d$ is the dimension of the optimization problem and $T$ is the time horizon, while a regret lower bound of $(d)$ is known (Gollapudi et al. 2021; Sakaue et al. 2025). Whether a finite regret bound polynomial in $d$ is achievable or not has remained an open question. We partially resolve this by showing that when the feasible sets are M-convex -- a broad class that includes matroids -- a finite regret bound of $O(d\\log d)$ is possible. We achieve this by combining a structural characterization of optimal solutions on M-convex sets with a geometric volume argument. Moreover, we extend our approach to adversarially corrupted feedback in up to $C$ rounds. We obtain a regret bound of $O((C+1)d\\log d)$ without prior knowledge of $C$, by monitoring directed graphs induced by the observed feedback to detect corruptions adaptively.",
    "published": "2026-02-02T05:48:54Z",
    "updated": "2026-02-02T05:48:54Z",
    "authors": [
      "Taihei Oki",
      "Shinsaku Sakaue"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "cs.DS",
      "stat.ML"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01682v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01682v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01677v1",
    "title": "SMTrack: State-Aware Mamba for Efficient Temporal Modeling in Visual Tracking",
    "summary": "Visual tracking aims to automatically estimate the state of a target object in a video sequence, which is challenging especially in dynamic scenarios. Thus, numerous methods are proposed to introduce temporal cues to enhance tracking robustness. However, conventional CNN and Transformer architectures exhibit inherent limitations in modeling long-range temporal dependencies in visual tracking, often necessitating either complex customized modules or substantial computational costs to integrate temporal cues. Inspired by the success of the state space model, we propose a novel temporal modeling paradigm for visual tracking, termed State-aware Mamba Tracker (SMTrack), providing a neat pipeline for training and tracking without needing customized modules or substantial computational costs to build long-range temporal dependencies. It enjoys several merits. First, we propose a novel selective state-aware space model with state-wise parameters to capture more diverse temporal cues for robust tracking. Second, SMTrack facilitates long-range temporal interactions with linear computational complexity during training. Third, SMTrack enables each frame to interact with previously tracked frames via hidden state propagation and updating, which releases computational costs of handling temporal cues during tracking. Extensive experimental results demonstrate that SMTrack achieves promising performance with low computational costs.",
    "published": "2026-02-02T05:44:59Z",
    "updated": "2026-02-02T05:44:59Z",
    "authors": [
      "Yinchao Ma",
      "Dengqing Yang",
      "Zhangyu He",
      "Wenfei Yang",
      "Tianzhu Zhang"
    ],
    "primary_category": "cs.CV",
    "categories": [
      "cs.CV"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01677v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01677v1",
    "comment": "This paper is accepted by IEEE TIP",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01671v1",
    "title": "AI-Assisted Adaptive Rendering for High-Frequency Security Telemetry in Web Interfaces",
    "summary": "Modern cybersecurity platforms must process and display high-frequency telemetry such as network logs, endpoint events, alerts, and policy changes in real time. Traditional rendering techniques based on static pagination or fixed polling intervals fail under volume conditions exceeding hundreds of thousands of events per second, leading to UI freezes, dropped frames, or stale data. This paper presents an AI-assisted adaptive rendering framework that dynamically regulates visual update frequency, prioritizes semantically relevant events, and selectively aggregates lower-priority data using behavior-driven heuristics and lightweight on-device machine learning models. Experimental validation demonstrates a 45-60 percent reduction in rendering overhead while maintaining analyst perception of real-time responsiveness.",
    "published": "2026-02-02T05:40:21Z",
    "updated": "2026-02-02T05:40:21Z",
    "authors": [
      "Mona Rajhans"
    ],
    "primary_category": "cs.HC",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CR"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01671v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01671v1",
    "comment": "To appear in IEEE ICCA 2025 proceedings",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01668v1",
    "title": "ASGMamba: Adaptive Spectral Gating Mamba for Multivariate Time Series Forecasting",
    "summary": "Long-term multivariate time series forecasting (LTSF) plays a crucial role in various high-performance computing applications, including real-time energy grid management and large-scale traffic flow simulation. However, existing solutions face a dilemma: Transformer-based models suffer from quadratic complexity, limiting their scalability on long sequences, while linear State Space Models (SSMs) often struggle to distinguish valuable signals from high-frequency noise, leading to wasted state capacity. To bridge this gap, we propose ASGMamba, an efficient forecasting framework designed for resource-constrained supercomputing environments. ASGMamba integrates a lightweight Adaptive Spectral Gating (ASG) mechanism that dynamically filters noise based on local spectral energy, enabling the Mamba backbone to focus its state evolution on robust temporal dynamics. Furthermore, we introduce a hierarchical multi-scale architecture with variable-specific Node Embeddings to capture diverse physical characteristics. Extensive experiments on nine benchmarks demonstrate that ASGMamba achieves state-of-the-art accuracy. While keeping strictly $$\\mathcal{O}(L)$$ complexity we significantly reduce the memory usage on long-horizon tasks, thus establishing ASGMamba as a scalable solution for high-throughput forecasting in resource limited environments.The code is available at https://github.com/hit636/ASGMamba",
    "published": "2026-02-02T05:38:21Z",
    "updated": "2026-02-02T05:38:21Z",
    "authors": [
      "Qianyang Li",
      "Xingjun Zhang",
      "Shaoxun Wang",
      "Jia Wei",
      "Yueqi Xing"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01668v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01668v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01666v1",
    "title": "Moonworks Lunara Aesthetic II: An Image Variation Dataset",
    "summary": "We introduce Lunara Aesthetic II, a publicly released, ethically sourced image dataset designed to support controlled evaluation and learning of contextual consistency in modern image generation and editing systems. The dataset comprises 2,854 anchor-linked variation pairs derived from original art and photographs created by Moonworks. Each variation pair applies contextual transformations, such as illumination, weather, viewpoint, scene composition, color tone, or mood; while preserving a stable underlying identity. Lunara Aesthetic II operationalizes identity-preserving contextual variation as a supervision signal while also retaining Lunara's signature high aesthetic scores. Results show high identity stability, strong target attribute realization, and a robust aesthetic profile that exceeds large-scale web datasets. Released under the Apache 2.0 license, Lunara Aesthetic II is intended for benchmarking, fine-tuning, and analysis of contextual generalization, identity preservation, and edit robustness in image generation and image-to-image systems with interpretable, relational supervision. The dataset is publicly available at: https://huggingface.co/datasets/moonworks/lunara-aesthetic-image-variations.",
    "published": "2026-02-02T05:37:28Z",
    "updated": "2026-02-02T05:37:28Z",
    "authors": [
      "Yan Wang",
      "Partho Hassan",
      "Samiha Sadeka",
      "Nada Soliman",
      "M M Sayeef Abdullah",
      "Sabit Hassan"
    ],
    "primary_category": "cs.CV",
    "categories": [
      "cs.CV"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01666v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01666v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "vision"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01661v1",
    "title": "From Frames to Sequences: Temporally Consistent Human-Centric Dense Prediction",
    "summary": "In this work, we focus on the challenge of temporally consistent human-centric dense prediction across video sequences. Existing models achieve strong per-frame accuracy but often flicker under motion, occlusion, and lighting changes, and they rarely have paired human video supervision for multiple dense tasks. We address this gap with a scalable synthetic data pipeline that generates photorealistic human frames and motion-aligned sequences with pixel-accurate depth, normals, and masks. Unlike prior static data synthetic pipelines, our pipeline provides both frame-level labels for spatial learning and sequence-level supervision for temporal learning. Building on this, we train a unified ViT-based dense predictor that (i) injects an explicit human geometric prior via CSE embeddings and (ii) improves geometry-feature reliability with a lightweight channel reweighting module after feature fusion. Our two-stage training strategy, combining static pretraining with dynamic sequence supervision, enables the model first to acquire robust spatial representations and then refine temporal consistency across motion-aligned sequences. Extensive experiments show that we achieve state-of-the-art performance on THuman2.1 and Hi4D and generalize effectively to in-the-wild videos.",
    "published": "2026-02-02T05:28:58Z",
    "updated": "2026-02-02T05:28:58Z",
    "authors": [
      "Xingyu Miao",
      "Junting Dong",
      "Qin Zhao",
      "Yuhang Yang",
      "Junhao Chen",
      "Yang Long"
    ],
    "primary_category": "cs.CV",
    "categories": [
      "cs.CV"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01661v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01661v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "vision"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01642v1",
    "title": "The Effect of Mini-Batch Noise on the Implicit Bias of Adam",
    "summary": "With limited high-quality data and growing compute, multi-epoch training is gaining back its importance across sub-areas of deep learning. Adam(W), versions of which are go-to optimizers for many tasks such as next token prediction, has two momentum hyperparameters $(_1, _2)$ controlling memory and one very important hyperparameter, batch size, controlling (in particular) the amount mini-batch noise. We introduce a theoretical framework to understand how mini-batch noise influences the implicit bias of memory in Adam (depending on $_1$, $_2$) towards sharper or flatter regions of the loss landscape, which is commonly observed to correlate with the generalization gap in multi-epoch training. We find that in the case of large batch sizes, higher $_2$ increases the magnitude of anti-regularization by memory (hurting generalization), but as the batch size becomes smaller, the dependence of (anti-)regulariation on $_2$ is reversed. A similar monotonicity shift (in the opposite direction) happens in $_1$. In particular, the commonly \"default\" pair $(_1, _2) = (0.9, 0.999)$ is a good choice if batches are small; for larger batches, in many settings moving $_1$ closer to $_2$ is much better in terms of validation accuracy in multi-epoch training. Moreover, our theoretical derivations connect the scale of the batch size at which the shift happens to the scale of the critical batch size. We illustrate this effect in experiments with small-scale data in the about-to-overfit regime.",
    "published": "2026-02-02T04:59:24Z",
    "updated": "2026-02-02T04:59:24Z",
    "authors": [
      "Matias D. Cattaneo",
      "Boris Shigida"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC",
      "stat.CO",
      "stat.ML"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01642v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01642v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01630v1",
    "title": "Research on World Models Is Not Merely Injecting World Knowledge into Specific Tasks",
    "summary": "World models have emerged as a critical frontier in AI research, aiming to enhance large models by infusing them with physical dynamics and world knowledge. The core objective is to enable agents to understand, predict, and interact with complex environments. However, current research landscape remains fragmented, with approaches predominantly focused on injecting world knowledge into isolated tasks, such as visual prediction, 3D estimation, or symbol grounding, rather than establishing a unified definition or framework. While these task-specific integrations yield performance gains, they often lack the systematic coherence required for holistic world understanding. In this paper, we analyze the limitations of such fragmented approaches and propose a unified design specification for world models. We suggest that a robust world model should not be a loose collection of capabilities but a normative framework that integrally incorporates interaction, perception, symbolic reasoning, and spatial representation. This work aims to provide a structured perspective to guide future research toward more general, robust, and principled models of the world.",
    "published": "2026-02-02T04:42:44Z",
    "updated": "2026-02-02T04:42:44Z",
    "authors": [
      "Bohan Zeng",
      "Kaixin Zhu",
      "Daili Hua",
      "Bozhou Li",
      "Chengzhuo Tong",
      "Yuran Wang",
      "Xinyi Huang",
      "Yifan Dai",
      "Zixiang Zhang",
      "Yifan Yang",
      "Zhou Liu",
      "Hao Liang",
      "Xiaochen Ma",
      "Ruichuan An",
      "Tianyi Bai",
      "Hongcheng Gao",
      "Junbo Niu",
      "Yang Shi",
      "Xinlong Chen",
      "Yue Ding",
      "Minglei Shi",
      "Kai Zeng",
      "Yiwen Tang",
      "Yuanxing Zhang",
      "Pengfei Wan",
      "Xintao Wang",
      "Wentao Zhang"
    ],
    "primary_category": "cs.CV",
    "categories": [
      "cs.CV"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01630v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01630v1",
    "comment": "13 pages, 4 figures",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01608v1",
    "title": "Reasoning with Autoregressive-Diffusion Collaborative Thoughts",
    "summary": "Autoregressive and diffusion models represent two complementary generative paradigms. Autoregressive models excel at sequential planning and constraint composition, yet struggle with tasks that require explicit spatial or physical grounding. Diffusion models, in contrast, capture rich spatial structure through high-dimensional generation, but lack the stepwise logical control needed to satisfy complex, multi-stage constraints or to reliably identify and correct errors. We introduce Collaborative Thoughts, a unified collaborative framework that enables autoregressive and diffusion models to reason and generate jointly through a closed-loop interaction. In Collaborative Thoughts, autoregressive models perform structured planning and constraint management, diffusion models instantiate these constraints as intermediate visual thoughts, and a vision-based critic module evaluates whether the visual thoughts satisfy the intended structural and physical requirements. This feedback is then used to iteratively refine subsequent planning and generation steps, mitigating error propagation across modalities. Importantly, Collaborative Thoughts uses the same collaborative loop regardless of whether the task is autoregressive question answering or diffusion-based visual generation. Through representative examples, we illustrate how Collaborative Thoughts can improve the reliability of spatial reasoning and the controllability of generation.",
    "published": "2026-02-02T03:54:15Z",
    "updated": "2026-02-02T03:54:15Z",
    "authors": [
      "Mu Yuan",
      "Liekang Zeng",
      "Guoliang Xing",
      "Lan Zhang",
      "Yunhao Liu"
    ],
    "primary_category": "cs.AI",
    "categories": [
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01608v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01608v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01599v1",
    "title": "The Multiple Ticket Hypothesis: Random Sparse Subnetworks Suffice for RLVR",
    "summary": "The Lottery Ticket Hypothesis demonstrated that sparse subnetworks can match full-model performance, suggesting parameter redundancy. Meanwhile, in Reinforcement Learning with Verifiable Rewards (RLVR), recent work has shown that updates concentrate on a sparse subset of parameters, which further lends evidence to this underlying redundancy. We study the simplest possible way to exploit this redundancy: training only a randomly selected subset of parameters at extreme sparsities. Empirically, we find that training just 1\\% of parameters matches or exceeds full-parameter RLVR finetuning across 3 models and 2 task domains. Moreover, different random masks show minimal overlap ($\\leq 0.005$ Jaccard similarity) and yet all succeed, suggesting pretrained models contain many viable sparse subnetworks rather than one privileged set. We term this the Multiple Ticket Hypothesis. We explain this phenomenon through the implicit per-step KL constraint in RLVR, which restricts updates to a low-dimensional subspace, enabling arbitrary sparse masks to succeed.",
    "published": "2026-02-02T03:43:31Z",
    "updated": "2026-02-02T03:43:31Z",
    "authors": [
      "Israel Adewuyi",
      "Solomon Okibe",
      "Vladmir Ivanov"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01599v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01599v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01585v1",
    "title": "A Lightweight Sparse Interaction Network for Time Series Forecasting",
    "summary": "Recent work shows that linear models can outperform several transformer models in long-term time-series forecasting (TSF). However, instead of explicitly performing temporal interaction through self-attention, linear models implicitly perform it based on stacked MLP structures, which may be insufficient in capturing the complex temporal dependencies and their performance still has potential for improvement. To this end, we propose a Lightweight Sparse Interaction Network (LSINet) for TSF task. Inspired by the sparsity of self-attention, we propose a Multihead Sparse Interaction Mechanism (MSIM). Different from self-attention, MSIM learns the important connections between time steps through sparsity-induced Bernoulli distribution to capture temporal dependencies for TSF. The sparsity is ensured by the proposed self-adaptive regularization loss. Moreover, we observe the shareability of temporal interactions and propose to perform Shared Interaction Learning (SIL) for MSIM to further enhance efficiency and improve convergence. LSINet is a linear model comprising only MLP structures with low overhead and equipped with explicit temporal interaction mechanisms. Extensive experiments on public datasets show that LSINet achieves both higher accuracy and better efficiency than advanced linear models and transformer models in TSF tasks. The code is available at the link https://github.com/Meteor-Stars/LSINet.",
    "published": "2026-02-02T03:24:14Z",
    "updated": "2026-02-02T03:24:14Z",
    "authors": [
      "Xu Zhang",
      "Qitong Wang",
      "Peng Wang",
      "Wei Wang"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01585v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01585v1",
    "comment": "The paper is published in AAAI Conference on Artificial Intelligence, AAAI 2025. The code is available at the link https://github.com/Meteor-Stars/LSINet",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01582v1",
    "title": "On the Fragility of AI-Based Channel Decoders under Small Channel Perturbations",
    "summary": "Recent advances in deep learning have led to AI-based error correction decoders that report empirical performance improvements over traditional belief-propagation (BP) decoding on AWGN channels. While such gains are promising, a fundamental question remains: where do these improvements come from, and what cost is paid to achieve them? In this work, we study this question through the lens of robustness to distributional shifts at the channel output. We evaluate both input-dependent adversarial perturbations (FGM and projected gradient methods under $\\ell_2$ constraints) and universal adversarial perturbations that apply a single norm-bounded shift to all received vectors. Our results show that recent AI decoders, including ECCT and CrossMPT, could suffer significant performance degradation under such perturbations, despite superior nominal performance under i.i.d. AWGN. Moreover, adversarial perturbations transfer relatively strongly between AI decoders but weakly to BP-based decoders, and universal perturbations are substantially more harmful than random perturbations of equal norm. These numerical findings suggest a potential robustness cost and higher sensitivity to channel distribution underlying recent AI decoding gains.",
    "published": "2026-02-02T03:22:12Z",
    "updated": "2026-02-02T03:22:12Z",
    "authors": [
      "Haoyu Lei",
      "Mohammad Jalali",
      "Chin Wa Lau",
      "Farzan Farnia"
    ],
    "primary_category": "cs.IT",
    "categories": [
      "cs.IT",
      "cs.AI",
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01582v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01582v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01576v1",
    "title": "Generative Visual Code Mobile World Models",
    "summary": "Mobile Graphical User Interface (GUI) World Models (WMs) offer a promising path for improving mobile GUI agent performance at train- and inference-time. However, current approaches face a critical trade-off: text-based WMs sacrifice visual fidelity, while the inability of visual WMs in precise text rendering led to their reliance on slow, complex pipelines dependent on numerous external models. We propose a novel paradigm: visual world modeling via renderable code generation, where a single Vision-Language Model (VLM) predicts the next GUI state as executable web code that renders to pixels, rather than generating pixels directly. This combines the strengths of both approaches: VLMs retain their linguistic priors for precise text rendering while their pre-training on structured web code enables high-fidelity visual generation. We introduce gWorld (8B, 32B), the first open-weight visual mobile GUI WMs built on this paradigm, along with a data generation framework (gWorld) that automatically synthesizes code-based training data. In extensive evaluation across 4 in- and 2 out-of-distribution benchmarks, gWorld sets a new pareto frontier in accuracy versus model size, outperforming 8 frontier open-weight models over 50.25x larger. Further analyses show that (1) scaling training data via gWorld yields meaningful gains, (2) each component of our pipeline improves data quality, and (3) stronger world modeling improves downstream mobile GUI policy performance.",
    "published": "2026-02-02T03:12:16Z",
    "updated": "2026-02-02T03:12:16Z",
    "authors": [
      "Woosung Koh",
      "Sungjun Han",
      "Segyu Lee",
      "Se-Young Yun",
      "Jamin Shin"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01576v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01576v1",
    "comment": "Pre-print (technical report)",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01561v1",
    "title": "Multimodal UNcommonsense: From Odd to Ordinary and Ordinary to Odd",
    "summary": "Commonsense reasoning in multimodal contexts remains a foundational challenge in artificial intelligence. We introduce Multimodal UNcommonsense(MUN), a benchmark designed to evaluate models' ability to handle scenarios that deviate from typical visual or contextual expectations. MUN pairs visual scenes with surprising or unlikely outcomes described in natural language, prompting models to either rationalize seemingly odd images using everyday logic or uncover unexpected interpretations in ordinary scenes. To support this task, we propose a retrieval-based in-context learning (R-ICL) framework that transfers reasoning capabilities from larger models to smaller ones without additional training. Leveraging a novel Multimodal Ensemble Retriever (MER), our method identifies semantically relevant exemplars even when image and text pairs are deliberately discordant. Experiments show an average improvement of 8.3% over baseline ICL methods, highlighting the effectiveness of R-ICL in low-frequency, atypical settings. MUN opens new directions for evaluating and improving visual-language models' robustness and adaptability in real-world, culturally diverse, and non-prototypical scenarios.",
    "published": "2026-02-02T02:54:34Z",
    "updated": "2026-02-02T02:54:34Z",
    "authors": [
      "Yejin Son",
      "Saejin Kim",
      "Dongjun Min",
      "Younjae Yu"
    ],
    "primary_category": "cs.CV",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01561v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01561v1",
    "comment": "24 pages",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01540v1",
    "title": "FSCA-Net: Feature-Separated Cross-Attention Network for Robust Multi-Dataset Training",
    "summary": "Crowd counting plays a vital role in public safety, traffic regulation, and smart city management. However, despite the impressive progress achieved by CNN- and Transformer-based models, their performance often deteriorates when applied across diverse environments due to severe domain discrepancies. Direct joint training on multiple datasets, which intuitively should enhance generalization, instead results in negative transfer, as shared and domain-specific representations become entangled. To address this challenge, we propose the Feature Separation and Cross-Attention Network FSCA-Net, a unified framework that explicitly disentangles feature representations into domain-invariant and domain-specific components. A novel cross-attention fusion module adaptively models interactions between these components, ensuring effective knowledge transfer while preserving dataset-specific discriminability. Furthermore, a mutual information optimization objective is introduced to maximize consistency among domain-invariant features and minimize redundancy among domain-specific ones, promoting complementary shared-private representations. Extensive experiments on multiple crowd counting benchmarks demonstrate that FSCA-Net effectively mitigates negative transfer and achieves state-of-the-art cross-dataset generalization, providing a robust and scalable solution for real-world crowd analysis.",
    "published": "2026-02-02T02:18:48Z",
    "updated": "2026-02-02T02:18:48Z",
    "authors": [
      "Yuehai Chen"
    ],
    "primary_category": "cs.CV",
    "categories": [
      "cs.CV"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01540v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01540v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01538v1",
    "title": "Making Avatars Interact: Towards Text-Driven Human-Object Interaction for Controllable Talking Avatars",
    "summary": "Generating talking avatars is a fundamental task in video generation. Although existing methods can generate full-body talking avatars with simple human motion, extending this task to grounded human-object interaction (GHOI) remains an open challenge, requiring the avatar to perform text-aligned interactions with surrounding objects. This challenge stems from the need for environmental perception and the control-quality dilemma in GHOI generation. To address this, we propose a novel dual-stream framework, InteractAvatar, which decouples perception and planning from video synthesis for grounded human-object interaction. Leveraging detection to enhance environmental perception, we introduce a Perception and Interaction Module (PIM) to generate text-aligned interaction motions. Additionally, an Audio-Interaction Aware Generation Module (AIM) is proposed to synthesize vivid talking avatars performing object interactions. With a specially designed motion-to-video aligner, PIM and AIM share a similar network structure and enable parallel co-generation of motions and plausible videos, effectively mitigating the control-quality dilemma. Finally, we establish a benchmark, GroundedInter, for evaluating GHOI video generation. Extensive experiments and comparisons demonstrate the effectiveness of our method in generating grounded human-object interactions for talking avatars. Project page: https://interactavatar.github.io",
    "published": "2026-02-02T02:12:09Z",
    "updated": "2026-02-02T02:12:09Z",
    "authors": [
      "Youliang Zhang",
      "Zhengguang Zhou",
      "Zhentao Yu",
      "Ziyao Huang",
      "Teng Hu",
      "Sen Liang",
      "Guozhen Zhang",
      "Ziqiao Peng",
      "Shunkai Li",
      "Yi Chen",
      "Zixiang Zhou",
      "Yuan Zhou",
      "Qinglin Lu",
      "Xiu Li"
    ],
    "primary_category": "cs.CV",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01538v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01538v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "vision"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01536v1",
    "title": "UniDWM: Towards a Unified Driving World Model via Multifaceted Representation Learning",
    "summary": "Achieving reliable and efficient planning in complex driving environments requires a model that can reason over the scene's geometry, appearance, and dynamics. We present UniDWM, a unified driving world model that advances autonomous driving through multifaceted representation learning. UniDWM constructs a structure- and dynamic-aware latent world representation that serves as a physically grounded state space, enabling consistent reasoning across perception, prediction, and planning. Specifically, a joint reconstruction pathway learns to recover the scene's structure, including geometry and visual texture, while a collaborative generation framework leverages a conditional diffusion transformer to forecast future world evolution within the latent space. Furthermore, we show that our UniDWM can be deemed as a variation of VAE, which provides theoretical guidance for the multifaceted representation learning. Extensive experiments demonstrate the effectiveness of UniDWM in trajectory planning, 4D reconstruction and generation, highlighting the potential of multifaceted world representations as a foundation for unified driving intelligence. The code will be publicly available at https://github.com/Say2L/UniDWM.",
    "published": "2026-02-02T02:10:51Z",
    "updated": "2026-02-02T02:10:51Z",
    "authors": [
      "Shuai Liu",
      "Siheng Ren",
      "Xiaoyao Zhu",
      "Quanmin Liang",
      "Zefeng Li",
      "Qiang Li",
      "Xin Hu",
      "Kai Huang"
    ],
    "primary_category": "cs.RO",
    "categories": [
      "cs.RO",
      "cs.CV"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01536v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01536v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01533v1",
    "title": "Rotation-free Online Handwritten Character Recognition Using Linear Recurrent Units",
    "summary": "Online handwritten character recognition leverages stroke order and dynamic features, which generally provide higher accuracy and robustness compared with offline recognition. However, in practical applications, rotational deformations can disrupt the spatial layout of strokes, substantially reducing recognition accuracy. Extracting rotation-invariant features therefore remains a challenging open problem. In this work, we employ the Sliding Window Path Signature (SW-PS) to capture local structural features of characters, and introduce the lightweight Linear Recurrent Units (LRU) as the classifier. The LRU combine the fast incremental processing capability of recurrent neural networks (RNN) with the efficient parallel training of state space models (SSM), while reliably modelling dynamic stroke characteristics. We conducted recognition experiments with random rotation angle up to $\\pm 180^{\\circ}$ on three subsets of the CASIA-OLHWDB1.1 dataset: digits, English upper letters, and Chinese radicals. The accuracies achieved after ensemble learning were $99.62\\%$, $96.67\\%$, and $94.33\\%$, respectively. Experimental results demonstrate that the proposed SW-PS+LRU framework consistently surpasses competing models in both convergence speed and test accuracy.",
    "published": "2026-02-02T01:57:45Z",
    "updated": "2026-02-02T01:57:45Z",
    "authors": [
      "Zhe Ling",
      "Sicheng Yu",
      "Danyu Yang"
    ],
    "primary_category": "cs.CV",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01533v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01533v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01522v1",
    "title": "When Is Rank-1 Enough? Geometry-Guided Initialization for Parameter-Efficient Fine-Tuning",
    "summary": "Parameter-efficient fine-tuning (PEFT) is a standard way to adapt multimodal large language models, yet extremely low-rank settings -- especially rank-1 LoRA -- are often unstable. We show that this instability is not solely due to limited capacity: in the rank-1 regime, optimization is highly sensitive to the update direction. Concretely, pretrained vision and text features form mismatched anisotropic regions, yielding a dominant \"gap\" direction that acts like a translation component and disproportionately steers early gradients under rank-1 constraints. Analyzing pretrained representations, we identify a modality-gap axis that dominates early gradient flow, while a random rank-1 initialization is unlikely to align with it, leading to weak gradients and training collapse. We propose Gap-Init, a geometry-aware initialization that aligns the rank-1 LoRA direction with an estimated modality-gap vector from a small calibration set, while keeping the initial LoRA update zero. Across multiple vision-language tasks and backbones, Gap-Init consistently stabilizes rank-1 training and can match or outperform strong rank-8 baselines. Our results suggest that at the extreme low-rank limit, initial alignment can matter as much as rank itself.",
    "published": "2026-02-02T01:31:25Z",
    "updated": "2026-02-02T01:31:25Z",
    "authors": [
      "Haoran Zhao",
      "Soyeon Caren Han",
      "Eduard Hovy"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01522v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01522v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01515v1",
    "title": "RAPT: Model-Predictive Out-of-Distribution Detection and Failure Diagnosis for Sim-to-Real Humanoid Robots",
    "summary": "Deploying learned control policies on humanoid robots is challenging: policies that appear robust in simulation can execute confidently in out-of-distribution (OOD) states after Sim-to-Real transfer, leading to silent failures that risk hardware damage. Although anomaly detection can mitigate these failures, prior methods are often incompatible with high-rate control, poorly calibrated at the extremely low false-positive rates required for practical deployment, or operate as black boxes that provide a binary stop signal without explaining why the robot drifted from nominal behavior. We present RAPT, a lightweight, self-supervised deployment-time monitor for 50Hz humanoid control. RAPT learns a probabilistic spatio-temporal manifold of nominal execution from simulation and evaluates execution-time predictive deviation as a calibrated, per-dimension signal. This yields (i) reliable online OOD detection under strict false-positive constraints and (ii) a continuous, interpretable measure of Sim-to-Real mismatch that can be tracked over time to quantify how far deployment has drifted from training. Beyond detection, we introduce an automated post-hoc root-cause analysis pipeline that combines gradient-based temporal saliency derived from RAPT's reconstruction objective with LLM-based reasoning conditioned on saliency and joint kinematics to produce semantic failure diagnoses in a zero-shot setting. We evaluate RAPT on a Unitree G1 humanoid across four complex tasks in simulation and on physical hardware. In large-scale simulation, RAPT improves True Positive Rate (TPR) by 37% over the strongest baseline at a fixed episode-level false positive rate of 0.5%. On real-world deployments, RAPT achieves a 12.5% TPR improvement and provides actionable interpretability, reaching 75% root-cause classification accuracy across 16 real-world failures using only proprioceptive data.",
    "published": "2026-02-02T01:04:55Z",
    "updated": "2026-02-02T01:04:55Z",
    "authors": [
      "Humphrey Munn",
      "Brendan Tidd",
      "Peter Bohm",
      "Marcus Gallagher",
      "David Howard"
    ],
    "primary_category": "cs.RO",
    "categories": [
      "cs.RO",
      "cs.LG"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01515v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01515v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01510v1",
    "title": "Enhancing Generalization in Evolutionary Feature Construction for Symbolic Regression through Vicinal Jensen Gap Minimization",
    "summary": "Genetic programming-based feature construction has achieved significant success in recent years as an automated machine learning technique to enhance learning performance. However, overfitting remains a challenge that limits its broader applicability. To improve generalization, we prove that vicinal risk, estimated through noise perturbation or mixup-based data augmentation, is bounded by the sum of empirical risk and a regularization term-either finite difference or the vicinal Jensen gap. Leveraging this decomposition, we propose an evolutionary feature construction framework that jointly optimizes empirical risk and the vicinal Jensen gap to control overfitting. Since datasets may vary in noise levels, we develop a noise estimation strategy to dynamically adjust regularization strength. Furthermore, to mitigate manifold intrusion-where data augmentation may generate unrealistic samples that fall outside the data manifold-we propose a manifold intrusion detection mechanism. Experimental results on 58 datasets demonstrate the effectiveness of Jensen gap minimization compared to other complexity measures. Comparisons with 15 machine learning algorithms further indicate that genetic programming with the proposed overfitting control strategy achieves superior performance.",
    "published": "2026-02-02T00:46:16Z",
    "updated": "2026-02-02T00:46:16Z",
    "authors": [
      "Hengzhe Zhang",
      "Qi Chen",
      "Bing Xue",
      "Wolfgang Banzhaf",
      "Mengjie Zhang"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "cs.NE"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01510v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01510v1",
    "comment": null,
    "journal_ref": null,
    "doi": "10.1109/TEVC.2025.3581739",
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01505v1",
    "title": "Optimal Sample Complexity for Single Time-Scale Actor-Critic with Momentum",
    "summary": "We establish an optimal sample complexity of $O(^{-2})$ for obtaining an $$-optimal global policy using a single-timescale actor-critic (AC) algorithm in infinite-horizon discounted Markov decision processes (MDPs) with finite state-action spaces, improving upon the prior state of the art of $O(^{-3})$. Our approach applies STORM (STOchastic Recursive Momentum) to reduce variance in the critic updates. However, because samples are drawn from a nonstationary occupancy measure induced by the evolving policy, variance reduction via STORM alone is insufficient. To address this challenge, we maintain a buffer of small fraction of recent samples and uniformly sample from it for each critic update. Importantly, these mechanisms are compatible with existing deep learning architectures and require only minor modifications, without compromising practical applicability.",
    "published": "2026-02-02T00:35:42Z",
    "updated": "2026-02-02T00:35:42Z",
    "authors": [
      "Navdeep Kumar",
      "Tehila Dahan",
      "Lior Cohen",
      "Ananyabrata Barua",
      "Giorgia Ramponi",
      "Kfir Yehuda Levy",
      "Shie Mannor"
    ],
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01505v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01505v1",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01503v1",
    "title": "Governance at the Edge of Architecture: Regulating NeuroAI and Neuromorphic Systems",
    "summary": "Current AI governance frameworks, including regulatory benchmarks for accuracy, latency, and energy efficiency, are built for static, centrally trained artificial neural networks on von Neumann hardware. NeuroAI systems, embodied in neuromorphic hardware and implemented via spiking neural networks, break these assumptions. This paper examines the limitations of current AI governance frameworks for NeuroAI, arguing that assurance and audit methods must co-evolve with these architectures, aligning traditional regulatory metrics with the physics, learning dynamics, and embodied efficiency of brain-inspired computation to enable technically grounded assurance.",
    "published": "2026-02-02T00:33:19Z",
    "updated": "2026-02-02T00:33:19Z",
    "authors": [
      "Afifah Kashif",
      "Abdul Muhsin Hameed",
      "Asim Iqbal"
    ],
    "primary_category": "cs.ET",
    "categories": [
      "cs.ET",
      "cs.AI",
      "cs.AR"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01503v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01503v1",
    "comment": "9 pages, 1 table, 1 figure",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "ai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2602.01501v1",
    "title": "TreeLoc: 6-DoF LiDAR Global Localization in Forests via Inter-Tree Geometric Matching",
    "summary": "Reliable localization is crucial for navigation in forests, where GPS is often degraded and LiDAR measurements are repetitive, occluded, and structurally complex. These conditions weaken the assumptions of traditional urban-centric localization methods, which assume that consistent features arise from unique structural patterns, necessitating forest-centric solutions to achieve robustness in these environments. To address these challenges, we propose TreeLoc, a LiDAR-based global localization framework for forests that handles place recognition and 6-DoF pose estimation. We represent scenes using tree stems and their Diameter at Breast Height (DBH), which are aligned to a common reference frame via their axes and summarized using the tree distribution histogram (TDH) for coarse matching, followed by fine matching with a 2D triangle descriptor. Finally, pose estimation is achieved through a two-step geometric verification. On diverse forest benchmarks, TreeLoc outperforms baselines, achieving precise localization. Ablation studies validate the contribution of each component. We also propose applications for long-term forest management using descriptors from a compact global tree database. TreeLoc is open-sourced for the robotics community at https://github.com/minwoo0611/TreeLoc.",
    "published": "2026-02-02T00:32:07Z",
    "updated": "2026-02-02T00:32:07Z",
    "authors": [
      "Minwoo Jung",
      "Nived Chebrolu",
      "Lucas Carvalho de Lima",
      "Haedam Oh",
      "Maurice Fallon",
      "Ayoung Kim"
    ],
    "primary_category": "cs.RO",
    "categories": [
      "cs.RO",
      "cs.CV"
    ],
    "abstract_url": "https://arxiv.org/abs/2602.01501v1",
    "pdf_url": "https://arxiv.org/pdf/2602.01501v1",
    "comment": "An 8-page paper with 7 tables and 8 figures, accepted to ICRA 2026",
    "journal_ref": null,
    "doi": null,
    "relevance_score": 1.2,
    "matched_areas": [
      "vision"
    ]
  }
]