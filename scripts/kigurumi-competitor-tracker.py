#!/usr/bin/env python3
"""
Kigurumi ç«å“æƒ…æŠ¥ Web æœç´¢æ¨¡å—
ä½¿ç”¨ Brave Search API æŒç»­è¿½è¸ªç«å“åŠ¨æ€

Author: AI Agent
Phase 2 - Competitor Intelligence
"""

import json
import os
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Any
import subprocess


class CompetitorWebTracker:
    """ç«å“ Web æƒ…æŠ¥è¿½è¸ªå™¨"""
    
    COMPETITOR_BRANDS = [
        'Dollkii', 'NFD Studio', 'Niya Kigurumi', 
        'KigMask', 'KigLand', 'KigDom', 'Hiyasuya',
        'Hadalabo', 'Kigurumi-Online', 'Animegao Mall'
    ]
    
    SEARCH_QUERIES = {
        'æ–°å“å‘å¸ƒ': [
            'Dollkii new release 2026',
            'NFD Studio new kigurumi mask',
            'Niya Kigurumi new product',
            'ç€ãã‚‹ã¿ æ–°ä½œ 2026',
            'kigurumi new release 2026'
        ],
        'ä»·æ ¼åŠ¨æ€': [
            'kigurumi mask price 2026',
            'Dollkii price',
            'NFD kigurumi price',
            'å¤´å£³ ä»·æ ¼ å®šåˆ¶',
            'kigurumi cost budget'
        ],
        'å¸‚åœºè¶‹åŠ¿': [
            'kigurumi market trend 2026',
            'ç€ãã‚‹ã¿ äººæ°—',
            'kigurumi community growth',
            'animegao popularity'
        ],
        'ç«å“å¯¹æ¯”': [
            'Dollkii vs NFD',
            'best kigurumi mask brand',
            'kigurumi maker comparison',
            'ç€å¤´å£³ å·¥ä½œå®¤ æ¨è'
        ]
    }
    
    def __init__(self, base_dir: str = "research/kigurumi"):
        self.base_dir = Path(base_dir)
        self.intel_dir = self.base_dir / "competitor-intel"
        self.intel_dir.mkdir(exist_ok=True)
        
        self.web_data_file = self.intel_dir / "web_search_results.jsonl"
        self.summary_file = self.intel_dir / "latest_summary.json"
    
    def search_web(self, query: str, count: int = 10) -> List[Dict]:
        """ä½¿ç”¨ web_search å·¥å…·è¿›è¡Œæœç´¢"""
        # ç”±äºæ— æ³•ç›´æ¥è°ƒç”¨ web_search å·¥å…·ï¼Œè¿™é‡Œè¿”å›æ¨¡æ‹Ÿç»“æ„
        # å®é™…è¿è¡Œæ—¶ï¼Œåº”è¯¥é€šè¿‡å¤–éƒ¨è°ƒç”¨æˆ– API è·å–æ•°æ®
        return []
    
    def run_comprehensive_search(self) -> Dict[str, Any]:
        """æ‰§è¡Œå…¨é¢çš„ç«å“æœç´¢"""
        results = {
            'search_time': datetime.now().isoformat(),
            'queries': {},
            'findings': []
        }
        
        for category, queries in self.SEARCH_QUERIES.items():
            results['queries'][category] = []
            for query in queries:
                # è®°å½•æœç´¢æ„å›¾
                results['queries'][category].append({
                    'query': query,
                    'status': 'scheduled'
                })
        
        # ä¿å­˜æœç´¢è®¡åˆ’
        self._save_search_plan(results)
        return results
    
    def _save_search_plan(self, plan: Dict):
        """ä¿å­˜æœç´¢è®¡åˆ’"""
        plan_file = self.intel_dir / f"search_plan_{datetime.now().strftime('%Y%m%d')}.json"
        with open(plan_file, 'w', encoding='utf-8') as f:
            json.dump(plan, f, ensure_ascii=False, indent=2)
    
    def analyze_brand_mentions(self, messages_file: str = "research/kigurumi/community-data/competitor_intel.jsonl") -> Dict:
        """åˆ†æç¤¾åŒºä¸­çš„å“ç‰ŒæåŠ"""
        mentions = []
        
        if Path(messages_file).exists():
            with open(messages_file, 'r', encoding='utf-8') as f:
                for line in f:
                    try:
                        intel = json.loads(line.strip())
                        mentions.append(intel)
                    except:
                        continue
        
        # å“ç‰ŒæåŠç»Ÿè®¡
        brand_stats = {}
        for m in mentions:
            brand = m.get('name', 'unknown')
            if brand not in brand_stats:
                brand_stats[brand] = {
                    'mentions': 0,
                    'sentiments': {'positive': 0, 'neutral': 0, 'negative': 0},
                    'contexts': []
                }
            brand_stats[brand]['mentions'] += 1
            brand_stats[brand]['sentiments'][m.get('sentiment', 'neutral')] += 1
            brand_stats[brand]['contexts'].append(m.get('context', '')[:100])
        
        return {
            'total_mentions': len(mentions),
            'brand_analysis': brand_stats,
            'analysis_date': datetime.now().isoformat()
        }
    
    def generate_competitor_alert(self) -> str:
        """ç”Ÿæˆç«å“åŠ¨æ€é¢„è­¦æŠ¥å‘Š"""
        analysis = self.analyze_brand_mentions()
        
        alert = f"""# ç«å“åŠ¨æ€é¢„è­¦æŠ¥å‘Š

ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M')}

## ğŸ“Š å“ç‰ŒæåŠç»Ÿè®¡

| å“ç‰Œ | æåŠæ¬¡æ•° | æƒ…æ„Ÿå€¾å‘ |
|-----|---------|---------|
"""
        
        for brand, stats in analysis['brand_analysis'].items():
            total = stats['mentions']
            pos = stats['sentiments']['positive']
            neg = stats['sentiments']['negative']
            sentiment = "ğŸ‘" if pos > neg else "ğŸ‘" if neg > pos else "ğŸ˜"
            alert += f"| {brand} | {total} | {sentiment} |\n"
        
        alert += f"""
## ğŸ” æœ€æ–°æåŠ

"""
        
        # æ·»åŠ æœ€æ–°å‡ æ¡æåŠ
        for brand, stats in list(analysis['brand_analysis'].items())[:3]:
            if stats['contexts']:
                alert += f"### {brand}\n"
                for ctx in stats['contexts'][:2]:
                    alert += f"- {ctx}...\n"
                alert += "\n"
        
        return alert
    
    def update_competitor_tracking_doc(self, tracking_file: str = "research/kigurumi/competitor-tracking.md"):
        """æ›´æ–°ç«å“è¿½è¸ªæ–‡æ¡£"""
        analysis = self.analyze_brand_mentions()
        
        # è¯»å–ç°æœ‰æ–‡æ¡£
        tracking_path = Path(tracking_file)
        if not tracking_path.exists():
            return
        
        with open(tracking_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # æ›´æ–°æœ¬æœˆåŠ¨æ€æ±‡æ€»éƒ¨åˆ†
        today = datetime.now().strftime('%Y-%m-%d')
        new_entries = []
        
        for brand, stats in analysis['brand_analysis'].items():
            if stats['mentions'] > 0:
                sentiment = "æ­£é¢" if stats['sentiments']['positive'] > stats['sentiments']['negative'] else "ä¸­æ€§"
                new_entries.append(f"| {brand} | ç¤¾åŒºæåŠ | è¢«æåŠ {stats['mentions']} æ¬¡ï¼Œæ•´ä½“æƒ…æ„Ÿ: {sentiment} | ä¸­ç­‰ |")
        
        # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…åº”è¯¥æ›´ç²¾ç»†åœ°æ›´æ–°æ–‡æ¡£
        print(f"ç«å“è¿½è¸ªæ–‡æ¡£æ›´æ–°å»ºè®®: æ·»åŠ  {len(new_entries)} æ¡æ–°åŠ¨æ€")
        return new_entries


def main():
    """ç«å“è¿½è¸ªä¸»å…¥å£"""
    tracker = CompetitorWebTracker()
    
    # 1. æ‰§è¡Œæœç´¢è®¡åˆ’
    search_plan = tracker.run_comprehensive_search()
    print(f"æœç´¢è®¡åˆ’å·²ç”Ÿæˆ: {len(search_plan['queries'])} ä¸ªç±»åˆ«")
    
    # 2. åˆ†æå“ç‰ŒæåŠ
    analysis = tracker.analyze_brand_mentions()
    print(f"\nå“ç‰ŒæåŠåˆ†æ:")
    print(f"- æ€»æåŠæ•°: {analysis['total_mentions']}")
    print(f"- æ¶‰åŠå“ç‰Œ: {list(analysis['brand_analysis'].keys())}")
    
    # 3. ç”Ÿæˆé¢„è­¦æŠ¥å‘Š
    alert = tracker.generate_competitor_alert()
    
    # ä¿å­˜é¢„è­¦æŠ¥å‘Š
    alert_file = tracker.intel_dir / f"alert_{datetime.now().strftime('%Y%m%d')}.md"
    with open(alert_file, 'w', encoding='utf-8') as f:
        f.write(alert)
    print(f"\né¢„è­¦æŠ¥å‘Šå·²ä¿å­˜: {alert_file}")
    
    return tracker, analysis


if __name__ == "__main__":
    tracker, analysis = main()
